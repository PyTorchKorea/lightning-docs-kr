


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ko" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ko" > <!--<![endif]-->
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5SCNQBF5');
  </script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="google-site-verification" content="okUst94cAlWSsUsGZTB4xSS4UKTtRV8Nu5XZ9pdd3Aw" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LightningModule &mdash; PyTorch Lightning &amp; PyTorch Korea User Group 2.0.5 문서</title>
  

  
  
    <link rel="shortcut icon" href="../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://lightning.ai/docs/pytorch/stable//api/lightning.pytorch.core.LightningModule.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/main.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />
    <link rel="next" title="HyperparametersMixin" href="lightning.pytorch.core.mixins.HyperparametersMixin.html" />
    <link rel="prev" title="LightningDataModule" href="lightning.pytorch.core.LightningDataModule.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-82W25RV60Q"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-82W25RV60Q');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>

  <script src="https://unpkg.com/react@18/umd/react.development.js" crossorigin></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js" crossorigin></script>
  <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>
  <script src="../_static/js/react/react.jsx" type="text/babel"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://lightning.ai/docs/pytorch/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://lightning.ai/pages/blog/">Blog</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/pytorch/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/fabric/stable/">
                  <span class="dropdown-title">Lightning Fabric</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li> -->

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://www.pytorchlightning.ai/community">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://lightning.ai/docs/pytorch/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://lightning.ai/forums/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <!-- 
          <li>
            <a href="https://lightning.ai/docs/pytorch/latest/past_versions.html">Previous Versions</a>
          </li>
          

          <li>
            <a href="https://github.com/Lightning-AI/lightning">GitHub</a>
          </li> -->

          <li>
            <a href="https://www.lightning.ai/">Lightning AI</a>
          </li>

          <li>
            <a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">파이토치 한국어 커뮤니티</a>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  2.0.5
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Home</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../starter/introduction.html">Lightning in 15 minutes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/installation.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../upgrade/migration_guide.html">Guide how to upgrade to the 2.0 version</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Level Up</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../levels/core_skills.html">Basic skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/intermediate.html">Intermediate skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/advanced.html">Advanced skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/expert.html">Expert skills</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/trainer.html">Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optional API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../api_references.html">accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#callbacks">callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#cli">cli</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api_references.html#core">core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#loggers">loggers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#profiler">profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#trainer">trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#strategies">strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#tuner">tuner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#utilities">utilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary/index.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/index.html">How-to Guides</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../api_references.html">accelerators</a> &gt;</li>
        
      <li>LightningModule</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/api/lightning.pytorch.core.LightningModule.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="lightningmodule">
<h1>LightningModule<a class="headerlink" href="#lightningmodule" title="이 표제에 대한 퍼머링크">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lightning.pytorch.core.</span></span><span class="sig-name descname"><span class="pre">LightningModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>기반 클래스: <code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.fabric.utilities.device_dtype_mixin._DeviceDtypeModuleMixin</span></code>, <a class="reference internal" href="lightning.pytorch.core.mixins.HyperparametersMixin.html#lightning.pytorch.core.mixins.HyperparametersMixin" title="lightning.pytorch.core.mixins.hparams_mixin.HyperparametersMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.pytorch.core.mixins.hparams_mixin.HyperparametersMixin</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.hooks.ModelHooks.html#lightning.pytorch.core.hooks.ModelHooks" title="lightning.pytorch.core.hooks.ModelHooks"><code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.pytorch.core.hooks.ModelHooks</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks" title="lightning.pytorch.core.hooks.DataHooks"><code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.pytorch.core.hooks.DataHooks</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.hooks.CheckpointHooks.html#lightning.pytorch.core.hooks.CheckpointHooks" title="lightning.pytorch.core.hooks.CheckpointHooks"><code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.pytorch.core.hooks.CheckpointHooks</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.all_gather"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.all_gather" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes. Failing to do so will cause your program to stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.all_gather.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.all_gather.params.data">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>]) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.all_gather.params.group"></span><strong>group</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.all_gather.params.group">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.all_gather.params.sync_grads"></span><strong>sync_grads</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.all_gather.params.sync_grads">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>]</p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.backward"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.backward" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#lightning.pytorch.core.LightningModule.training_step" title="lightning.pytorch.core.LightningModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your
own implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><p><span class="target" id="lightning.pytorch.core.LightningModule.backward.params.loss"></span><strong>loss</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.backward.params.loss">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – The loss tensor returned by <a class="reference internal" href="#lightning.pytorch.core.LightningModule.training_step" title="lightning.pytorch.core.LightningModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.clip_gradients"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.clip_gradients" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#lightning.pytorch.core.LightningModule.configure_gradient_clipping" title="lightning.pytorch.core.LightningModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.clip_gradients.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.clip_gradients.params.optimizer">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>) – Current optimizer being used.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.clip_gradients.params.gradient_clip_val"></span><strong>gradient_clip_val</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.clip_gradients.params.gradient_clip_val">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – The value at which to clip gradients.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.clip_gradients.params.gradient_clip_algorithm"></span><strong>gradient_clip_algorithm</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.clip_gradients.params.gradient_clip_algorithm">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.configure_callbacks"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.configure_callbacks" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code>
gets called, the list or a callback returned here will be merged with the list of callbacks passed to the
Trainer’s <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks
already present in the Trainer’s callbacks list, it will take priority and replace them. In addition,
Lightning will make sure <a class="reference internal" href="lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> callbacks
run last.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence</span></code></a>[<a class="reference internal" href="lightning.pytorch.callbacks.Callback.html#lightning.pytorch.callbacks.Callback" title="lightning.pytorch.callbacks.callback.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></a>], <a class="reference internal" href="lightning.pytorch.callbacks.Callback.html#lightning.pytorch.callbacks.Callback" title="lightning.pytorch.callbacks.callback.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></a>]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.configure_gradient_clipping"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.configure_gradient_clipping" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step" title="lightning.pytorch.core.LightningModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.optimizer">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>) – Current optimizer being used.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.gradient_clip_val"></span><strong>gradient_clip_val</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.gradient_clip_val">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.gradient_clip_algorithm"></span><strong>gradient_clip_algorithm</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.configure_gradient_clipping.params.gradient_clip_algorithm">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.configure_optimizers"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.configure_optimizers" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you’d need
one. But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only
works in the manual optimization mode.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p><p>Any of these 6 options.</p>
<ul class="simple">
<li><p><strong>Single optimizer</strong>.</p></li>
<li><p><strong>List or Tuple</strong> of optimizers.</p></li>
<li><p><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers
(or multiple <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>).</p></li>
<li><p><strong>Dictionary</strong>, with an <code class="docutils literal notranslate"><span class="pre">&quot;optimizer&quot;</span></code> key, and (optionally) a <code class="docutils literal notranslate"><span class="pre">&quot;lr_scheduler&quot;</span></code>
key whose value is a single LR scheduler or <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>.</p></li>
<li><p><strong>None</strong> - Fit will run without any optimizer.</p></li>
</ul>
</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># REQUIRED: The scheduler instance</span>
    <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="c1"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.</span>
    <span class="c1"># &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;</span>
    <span class="c1"># updates it after a optimizer update.</span>
    <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="c1"># How many epochs/steps should pass between calls to</span>
    <span class="c1"># `scheduler.step()`. 1 corresponds to updating the learning</span>
    <span class="c1"># rate after every epoch/step.</span>
    <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Metric to to monitor for schedulers like `ReduceLROnPlateau`</span>
    <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="c1"># If set to `True`, will enforce that the value specified &#39;monitor&#39;</span>
    <span class="c1"># is available when the scheduler is updated, thus stopping</span>
    <span class="c1"># training if not found. If set to `False`, it will only produce a warning</span>
    <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># If using the `LearningRateMonitor` callback to monitor the</span>
    <span class="c1"># learning rate progress, this keyword can be used to specify</span>
    <span class="c1"># a custom logged name</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>When there are schedulers in which the <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method is conditioned on a value, such as the
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.lr_scheduler.ReduceLROnPlateau</span></code></a> scheduler, Lightning requires that the
<code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> contains the keyword <code class="docutils literal notranslate"><span class="pre">&quot;monitor&quot;</span></code> set to the metric name that the scheduler
should be conditioned on.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The ReduceLROnPlateau scheduler requires a monitor</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span>
            <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;metric_to_track&quot;</span><span class="p">,</span>
            <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="s2">&quot;indicates how often the metric is updated&quot;</span>
            <span class="c1"># If &quot;monitor&quot; references validation metrics, then &quot;frequency&quot; should be set to a</span>
            <span class="c1"># multiple of &quot;trainer.check_val_every_n_epoch&quot;.</span>
        <span class="p">},</span>
    <span class="p">}</span>


<span class="c1"># In the case of two optimizers, only one using the ReduceLROnPlateau scheduler</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer1</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">optimizer2</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler1</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="n">scheduler2</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer1</span><span class="p">,</span>
            <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">scheduler1</span><span class="p">,</span>
                <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;metric_to_track&quot;</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer2</span><span class="p">,</span> <span class="s2">&quot;lr_scheduler&quot;</span><span class="p">:</span> <span class="n">scheduler2</span><span class="p">},</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>Metrics can be made available to monitor by simply logging it using
<code class="docutils literal notranslate"><span class="pre">self.log('metric_to_track',</span> <span class="pre">metric_val)</span></code> in your <a class="reference internal" href="#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>Some things to know:</p>
<ul class="simple">
<li><p>Lightning calls <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> and <code class="docutils literal notranslate"><span class="pre">.step()</span></code> automatically in case of automatic optimization.</p></li>
<li><p>If a learning rate scheduler is specified in <code class="docutils literal notranslate"><span class="pre">configure_optimizers()</span></code> with key
<code class="docutils literal notranslate"><span class="pre">&quot;interval&quot;</span></code> (default “epoch”) in the scheduler configuration, Lightning will call
the scheduler’s <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method automatically in case of automatic optimization.</p></li>
<li><p>If you use 16-bit precision (<code class="docutils literal notranslate"><span class="pre">precision=16</span></code>), Lightning will automatically handle the optimizer.</p></li>
<li><p>If you use <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html#torch.optim.LBFGS" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.LBFGS</span></code></a>, Lightning handles the closure function automatically for you.</p></li>
<li><p>If you use multiple optimizers, you will have to switch to ‘manual optimization’ mode and step them
yourself.</p></li>
<li><p>If you need to control how often the optimizer steps, override the <a class="reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step" title="lightning.pytorch.core.LightningModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a> hook.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.forward"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.forward" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Same as <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward" title="(PyTorch v2.0에서)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.forward.params.*args"></span><strong>*args</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.forward.params.*args">¶</a> – Whatever you decide to pass into the forward method.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.forward.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.forward.params.**kwargs">¶</a> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.freeze"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.freeze" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.load_from_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.load_from_checkpoint"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint
it stores the arguments passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.load_from_checkpoint.params.checkpoint_path"></span><strong>checkpoint_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint.params.checkpoint_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.IO" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">IO</span></code></a>]) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.load_from_checkpoint.params.map_location"></span><strong>map_location</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint.params.map_location">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(PyTorch v2.0에서)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.load_from_checkpoint.params.hparams_file"></span><strong>hparams_file</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint.params.hparams_file">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a> and passed into your
<a class="reference internal" href="#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <a class="reference external" href="https://docs.python.org/3/library/argparse.html#argparse.Namespace" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code></a>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>.</p>
</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.load_from_checkpoint.params.strict"></span><strong>strict</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint.params.strict">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.load_from_checkpoint.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.load_from_checkpoint.params.**kwargs">¶</a> – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Self</span></code></p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p><a class="reference internal" href="#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> instance with loaded weights and hyperparameters (if available).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <a class="reference internal" href="#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>
<strong>class</strong> to call it instead of the <a class="reference internal" href="#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> instance.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.log"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.log" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <a class="reference internal" href="../extensions/logging.html#automatic-logging"><span class="std std-ref">Automatic Logging</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.name"></span><strong>name</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.name">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>) – key to log.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.value"></span><strong>value</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.value">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/pages/implement.html#torchmetrics.Metric" title="(PyTorch-Metrics v1.0.1에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.prog_bar"></span><strong>prog_bar</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.prog_bar">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.logger"></span><strong>logger</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.logger">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.on_step"></span><strong>on_step</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.on_step">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <a class="reference internal" href="../extensions/logging.html#automatic-logging"><span class="std std-ref">Automatic Logging</span></a> for details.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.on_epoch"></span><strong>on_epoch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.on_epoch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <a class="reference internal" href="../extensions/logging.html#automatic-logging"><span class="std std-ref">Automatic Logging</span></a> for details.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.reduce_fx"></span><strong>reduce_fx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.reduce_fx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.enable_graph"></span><strong>enable_graph</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.enable_graph">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.sync_dist"></span><strong>sync_dist</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.sync_dist">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.sync_dist_group"></span><strong>sync_dist_group</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.sync_dist_group">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – the DDP group to sync across.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.add_dataloader_idx"></span><strong>add_dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.add_dataloader_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.batch_size">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.metric_attribute"></span><strong>metric_attribute</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.metric_attribute">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – To restore the metric state, Lightning requires the reference of the
<a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/pages/implement.html#torchmetrics.Metric" title="(PyTorch-Metrics v1.0.1에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code></a> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log.params.rank_zero_only"></span><strong>rank_zero_only</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log.params.rank_zero_only">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.log_dict"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.log_dict" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.dictionary"></span><strong>dictionary</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.dictionary">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Mapping" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/pages/implement.html#torchmetrics.Metric" title="(PyTorch-Metrics v1.0.1에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]) – key value pairs.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.prog_bar"></span><strong>prog_bar</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.prog_bar">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.logger"></span><strong>logger</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.logger">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.on_step"></span><strong>on_step</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.on_step">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <a class="reference internal" href="../extensions/logging.html#automatic-logging"><span class="std std-ref">Automatic Logging</span></a> for details.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.on_epoch"></span><strong>on_epoch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.on_epoch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <a class="reference internal" href="../extensions/logging.html#automatic-logging"><span class="std std-ref">Automatic Logging</span></a> for details.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.reduce_fx"></span><strong>reduce_fx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.reduce_fx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>]) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.enable_graph"></span><strong>enable_graph</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.enable_graph">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.sync_dist"></span><strong>sync_dist</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.sync_dist">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.sync_dist_group"></span><strong>sync_dist_group</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.sync_dist_group">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – the ddp group to sync across.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.add_dataloader_idx"></span><strong>add_dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.add_dataloader_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.batch_size">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.log_dict.params.rank_zero_only"></span><strong>rank_zero_only</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.log_dict.params.rank_zero_only">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether the value will be logged only on rank 0. This will prevent synchronization which
would produce a deadlock as not all processes would perform this log call.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.lr_scheduler_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.lr_scheduler_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Override this method to adjust the default way the
<a class="reference internal" href="lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></a> calls each scheduler.
By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example
for each scheduler based on its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.lr_scheduler_step.params.scheduler"></span><strong>scheduler</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.lr_scheduler_step.params.scheduler">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code></a>]) – Learning rate scheduler.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.lr_scheduler_step.params.metric"></span><strong>metric</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.lr_scheduler_step.params.metric">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.lr_schedulers"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.lr_schedulers" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual
optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">LRScheduler</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <a class="reference internal" href="#lightning.pytorch.core.LightningModule.configure_optimizers" title="lightning.pytorch.core.LightningModule.configure_optimizers"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code></a>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.manual_backward"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.manual_backward" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#lightning.pytorch.core.LightningModule.training_step" title="lightning.pytorch.core.LightningModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <a class="reference internal" href="../common/optimization.html#id2"><span class="std std-ref">manual optimization</span></a> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.manual_backward.params.loss"></span><strong>loss</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.manual_backward.params.loss">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.manual_backward.params.*args"></span><strong>*args</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.manual_backward.params.*args">¶</a> – Additional positional arguments to be forwarded to <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="(PyTorch v2.0에서)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></a></p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.manual_backward.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.manual_backward.params.**kwargs">¶</a> – Additional keyword arguments to be forwarded to <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="(PyTorch v2.0에서)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></a></p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.optimizer_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.optimizer_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Override this method to adjust the default way the <a class="reference internal" href="lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></a>
calls the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_step.params.epoch"></span><strong>epoch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step.params.epoch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Current epoch</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_step.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step.params.batch_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Index of current batch</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_step.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step.params.optimizer">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a>]) – A PyTorch optimizer</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_step.params.optimizer_closure"></span><strong>optimizer_closure</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_step.params.optimizer_closure">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]]) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

<span class="c1"># Learning rate warm-up</span>
<span class="k">def</span> <span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># update params</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># manually warm up lr without a scheduler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">:</span>
        <span class="n">lr_scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">500.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pg</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_scale</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.optimizer_zero_grad"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.optimizer_zero_grad" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.epoch"></span><strong>epoch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.epoch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Current epoch</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.batch_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Index of current batch</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizer_zero_grad.params.optimizer">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>) – A PyTorch optimizer</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span> <span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad" title="(PyTorch v2.0에서)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code></a> for the explanation of the above example.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><span class="pre">lightning.pytorch.core.optimizer.LightningOptimizer</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><span class="pre">lightning.pytorch.core.optimizer.LightningOptimizer</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.optimizers"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.optimizers" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><span class="pre">Literal</span></a><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><span class="pre">bool</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><span class="pre">lightning.pytorch.core.optimizer.LightningOptimizer</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning.fabric.wrappers._FabricOptimizer</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><span class="pre">lightning.pytorch.core.optimizer.LightningOptimizer</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><span class="pre">lightning.fabric.wrappers._FabricOptimizer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><p><span class="target" id="lightning.pytorch.core.LightningModule.optimizers.params.use_pl_optimizer"></span><strong>use_pl_optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.optimizers.params.use_pl_optimizer">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a> for automatic handling of precision and
profiling.</p>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_FabricOptimizer</span></code>]]</p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.predict_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.predict_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Step function called during <a class="reference internal" href="lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.predict" title="lightning.pytorch.trainer.trainer.Trainer.predict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></a>. By default, it
calls <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code>. Override to add any processing logic.</p>
<p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_step()</span></code> is used
to scale inference on multi-devices.</p>
<p>To prevent an OOM error, it is possible to use <a class="reference internal" href="lightning.pytorch.callbacks.BasePredictionWriter.html#lightning.pytorch.callbacks.BasePredictionWriter" title="lightning.pytorch.callbacks.BasePredictionWriter"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasePredictionWriter</span></code></a>
callback to write the predictions to disk or database after each batch or on epoch end.</p>
<p>The <a class="reference internal" href="lightning.pytorch.callbacks.BasePredictionWriter.html#lightning.pytorch.callbacks.BasePredictionWriter" title="lightning.pytorch.callbacks.BasePredictionWriter"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasePredictionWriter</span></code></a> should be used while using a spawn
based accelerator. This happens for <code class="docutils literal notranslate"><span class="pre">Trainer(strategy=&quot;ddp_spawn&quot;)</span></code>
or training on 8 TPU cores with <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator=&quot;tpu&quot;,</span> <span class="pre">devices=8)</span></code> as predictions won’t be returned.</p>
<p>Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="n">dm</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.predict_step.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.predict_step.params.batch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>) – Current batch.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.predict_step.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.predict_step.params.batch_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Index of current batch.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.predict_step.params.dataloader_idx"></span><strong>dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.predict_step.params.dataloader_idx">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Index of the current dataloader.</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p>Predicted output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.print"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.print" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.print.params.*args"></span><strong>*args</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.print.params.*args">¶</a> – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.print.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.print.params.**kwargs">¶</a> – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.test_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.test_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.test_step.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.test_step.params.batch">¶</a> – The output of your <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a>.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.test_step.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.test_step.params.batch_idx">¶</a> – The index of this batch.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.test_step.params.dataloader_id"></span><strong>dataloader_id</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.test_step.params.dataloader_id">¶</a> – The index of the dataloader that produced this batch.
(only if multiple test dataloaders used).</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p><p>Any of.</p>
<blockquote>
<div><ul class="simple">
<li><p>Any object or value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Testing will skip to the next batch</p></li>
</ul>
</div></blockquote>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>


<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#lightning.pytorch.core.LightningModule.test_step" title="lightning.pytorch.core.LightningModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>When the <a class="reference internal" href="#lightning.pytorch.core.LightningModule.test_step" title="lightning.pytorch.core.LightningModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.to_onnx"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.to_onnx" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_onnx.params.file_path"></span><strong>file_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_onnx.params.file_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></a>]) – The path of the file the onnx model should be saved to.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_onnx.params.input_sample"></span><strong>input_sample</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_onnx.params.input_sample">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_onnx.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_onnx.params.**kwargs">¶</a> – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.to_torchscript"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.to_torchscript" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>By default compiles the whole model to a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code></a>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <cite>example_inputs</cite> argument is
provided, or the model has <a class="reference internal" href="#lightning.pytorch.core.LightningModule.example_input_array" title="lightning.pytorch.core.LightningModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that
are scripted you should override this method. In case you want to return multiple modules, we recommend
using a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_torchscript.params.file_path"></span><strong>file_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_torchscript.params.file_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_torchscript.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_torchscript.params.method">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_torchscript.params.example_inputs"></span><strong>example_inputs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_torchscript.params.example_inputs">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#lightning.pytorch.core.LightningModule.example_input_array" title="lightning.pytorch.core.LightningModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.to_torchscript.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.to_torchscript.params.**kwargs">¶</a> – Additional arguments that will be passed to the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script" title="(PyTorch v2.0에서)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code></a> or
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace" title="(PyTorch v2.0에서)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code></a> function.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">참고</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <a class="reference external" href="https://pytorch.org/docs/stable/jit.html#module-torch.jit" title="(PyTorch v2.0에서)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code></a>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code>]]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>This LightningModule as a torchscript, regardless of whether <cite>file_path</cite> is
defined or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.toggle_optimizer"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.toggle_optimizer" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step
to prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#lightning.pytorch.core.LightningModule.untoggle_optimizer" title="lightning.pytorch.core.LightningModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><p><span class="target" id="lightning.pytorch.core.LightningModule.toggle_optimizer.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.toggle_optimizer.params.optimizer">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a>]) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.training_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.training_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or
logger.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.training_step.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.training_step.params.batch">¶</a> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> | (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, …) | [<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, …]) – The output of your <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a>. A tensor, tuple or list.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.training_step.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.training_step.params.batch_idx">¶</a> (<code class="docutils literal notranslate"><span class="pre">int</span></code>) – Integer displaying index of this batch</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]]</p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p><p>Any of.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code></p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">None</span></code> - Training will skip to the next batch. This is only for automatic optimization.</dt><dd><p>This is not supported for multi-GPU, TPU, IPU, or DeepSpeed.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<p>In this step you’d normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>To use multiple optimizers, you can switch to ‘manual optimization’ and control their stepping:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">opt1</span><span class="p">,</span> <span class="n">opt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>

    <span class="c1"># do training_step with encoder</span>
    <span class="o">...</span>
    <span class="n">opt1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># do training_step with decoder</span>
    <span class="o">...</span>
    <span class="n">opt2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>When <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> &gt; 1, the loss returned here will be automatically
normalized by <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> internally.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.unfreeze"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.unfreeze" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.untoggle_optimizer"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.untoggle_optimizer" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#lightning.pytorch.core.LightningModule.toggle_optimizer" title="lightning.pytorch.core.LightningModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><p><span class="target" id="lightning.pytorch.core.LightningModule.untoggle_optimizer.params.optimizer"></span><strong>optimizer</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.untoggle_optimizer.params.optimizer">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a>, <a class="reference internal" href="lightning.pytorch.core.optimizer.LightningOptimizer.html#lightning.pytorch.core.optimizer.LightningOptimizer" title="lightning.pytorch.core.optimizer.LightningOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code></a>]) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/core/module.html#LightningModule.validation_step"><span class="viewcode-link"><span class="pre">[소스]</span></span></a><a class="headerlink" href="#lightning.pytorch.core.LightningModule.validation_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Operates on a single batch of data from the validation set. In this step you’d might generate examples
or calculate anything of interest like accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.validation_step.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.validation_step.params.batch">¶</a> – The output of your <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a>.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.validation_step.params.batch_idx"></span><strong>batch_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.validation_step.params.batch_idx">¶</a> – The index of this batch.</p></li>
<li><p><span class="target" id="lightning.pytorch.core.LightningModule.validation_step.params.dataloader_idx"></span><strong>dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.core.LightningModule.validation_step.params.dataloader_idx">¶</a> – The index of the dataloader that produced this batch.
(only if multiple val dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">반환 형식</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</p>
</dd>
<dt class="field-odd">반환</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>Any object or value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Validation will skip to the next batch</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one val dataloader:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>


<span class="c1"># if you have multiple val dataloaders:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single validation dataset</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple val dataloaders, <a class="reference internal" href="#lightning.pytorch.core.LightningModule.validation_step" title="lightning.pytorch.core.LightningModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple validation dataloaders</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>If you don’t need to validate you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>When the <a class="reference internal" href="#lightning.pytorch.core.LightningModule.validation_step" title="lightning.pytorch.core.LightningModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> is called, the model has been put in eval mode
and PyTorch gradients have been disabled. At the end of validation,
the model goes back to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.automatic_optimization">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><span class="pre">bool</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.automatic_optimization" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.current_epoch">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><span class="pre">int</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.current_epoch" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.example_input_array">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><span class="pre">torch.Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.example_input_array" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#lightning.pytorch.core.LightningModule.forward" title="lightning.pytorch.core.LightningModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method.
The return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.global_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><span class="pre">int</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.global_rank" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.global_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><span class="pre">int</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.global_step" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this propery is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.local_rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><span class="pre">int</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.local_rank" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.logger">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><span class="pre">lightning.pytorch.loggers.logger.Logger</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">lightning.fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.logger" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.loggers">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><span class="pre">lightning.pytorch.loggers.logger.Logger</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">lightning.fabric.loggers.logger.Logger</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.loggers" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference internal" href="lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lightning.pytorch.core.LightningModule.on_gpu">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><span class="pre">bool</span></a></em><a class="headerlink" href="#lightning.pytorch.core.LightningModule.on_gpu" title="이 정의에 대한 퍼머링크">¶</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lightning.pytorch.core.mixins.HyperparametersMixin.html" class="btn btn-neutral float-right" title="HyperparametersMixin" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="lightning.pytorch.core.LightningDataModule.html" class="btn btn-neutral" title="LightningDataModule" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2018-2023, Lightning AI et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">LightningModule</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Click to show';</script>
         <script>let toggleHintHide = 'Click to hide';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script src="../_static/translations.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Best practices', 'Optional Extensions', 'Tutorials', 'API References', 'Bolts', 'Examples', 'Partner Domain Frameworks', 'Community'];
</script>



  <!-- Begin Footer -->

  <!-- <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources"> -->
    <!-- <div class="container"> -->
      <!-- <div class="row"> -->
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/#community-examples">View Resources</a>
        </div>
        -->
      <!-- </div> -->
    <!-- </div> -->
  <!-- </div> -->

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://lightning.ai/docs/pytorch/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning.ai/docs/pytorch/latest/">PyTorch</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://lightning.ai/pages/blog/">Blog</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning.ai/docs/pytorch/latest/#community-examples">Resources</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/">Docs</a></li>
            <li><a href="https://www.pytorchlightning.ai/community" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/LightningAI" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://lightning.ai/docs/pytorch/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://lightning.ai/pages/blog/">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning.ai/docs/pytorch/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Lightning Fabric</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Fabric</a>
            </li>
          </ul> -->

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning.ai/docs/pytorch/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/pytorch/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="https://www.pytorchlightning.ai/community">Community</a>
            </li>

            <li>
              <a href="https://lightning.ai/forums/">Forums</a>
            </li>
          </ul>-->

          <li>
            <a href="https://www.lightning.ai/">Lightning.ai</a>
          </li>

          <li>
            <a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">파이토치 한국어 커뮤니티</a>
          </li>

        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5SCNQBF5"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
 </body>
</html>