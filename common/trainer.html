


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ko" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ko" > <!--<![endif]-->
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5SCNQBF5');
  </script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="google-site-verification" content="okUst94cAlWSsUsGZTB4xSS4UKTtRV8Nu5XZ9pdd3Aw" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Trainer &mdash; PyTorch Lightning &amp; PyTorch Korea User Group 2.0.5 문서</title>
  

  
  
    <link rel="shortcut icon" href="../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://lightning.ai/docs/pytorch/stable//common/trainer.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/main.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />
    <link rel="next" title="accelerators" href="../api_references.html" />
    <link rel="prev" title="LightningModule" href="lightning_module.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-82W25RV60Q"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-82W25RV60Q');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>

  <script src="https://unpkg.com/react@18/umd/react.development.js" crossorigin></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js" crossorigin></script>
  <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>
  <script src="../_static/js/react/react.jsx" type="text/babel"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://lightning.ai/docs/pytorch/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://lightning.ai/pages/blog/">Blog</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/pytorch/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/fabric/stable/">
                  <span class="dropdown-title">Lightning Fabric</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li> -->

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://www.pytorchlightning.ai/community">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://lightning.ai/docs/pytorch/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://lightning.ai/forums/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <!-- 
          <li>
            <a href="https://lightning.ai/docs/pytorch/latest/past_versions.html">Previous Versions</a>
          </li>
          

          <li>
            <a href="https://github.com/Lightning-AI/lightning">GitHub</a>
          </li> -->

          <li>
            <a href="https://www.lightning.ai/">Lightning AI</a>
          </li>

          <li>
            <a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">파이토치 한국어 커뮤니티</a>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  2.0.5
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Home</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../starter/introduction.html">Lightning in 15 minutes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/installation.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../upgrade/migration_guide.html">Guide how to upgrade to the 2.0 version</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Level Up</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../levels/core_skills.html">Basic skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/intermediate.html">Intermediate skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/advanced.html">Advanced skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/expert.html">Expert skills</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lightning_module.html">LightningModule</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optional API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html">accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#callbacks">callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#cli">cli</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#core">core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#loggers">loggers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#profiler">profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#trainer">trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#strategies">strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#tuner">tuner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_references.html#utilities">utilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary/index.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">How-to Guides</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Trainer</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/common/trainer.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="trainer">
<span id="id1"></span><h1>Trainer<a class="headerlink" href="#trainer" title="이 표제에 대한 퍼머링크">¶</a></h1>
<p>Once you’ve organized your PyTorch code into a <a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>, the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> automates everything else.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> achieves the following:</p>
<ol class="arabic simple">
<li><p>You maintain control over all aspects via PyTorch code in your <a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>.</p></li>
<li><p>The trainer uses best practices embedded by contributors and users
from top AI labs such as Facebook AI Research, NYU, MIT, Stanford, etc…</p></li>
<li><p>The trainer allows disabling any key part that you don’t want automated.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
</div>
<hr class="docutils" />
<section id="basic-use">
<h2>Basic use<a class="headerlink" href="#basic-use" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>This is the basic use of the trainer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">()</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">val_dataloader</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="under-the-hood">
<h2>Under the hood<a class="headerlink" href="#under-the-hood" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>The Lightning <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> does much more than just “training”. Under the hood, it handles all loop details for you, some examples include:</p>
<ul class="simple">
<li><p>Automatically enabling/disabling grads</p></li>
<li><p>Running the training, validation and test dataloaders</p></li>
<li><p>Calling the Callbacks at the appropriate times</p></li>
<li><p>Putting batches and computations on the correct devices</p></li>
</ul>
<p>Here’s the pseudocode for what the trainer does under the hood (showing the train loop only)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># put model in train mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
    <span class="c1"># calls hooks like this one</span>
    <span class="n">on_train_batch_start</span><span class="p">()</span>

    <span class="c1"># train step</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

    <span class="c1"># clear gradients</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># backward</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># update parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="trainer-in-python-scripts">
<h2>Trainer in Python scripts<a class="headerlink" href="#trainer-in-python-scripts" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>In Python scripts, it’s recommended you use a main function to call the Trainer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">ArgumentParser</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">hparams</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LightningModule</span><span class="p">()</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--accelerator&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--devices&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<p>So you can run it like so:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>main.py<span class="w"> </span>--accelerator<span class="w"> </span><span class="s1">&#39;gpu&#39;</span><span class="w"> </span>--devices<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>Pro-tip: You don’t need to define all flags manually.
You can let the <a class="reference internal" href="../cli/lightning_cli.html"><span class="doc">LightningCLI</span></a> create the Trainer and model with arguments supplied from the CLI.</p>
</div>
<p>If you want to stop a training run early, you can press “Ctrl + C” on your keyboard.
The trainer will catch the <code class="docutils literal notranslate"><span class="pre">KeyboardInterrupt</span></code> and attempt a graceful shutdown. The trainer object will also set
an attribute <code class="docutils literal notranslate"><span class="pre">interrupted</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> in such cases. If you have a callback which shuts down compute
resources, for example, you can conditionally run the shutdown logic for only uninterrupted runs by overriding <code class="xref py py-meth docutils literal notranslate"><span class="pre">lightning.pytorch.Callback.on_exception()</span></code>.</p>
</section>
<hr class="docutils" />
<section id="validation">
<h2>Validation<a class="headerlink" href="#validation" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>You can perform an evaluation epoch over the validation set, outside of the training loop,
using <a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.validate" title="lightning.pytorch.trainer.trainer.Trainer.validate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></a>. This might be
useful if you want to collect new metrics from a model right at its initialization
or after it has already been trained.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">val_dataloaders</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>Once you’re done training, feel free to run the test set!
(Only right before publishing your paper or pushing to production)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">test_dataloaders</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="reproducibility">
<h2>Reproducibility<a class="headerlink" href="#reproducibility" title="이 표제에 대한 퍼머링크">¶</a></h2>
<p>To ensure full reproducibility from run to run you need to set seeds for pseudo-random generators,
and set <code class="docutils literal notranslate"><span class="pre">deterministic</span></code> flag in <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">seed_everything</span>

<span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># sets seeds for numpy, torch and python.random.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>By setting <code class="docutils literal notranslate"><span class="pre">workers=True</span></code> in <code class="xref py py-func docutils literal notranslate"><span class="pre">seed_everything()</span></code>, Lightning derives
unique seeds across all dataloader workers and processes for <a class="reference external" href="https://pytorch.org/docs/stable/torch.html#module-torch" title="(PyTorch v2.0에서)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/index.html#module-numpy" title="(NumPy v1.25에서)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy</span></code></a> and stdlib
<a class="reference external" href="https://docs.python.org/3/library/random.html#module-random" title="(Python v3.11에서)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">random</span></code></a> number generators. When turned on, it ensures that e.g. data augmentations are not repeated across workers.</p>
<hr class="docutils" />
</section>
<section id="trainer-flags">
<span id="id2"></span><h2>Trainer flags<a class="headerlink" href="#trainer-flags" title="이 표제에 대한 퍼머링크">¶</a></h2>
<section id="accelerator">
<h3>accelerator<a class="headerlink" href="#accelerator" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Supports passing different accelerator types (<code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;,</span> <span class="pre">&quot;gpu&quot;,</span> <span class="pre">&quot;tpu&quot;,</span> <span class="pre">&quot;ipu&quot;,</span> <span class="pre">&quot;auto&quot;</span></code>)
as well as custom accelerator instances.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CPU accelerator</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with GPU Accelerator using 2 GPUs</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with TPU Accelerator using 8 tpu cores</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;tpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with GPU Accelerator using the DistributedDataParallel strategy</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;ddp&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> option recognizes the machine you are on, and selects the appropriate <code class="docutils literal notranslate"><span class="pre">Accelerator</span></code>.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># If your machine has GPUs, it will use the GPU Accelerator for training</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also modify hardware behavior by subclassing an existing accelerator to adjust for your needs.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyOwnAcc</span><span class="p">(</span><span class="n">CPUAccelerator</span><span class="p">):</span>
    <span class="o">...</span>

<span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="n">MyOwnAcc</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">devices</span></code> flag is not defined, it will assume <code class="docutils literal notranslate"><span class="pre">devices</span></code> to be <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> and fetch the <code class="docutils literal notranslate"><span class="pre">auto_device_count</span></code>
from the accelerator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is part of the built-in `CUDAAccelerator`</span>
<span class="k">class</span> <span class="nc">CUDAAccelerator</span><span class="p">(</span><span class="n">Accelerator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Accelerator for GPU devices.&quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">auto_device_count</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the devices when set to auto.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>


<span class="c1"># Training with GPU Accelerator using total number of gpus available on the system</span>
<span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="accumulate-grad-batches">
<h3>accumulate_grad_batches<a class="headerlink" href="#accumulate-grad-batches" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Accumulates gradients over k batches before stepping the optimizer.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer (no accumulation)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accumulate_grad_batches</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># accumulate every 4 batches (effective batch size is batch*4)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accumulate_grad_batches</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>See also: <a class="reference internal" href="optimization.html#id3"><span class="std std-ref">Gradient Accumulation</span></a> to enable more fine-grained accumulation schedules.</p>
</section>
<section id="benchmark">
<h3>benchmark<a class="headerlink" href="#benchmark" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/benchmark.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/benchmark.mp4" type="video/mp4"></video><p>The value (<code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>) to set <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.benchmark</span></code> to. The value for
<code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.benchmark</span></code> set in the current session will be used (<code class="docutils literal notranslate"><span class="pre">False</span></code> if not manually set).
If <code class="xref py py-paramref docutils literal notranslate"><span class="pre">deterministic</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this will default to <code class="docutils literal notranslate"><span class="pre">False</span></code>.
You can read more about the interaction of <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.benchmark</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span></code>
<a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking">here</a></p>
<p>Setting this flag to <code class="docutils literal notranslate"><span class="pre">True</span></code> can increase the speed of your system if your input sizes don’t
change. However, if they do, then it might make your system slower. The CUDNN auto-tuner will try to find the best
algorithm for the hardware when a new input size is encountered. This might also increase the memory usage.
Read more about it <a class="reference external" href="https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936">here</a>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Will use whatever the current value for torch.backends.cudnn.benchmark, normally False</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">benchmark</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># default</span>

<span class="c1"># you can overwrite the value</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">benchmark</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="deterministic">
<h3>deterministic<a class="headerlink" href="#deterministic" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/deterministic.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/deterministic.mp4" type="video/mp4"></video><p>This flag sets the <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span></code> flag.
Might make your system slower, but ensures reproducibility.</p>
<p>For more info check <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch docs</a>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="callbacks">
<h3>callbacks<a class="headerlink" href="#callbacks" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>This argument can be used to add a <a class="reference internal" href="../api/lightning.pytorch.callbacks.Callback.html#lightning.pytorch.callbacks.Callback" title="lightning.pytorch.callbacks.callback.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></a> or a list of them.
Callbacks run sequentially in the order defined here
with the exception of <a class="reference internal" href="../api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> callbacks which run
after all others to ensure all states are saved to the checkpoints.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># single callback</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="n">PrintCallback</span><span class="p">())</span>

<span class="c1"># a list of callbacks</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">PrintCallback</span><span class="p">()])</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="k">class</span> <span class="nc">PrintCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_train_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training is started!&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training is done.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Model-specific callbacks can also be added inside the <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> through
<code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_callbacks()</span></code>.
Callbacks returned in this hook will extend the list initially given to the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> argument, and replace
the trainer callbacks should there be two or more of the same type.
<a class="reference internal" href="../api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> callbacks always run last.</p>
</section>
<section id="check-val-every-n-epoch">
<h3>check_val_every_n_epoch<a class="headerlink" href="#check-val-every-n-epoch" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/check_val_every_n_epoch.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/check_val_every_n_epoch.mp4" type="video/mp4"></video><p>Check val every n train epochs.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># run val loop every 10 training epochs</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="default-root-dir">
<h3>default_root_dir<a class="headerlink" href="#default-root-dir" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/default%E2%80%A8_root_dir.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/default_root_dir.mp4" type="video/mp4"></video><p>Default path for logs and weights when no logger or
<a class="reference internal" href="../api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">lightning.pytorch.callbacks.ModelCheckpoint</span></code></a> callback passed.  On
certain clusters you might want to separate where logs and checkpoints are
stored. If you don’t then use this argument for convenience. Paths can be local
paths or remote paths such as <code class="docutils literal notranslate"><span class="pre">s3://bucket/path</span></code> or <code class="docutils literal notranslate"><span class="pre">hdfs://path/</span></code>. Credentials
will need to be set up to use remote filepaths.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">default_root_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="devices">
<h3>devices<a class="headerlink" href="#devices" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Number of devices to train on (<code class="docutils literal notranslate"><span class="pre">int</span></code>), which devices to train on (<code class="docutils literal notranslate"><span class="pre">list</span></code> or <code class="docutils literal notranslate"><span class="pre">str</span></code>), or <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training with CPU Accelerator using 2 processes</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with GPU Accelerator using GPUs 1 and 3</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with TPU Accelerator using 8 tpu cores</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;tpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">팁</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> option recognizes the devices to train on, depending on the <code class="docutils literal notranslate"><span class="pre">Accelerator</span></code> being used.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use whatever hardware your machine has available</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="c1"># Training with CPU Accelerator using 1 process</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with TPU Accelerator using 8 tpu cores</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;tpu&quot;</span><span class="p">)</span>

<span class="c1"># Training with IPU Accelerator using 4 ipus</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;ipu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">devices</span></code> flag is not defined, it will assume <code class="docutils literal notranslate"><span class="pre">devices</span></code> to be <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> and fetch the <code class="docutils literal notranslate"><span class="pre">auto_device_count</span></code>
from the accelerator.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is part of the built-in `CUDAAccelerator`</span>
<span class="k">class</span> <span class="nc">CUDAAccelerator</span><span class="p">(</span><span class="n">Accelerator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Accelerator for GPU devices.&quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">auto_device_count</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the devices when set to auto.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>


<span class="c1"># Training with GPU Accelerator using total number of gpus available on the system</span>
<span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="enable-checkpointing">
<h3>enable_checkpointing<a class="headerlink" href="#enable-checkpointing" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>By default Lightning saves a checkpoint for you in your current working directory, with the state of your last training epoch,
Checkpoints capture the exact value of all parameters used by a model.
To disable automatic checkpointing, set this to <cite>False</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by Trainer, saves the most recent model to a single checkpoint after each epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># turn off automatic checkpointing</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>You can override the default behavior by initializing the <a class="reference internal" href="../api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a>
callback, and adding it to the <a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.callbacks" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">callbacks</span></code></a> list.
See <a class="reference internal" href="checkpointing.html"><span class="doc">Saving and Loading Checkpoints</span></a> for how to customize checkpointing.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># Init ModelCheckpoint callback, monitoring &#39;val_loss&#39;</span>
<span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>

<span class="c1"># Add your callback to the callbacks list</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="fast-dev-run">
<h3>fast_dev_run<a class="headerlink" href="#fast-dev-run" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/fast_dev_run.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/fast_dev_run.mp4" type="video/mp4"></video><p>Runs n if set to <code class="docutils literal notranslate"><span class="pre">n</span></code> (int) else 1 if set to <code class="docutils literal notranslate"><span class="pre">True</span></code> batch(es) to ensure your code will execute without errors. This
applies to fitting, validating, testing, and predicting. This flag is <strong>only</strong> recommended for debugging purposes and
should not be used to limit the number of batches to run.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># runs only 1 training and 1 validation batch and the program ends</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="c1"># runs 7 predict batches and program ends</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>This argument is different from <code class="docutils literal notranslate"><span class="pre">limit_{train,val,test,predict}_batches</span></code> because side effects are avoided to reduce the
impact to subsequent runs. These are the changes enabled:</p>
<ul class="simple">
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">Trainer(max_epochs=1)</span></code>.</p></li>
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">Trainer(max_steps=...)</span></code> to 1 or the number passed.</p></li>
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">Trainer(num_sanity_val_steps=0)</span></code>.</p></li>
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">Trainer(val_check_interval=1.0)</span></code>.</p></li>
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">Trainer(check_every_n_epoch=1)</span></code>.</p></li>
<li><p>Disables all loggers.</p></li>
<li><p>Disables passing logged metrics to loggers.</p></li>
<li><p>The <a class="reference internal" href="../api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint" title="lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code></a> callbacks will not trigger.</p></li>
<li><p>The <a class="reference internal" href="../api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.pytorch.callbacks.EarlyStopping" title="lightning.pytorch.callbacks.early_stopping.EarlyStopping"><code class="xref py py-class docutils literal notranslate"><span class="pre">EarlyStopping</span></code></a> callbacks will not trigger.</p></li>
<li><p>Sets <code class="docutils literal notranslate"><span class="pre">limit_{train,val,test,predict}_batches</span></code> to 1 or the number passed.</p></li>
<li><p>Disables the tuning callbacks (<a class="reference internal" href="../api/lightning.pytorch.callbacks.BatchSizeFinder.html#lightning.pytorch.callbacks.BatchSizeFinder" title="lightning.pytorch.callbacks.batch_size_finder.BatchSizeFinder"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchSizeFinder</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.callbacks.LearningRateFinder.html#lightning.pytorch.callbacks.LearningRateFinder" title="lightning.pytorch.callbacks.lr_finder.LearningRateFinder"><code class="xref py py-class docutils literal notranslate"><span class="pre">LearningRateFinder</span></code></a>).</p></li>
<li><p>If using the CLI, the configuration file is not saved.</p></li>
</ul>
</section>
<section id="gradient-clip-val">
<h3>gradient_clip_val<a class="headerlink" href="#gradient-clip-val" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/gradient+_clip_val.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/gradient_clip_val.mp4" type="video/mp4"></video><p>Gradient clipping value</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">gradient_clip_val</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="limit-train-batches">
<h3>limit_train_batches<a class="headerlink" href="#limit-train-batches" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/limit_train_batches.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/limit_batches.mp4" type="video/mp4"></video><p>How much of training dataset to check.
Useful when debugging or testing something that happens at the end of an epoch.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># run through only 25% of the training set each epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># run through only 10 batches of the training set each epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="limit-test-batches">
<h3>limit_test_batches<a class="headerlink" href="#limit-test-batches" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/limit_test_batches.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/limit_batches.mp4" type="video/mp4"></video><p>How much of test dataset to check.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_test_batches</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># run through only 25% of the test set each epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_test_batches</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># run for only 10 batches</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_test_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>In the case of multiple test dataloaders, the limit applies to each dataloader individually.</p>
</section>
<section id="limit-val-batches">
<h3>limit_val_batches<a class="headerlink" href="#limit-val-batches" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/limit_val_batches.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/limit_batches.mp4" type="video/mp4"></video><p>How much of validation dataset to check.
Useful when debugging or testing something that happens at the end of an epoch.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_val_batches</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># run through only 25% of the validation set each epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_val_batches</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># run for only 10 batches</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_val_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># disable validation</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_val_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>In the case of multiple validation dataloaders, the limit applies to each dataloader individually.</p>
</section>
<section id="log-every-n-steps">
<h3>log_every_n_steps<a class="headerlink" href="#log-every-n-steps" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/log_every_n_steps.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/log_every_n_steps.mp4" type="video/mp4"></video><p>How often to add logging rows (does not write to disk)</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>See Also:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../extensions/logging.html"><span class="doc">logging</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="logger">
<h3>logger<a class="headerlink" href="#logger" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p><a class="reference internal" href="../visualize/loggers.html"><span class="doc">Logger</span></a> (or iterable collection of loggers) for experiment tracking. A <code class="docutils literal notranslate"><span class="pre">True</span></code> value uses the default <code class="docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code> shown below. <code class="docutils literal notranslate"><span class="pre">False</span></code> will disable logging.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.loggers</span> <span class="kn">import</span> <span class="n">TensorBoardLogger</span>

<span class="c1"># default logger used by trainer (if tensorboard is installed)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">TensorBoardLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lightning_logs&quot;</span><span class="p">)</span>
<span class="n">Trainer</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="max-epochs">
<h3>max_epochs<a class="headerlink" href="#max-epochs" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/max_epochs.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/min_max_epochs.mp4" type="video/mp4"></video><p>Stop training once this number of epochs is reached</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>If both <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> and <code class="docutils literal notranslate"><span class="pre">max_steps</span></code> aren’t specified, <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> will default to <code class="docutils literal notranslate"><span class="pre">1000</span></code>.
To enable infinite training, set <code class="docutils literal notranslate"><span class="pre">max_epochs</span> <span class="pre">=</span> <span class="pre">-1</span></code>.</p>
</section>
<section id="min-epochs">
<h3>min_epochs<a class="headerlink" href="#min-epochs" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/min_epochs.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/min_max_epochs.mp4" type="video/mp4"></video><p>Force training for at least these many epochs</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="max-steps">
<h3>max_steps<a class="headerlink" href="#max-steps" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/max_steps.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/min_max_steps.mp4" type="video/mp4"></video><p>Stop training after this number of <a class="reference internal" href="#global-step"><span class="std std-ref">global steps</span></a>.
Training will stop if max_steps or max_epochs have reached (earliest).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Default (disabled)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Stop after 100 steps</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">max_steps</span></code> is not specified, <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> will be used instead (and <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> defaults to
<code class="docutils literal notranslate"><span class="pre">1000</span></code> if <code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> is not specified). To disable this default, set <code class="docutils literal notranslate"><span class="pre">max_steps</span> <span class="pre">=</span> <span class="pre">-1</span></code>.</p>
</section>
<section id="min-steps">
<h3>min_steps<a class="headerlink" href="#min-steps" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/min_steps.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/min_max_steps.mp4" type="video/mp4"></video><p>Force training for at least this number of <a class="reference internal" href="#global-step"><span class="std std-ref">global steps</span></a>.
Trainer will train model for at least min_steps or min_epochs (latest).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Default (disabled)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Run at least for 100 steps (disable min_epochs)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">min_epochs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="max-time">
<h3>max_time<a class="headerlink" href="#max-time" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Set the maximum amount of time for training. Training will get interrupted mid-epoch.
For customizable options use the <a class="reference internal" href="../api/lightning.pytorch.callbacks.Timer.html#lightning.pytorch.callbacks.Timer" title="lightning.pytorch.callbacks.timer.Timer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Timer</span></code></a> callback.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Default (disabled)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_time</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Stop after 12 hours of training or when reaching 10 epochs (string)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_time</span><span class="o">=</span><span class="s2">&quot;00:12:00:00&quot;</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Stop after 1 day and 5 hours (dict)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">max_time</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;days&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;hours&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>
</pre></div>
</div>
<p>In case <code class="docutils literal notranslate"><span class="pre">max_time</span></code> is used together with <code class="docutils literal notranslate"><span class="pre">min_steps</span></code> or <code class="docutils literal notranslate"><span class="pre">min_epochs</span></code>, the <code class="docutils literal notranslate"><span class="pre">min_*</span></code> requirement
always has precedence.</p>
</section>
<section id="num-nodes">
<h3>num_nodes<a class="headerlink" href="#num-nodes" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/num_nodes.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/num_nodes.mp4" type="video/mp4"></video><p>Number of GPU nodes for distributed training.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># to train on 8 nodes</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="num-sanity-val-steps">
<h3>num_sanity_val_steps<a class="headerlink" href="#num-sanity-val-steps" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/num_sanity%E2%80%A8_val_steps.jp" preload="auto" width="400"><source src="../_static/fetched-s3-assets/num_sanity_val_steps.mp4" type="video/mp4"></video><p>Sanity check runs n batches of val before starting the training routine.
This catches any bugs in your validation without having to wait for the first validation check.
The Trainer uses 2 steps by default. Turn it off or modify it here.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_sanity_val_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># turn it off</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_sanity_val_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># check all validation data</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_sanity_val_steps</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>This option will reset the validation dataloader unless <code class="docutils literal notranslate"><span class="pre">num_sanity_val_steps=0</span></code>.</p>
</section>
<section id="overfit-batches">
<h3>overfit_batches<a class="headerlink" href="#overfit-batches" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/overfit_batches.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/overfit_batches.mp4" type="video/mp4"></video><p>Uses this much data of the training &amp; validation set.
If the training &amp; validation dataloaders have <code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code>, Lightning will automatically disable it.</p>
<p>Useful for quickly debugging or trying to overfit on purpose.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">overfit_batches</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># use only 1% of the train &amp; val set</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">overfit_batches</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># overfit on 10 of the same batches</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">overfit_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="plugins">
<h3>plugins<a class="headerlink" href="#plugins" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p><a class="reference internal" href="../extensions/plugins.html#plugins"><span class="std std-ref">Plugins</span></a> allow you to connect arbitrary backends, precision libraries, clusters etc. For example:</p>
<ul class="simple">
<li><p><a class="reference internal" href="checkpointing_expert.html#checkpointing-expert"><span class="std std-ref">Checkpoint IO</span></a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/elastic/0.2.2/index.html">TorchElastic</a></p></li>
<li><p><a class="reference internal" href="precision_expert.html#precision-expert"><span class="std std-ref">Precision Plugins</span></a></p></li>
</ul>
<p>To define your own behavior, subclass the relevant class and pass it in. Here’s an example linking up your own
<a class="reference internal" href="../api/lightning.pytorch.plugins.environments.ClusterEnvironment.html#lightning.pytorch.plugins.environments.ClusterEnvironment" title="lightning.pytorch.plugins.environments.ClusterEnvironment"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClusterEnvironment</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.plugins.environments</span> <span class="kn">import</span> <span class="n">ClusterEnvironment</span>


<span class="k">class</span> <span class="nc">MyCluster</span><span class="p">(</span><span class="n">ClusterEnvironment</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">main_address</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">your_main_address</span>

    <span class="k">def</span> <span class="nf">main_port</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">your_main_port</span>

    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">the_world_size</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">plugins</span><span class="o">=</span><span class="p">[</span><span class="n">MyCluster</span><span class="p">()],</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="precision">
<h3>precision<a class="headerlink" href="#precision" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Lightning supports either double (64), float (32), bfloat16 (bf16), or half (16) precision training.</p>
<p>Half precision, or mixed precision, is the combined use of 32 and 16 bit floating points to reduce memory footprint during model training. This can result in improved performance, achieving +3X speedups on modern GPUs.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># 16-bit precision</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="s2">&quot;16-mixed&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># works only on CUDA</span>

<span class="c1"># bfloat16 precision</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="s2">&quot;bf16-mixed&quot;</span><span class="p">)</span>

<span class="c1"># 64-bit precision</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>When running on TPUs, torch.bfloat16 will be used but tensor printing will still show torch.float32.</p>
</div>
</section>
<section id="profiler">
<h3>profiler<a class="headerlink" href="#profiler" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/profiler.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/profiler.mp4" type="video/mp4"></video><p>To profile individual steps during training and assist in identifying bottlenecks.</p>
<p>See the <a class="reference internal" href="../tuning/profiler.html"><span class="doc">profiler documentation</span></a>. for more details.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.profilers</span> <span class="kn">import</span> <span class="n">SimpleProfiler</span><span class="p">,</span> <span class="n">AdvancedProfiler</span>

<span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># to profile standard training events, equivalent to `profiler=SimpleProfiler()`</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="s2">&quot;simple&quot;</span><span class="p">)</span>

<span class="c1"># advanced profiler for function-level stats, equivalent to `profiler=AdvancedProfiler()`</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="s2">&quot;advanced&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="enable-progress-bar">
<h3>enable_progress_bar<a class="headerlink" href="#enable-progress-bar" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Whether to enable or disable the progress bar. Defaults to True.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># disable progress bar</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="reload-dataloaders-every-n-epochs">
<h3>reload_dataloaders_every_n_epochs<a class="headerlink" href="#reload-dataloaders-every-n-epochs" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/reload_%E2%80%A8dataloaders_%E2%80%A8every_epoch.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/reload_dataloaders_every_epoch.mp4" type="video/mp4"></video><p>Set to a positive integer to reload dataloaders every n epochs from your currently used data source.
DataSource can be a <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> or a <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if 0 (default)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="c1"># or if using data module: datamodule.train_dataloader()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="o">...</span>

<span class="c1"># if a positive integer</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">reload_dataloaders_every_n_epochs</span><span class="p">:</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
        <span class="c1"># or if using data module: datamodule.train_dataloader()</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>The pseudocode applies also to the <code class="docutils literal notranslate"><span class="pre">val_dataloader</span></code>.</p>
</section>
<section id="use-distributed-sampler">
<span id="replace-sampler-ddp"></span><h3>use_distributed_sampler<a class="headerlink" href="#use-distributed-sampler" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>See <a class="reference internal" href="#lightning.pytorch.trainer.Trainer.params.use_distributed_sampler" title="lightning.pytorch.trainer.Trainer.params.use_distributed_sampler"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">lightning.pytorch.trainer.Trainer.params.use_distributed_sampler</span></code></a>.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">use_distributed_sampler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>By setting to False, you have to add your own distributed sampler:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in your LightningModule or LightningDataModule</span>
<span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># default used by the Trainer</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataloader</span>
</pre></div>
</div>
</section>
<section id="strategy">
<h3>strategy<a class="headerlink" href="#strategy" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Supports passing different training strategies with aliases (ddp, fsdp, etc) as well as configured strategies.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data-parallel training with the DDP strategy on 4 GPUs</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;ddp&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Model-parallel training with the FSDP strategy on 4 GPUs</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;fsdp&quot;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Additionally, you can pass a strategy object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightning.pytorch.strategies</span> <span class="kn">import</span> <span class="n">DDPStrategy</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="n">DDPStrategy</span><span class="p">(</span><span class="n">static_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>See Also:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="../accelerators/gpu_basic.html#multi-gpu"><span class="std std-ref">Multi GPU Training</span></a>.</p></li>
<li><p><a class="reference internal" href="../advanced/model_parallel.html"><span class="doc">Model Parallel GPU training guide</span></a>.</p></li>
<li><p><a class="reference internal" href="../accelerators/tpu.html"><span class="doc">TPU training guide</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="sync-batchnorm">
<h3>sync_batchnorm<a class="headerlink" href="#sync-batchnorm" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/sync_batchnorm.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/sync_batchnorm.mp4" type="video/mp4"></video><p>Enable synchronization between batchnorm layers across all GPUs.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">sync_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="val-check-interval">
<h3>val_check_interval<a class="headerlink" href="#val-check-interval" title="이 표제에 대한 퍼머링크">¶</a></h3>
<video controls="True" muted="True" poster="../_static/fetched-s3-assets/val_check_interval.jpg" preload="auto" width="400"><source src="../_static/fetched-s3-assets/val_check_interval.mp4" type="video/mp4"></video><p>How often within one training epoch to check the validation set.
Can specify as float or int.</p>
<ul class="simple">
<li><p>pass a <code class="docutils literal notranslate"><span class="pre">float</span></code> in the range [0.0, 1.0] to check after a fraction of the training epoch.</p></li>
<li><p>pass an <code class="docutils literal notranslate"><span class="pre">int</span></code> to check after a fixed number of training batches. An <code class="docutils literal notranslate"><span class="pre">int</span></code> value can only be higher than the number of training
batches when <code class="docutils literal notranslate"><span class="pre">check_val_every_n_epoch=None</span></code>, which validates after every <code class="docutils literal notranslate"><span class="pre">N</span></code> training batches across epochs or iteration-based training.</p></li>
</ul>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">val_check_interval</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># check validation set 4 times during a training epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">val_check_interval</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># check validation set every 1000 training batches in the current epoch</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">val_check_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># check validation set every 1000 training batches across complete epochs or during iteration-based training</span>
<span class="c1"># use this when using iterableDataset and your dataset has no length</span>
<span class="c1"># (ie: production cases with streaming data)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">val_check_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here is the computation to estimate the total number of batches seen within an epoch.</span>

<span class="c1"># Find the total number of train batches</span>
<span class="n">total_train_batches</span> <span class="o">=</span> <span class="n">total_train_samples</span> <span class="o">//</span> <span class="p">(</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">)</span>

<span class="c1"># Compute how many times we will call validation during the training loop</span>
<span class="n">val_check_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_train_batches</span> <span class="o">*</span> <span class="n">val_check_interval</span><span class="p">))</span>
<span class="n">val_checks_per_epoch</span> <span class="o">=</span> <span class="n">total_train_batches</span> <span class="o">/</span> <span class="n">val_check_batch</span>

<span class="c1"># Find the total number of validation batches</span>
<span class="n">total_val_batches</span> <span class="o">=</span> <span class="n">total_val_samples</span> <span class="o">//</span> <span class="p">(</span><span class="n">val_batch_size</span> <span class="o">*</span> <span class="n">world_size</span><span class="p">)</span>

<span class="c1"># Total number of batches run</span>
<span class="n">total_fit_batches</span> <span class="o">=</span> <span class="n">total_train_batches</span> <span class="o">+</span> <span class="n">total_val_batches</span>
</pre></div>
</div>
</section>
<section id="enable-model-summary">
<h3>enable_model_summary<a class="headerlink" href="#enable-model-summary" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Whether to enable or disable the model summarization. Defaults to True.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_model_summary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># disable summarization</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_model_summary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># enable custom summarization</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">ModelSummary</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_model_summary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ModelSummary</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=-</span><span class="mi">1</span><span class="p">)])</span>
</pre></div>
</div>
</section>
<section id="inference-mode">
<h3>inference_mode<a class="headerlink" href="#inference-mode" title="이 표제에 대한 퍼머링크">¶</a></h3>
<p>Whether to use <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.inference_mode()</span></code> or <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.no_grad()</span></code> mode during evaluation
(<code class="docutils literal notranslate"><span class="pre">validate</span></code>/<code class="docutils literal notranslate"><span class="pre">test</span></code>/<code class="docutils literal notranslate"><span class="pre">predict</span></code>)</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default used by the Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">inference_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Use `torch.no_grad` instead</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">inference_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>With <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.inference_mode()</span></code> disabled, you can enable the grad of your model layers if required.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
            <span class="n">grad_preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="n">preds2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">grad_preds</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">inference_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="trainer-class-api">
<h2>Trainer class API<a class="headerlink" href="#trainer-class-api" title="이 표제에 대한 퍼머링크">¶</a></h2>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="이 표제에 대한 퍼머링크">¶</a></h3>
<section id="init">
<h4>init<a class="headerlink" href="#init" title="이 표제에 대한 퍼머링크">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Trainer.</span></span><span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accelerator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">devices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precision</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'32-true'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_dev_run</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limit_train_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limit_val_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limit_test_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">limit_predict_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overfit_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_check_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_val_every_n_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_sanity_val_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_every_n_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_checkpointing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_model_summary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accumulate_grad_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_distributed_sampler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">profiler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detect_anomaly</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">barebones</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plugins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_batchnorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reload_dataloaders_every_n_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_root_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/trainer/trainer.html#Trainer.__init__"><span class="viewcode-link"><span class="pre">[소스]</span></span></a></dt>
<dd><p>Customize every aspect of training via flags.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.accelerator"></span><strong>accelerator</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.accelerator">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.accelerators.Accelerator.html#lightning.pytorch.accelerators.Accelerator" title="lightning.pytorch.accelerators.accelerator.Accelerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">Accelerator</span></code></a>]) – Supports passing different accelerator types (“cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps”, “auto”)
as well as custom accelerator instances.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.strategy"></span><strong>strategy</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.strategy">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.strategies.Strategy.html#lightning.pytorch.strategies.Strategy" title="lightning.pytorch.strategies.strategy.Strategy"><code class="xref py py-class docutils literal notranslate"><span class="pre">Strategy</span></code></a>]) – Supports different training strategies with aliases as well custom strategies.
Default: <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.devices"></span><strong>devices</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.devices">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – The devices to use. Can be set to a positive number (int or str), a sequence of device indices
(list or str), the value <code class="docutils literal notranslate"><span class="pre">-1</span></code> to indicate all available devices should be used, or <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> for
automatic selection based on the chosen accelerator. Default: <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.num_nodes"></span><strong>num_nodes</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.num_nodes">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Number of GPU nodes for distributed training.
Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.precision"></span><strong>precision</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.precision">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[64, 32, 16], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[‘16-mixed’, ‘bf16-mixed’, ‘32-true’, ‘64-true’], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[‘64’, ‘32’, ‘16’, ‘bf16’]]) – Double precision (64, ‘64’ or ‘64-true’), full precision (32, ‘32’ or ‘32-true’),
16bit mixed precision (16, ‘16’, ‘16-mixed’) or bfloat16 mixed precision (‘bf16’, ‘bf16-mixed’).
Can be used on CPU, GPU, TPUs, HPUs or IPUs.
Default: <code class="docutils literal notranslate"><span class="pre">'32-true'</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.logger"></span><strong>logger</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.logger">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Iterable" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterable</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Logger (or iterable collection of loggers) for experiment tracking. A <code class="docutils literal notranslate"><span class="pre">True</span></code> value uses
the default <code class="docutils literal notranslate"><span class="pre">TensorBoardLogger</span></code> if it is installed, otherwise <code class="docutils literal notranslate"><span class="pre">CSVLogger</span></code>.
<code class="docutils literal notranslate"><span class="pre">False</span></code> will disable logging. If multiple loggers are provided, local files
(checkpoints, profiler traces, etc.) are saved in the <code class="docutils literal notranslate"><span class="pre">log_dir</span></code> of he first logger.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.callbacks"></span><strong>callbacks</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.callbacks">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.callbacks.Callback.html#lightning.pytorch.callbacks.Callback" title="lightning.pytorch.callbacks.callback.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></a>], <a class="reference internal" href="../api/lightning.pytorch.callbacks.Callback.html#lightning.pytorch.callbacks.Callback" title="lightning.pytorch.callbacks.callback.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">Callback</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Add a callback or list of callbacks.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.fast_dev_run"></span><strong>fast_dev_run</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.fast_dev_run">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – Runs n if set to <code class="docutils literal notranslate"><span class="pre">n</span></code> (int) else 1 if set to <code class="docutils literal notranslate"><span class="pre">True</span></code> batch(es)
of train, val and test to find any bugs (ie: a sort of unit test).
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.max_epochs"></span><strong>max_epochs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.max_epochs">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Stop training once this number of epochs is reached. Disabled by default (None).
If both max_epochs and max_steps are not specified, defaults to <code class="docutils literal notranslate"><span class="pre">max_epochs</span> <span class="pre">=</span> <span class="pre">1000</span></code>.
To enable infinite training, set <code class="docutils literal notranslate"><span class="pre">max_epochs</span> <span class="pre">=</span> <span class="pre">-1</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.min_epochs"></span><strong>min_epochs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.min_epochs">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Force training for at least these many epochs. Disabled by default (None).</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.max_steps"></span><strong>max_steps</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.max_steps">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Stop training after this number of steps. Disabled by default (-1). If <code class="docutils literal notranslate"><span class="pre">max_steps</span> <span class="pre">=</span> <span class="pre">-1</span></code>
and <code class="docutils literal notranslate"><span class="pre">max_epochs</span> <span class="pre">=</span> <span class="pre">None</span></code>, will default to <code class="docutils literal notranslate"><span class="pre">max_epochs</span> <span class="pre">=</span> <span class="pre">1000</span></code>. To enable infinite training, set
<code class="docutils literal notranslate"><span class="pre">max_epochs</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.min_steps"></span><strong>min_steps</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.min_steps">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Force training for at least these number of steps. Disabled by default (<code class="docutils literal notranslate"><span class="pre">None</span></code>).</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.max_time"></span><strong>max_time</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.max_time">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/datetime.html#datetime.timedelta" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">timedelta</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Stop training after this amount of time has passed. Disabled by default (<code class="docutils literal notranslate"><span class="pre">None</span></code>).
The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a
<a class="reference external" href="https://docs.python.org/3/library/datetime.html#datetime.timedelta" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">datetime.timedelta</span></code></a>, or a dictionary with keys that will be passed to
<a class="reference external" href="https://docs.python.org/3/library/datetime.html#datetime.timedelta" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">datetime.timedelta</span></code></a>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.limit_train_batches"></span><strong>limit_train_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.limit_train_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – How much of training dataset to check (float = fraction, int = num_batches).
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.limit_val_batches"></span><strong>limit_val_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.limit_val_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – How much of validation dataset to check (float = fraction, int = num_batches).
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.limit_test_batches"></span><strong>limit_test_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.limit_test_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – How much of test dataset to check (float = fraction, int = num_batches).
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.limit_predict_batches"></span><strong>limit_predict_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.limit_predict_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – How much of prediction dataset to check (float = fraction, int = num_batches).
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.overfit_batches"></span><strong>overfit_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.overfit_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]) – Overfit a fraction of training/validation data (float) or a set number of batches (int).
Default: <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.val_check_interval"></span><strong>val_check_interval</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.val_check_interval">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – How often to check the validation set. Pass a <code class="docutils literal notranslate"><span class="pre">float</span></code> in the range [0.0, 1.0] to check
after a fraction of the training epoch. Pass an <code class="docutils literal notranslate"><span class="pre">int</span></code> to check after a fixed number of training
batches. An <code class="docutils literal notranslate"><span class="pre">int</span></code> value can only be higher than the number of training batches when
<code class="docutils literal notranslate"><span class="pre">check_val_every_n_epoch=None</span></code>, which validates after every <code class="docutils literal notranslate"><span class="pre">N</span></code> training batches
across epochs or during iteration-based training.
Default: <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.check_val_every_n_epoch"></span><strong>check_val_every_n_epoch</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.check_val_every_n_epoch">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Perform a validation loop every after every <cite>N</cite> training epochs. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
validation will be done solely based on the number of training batches, requiring <code class="docutils literal notranslate"><span class="pre">val_check_interval</span></code>
to be an integer value.
Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.num_sanity_val_steps"></span><strong>num_sanity_val_steps</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.num_sanity_val_steps">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – Sanity check runs n validation batches before starting the training routine.
Set it to <cite>-1</cite> to run all batches in all validation dataloaders.
Default: <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.log_every_n_steps"></span><strong>log_every_n_steps</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.log_every_n_steps">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]) – How often to log within steps.
Default: <code class="docutils literal notranslate"><span class="pre">50</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.enable_checkpointing"></span><strong>enable_checkpointing</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.enable_checkpointing">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, enable checkpointing.
It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.callbacks" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">callbacks</span></code></a>.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.enable_progress_bar"></span><strong>enable_progress_bar</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.enable_progress_bar">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – Whether to enable to progress bar by default.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.enable_model_summary"></span><strong>enable_model_summary</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.enable_model_summary">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – Whether to enable model summarization by default.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.accumulate_grad_batches"></span><strong>accumulate_grad_batches</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.accumulate_grad_batches">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Accumulates gradients over k batches before stepping the optimizer.
Default: 1.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.gradient_clip_val"></span><strong>gradient_clip_val</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.gradient_clip_val">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – The value at which to clip gradients. Passing <code class="docutils literal notranslate"><span class="pre">gradient_clip_val=None</span></code> disables
gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.gradient_clip_algorithm"></span><strong>gradient_clip_algorithm</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.gradient_clip_algorithm">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm. By default it will
be set to <code class="docutils literal notranslate"><span class="pre">&quot;norm&quot;</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.deterministic"></span><strong>deterministic</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.deterministic">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Literal" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Literal</span></code></a>[‘warn’], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, sets whether PyTorch operations must use deterministic algorithms.
Set to <code class="docutils literal notranslate"><span class="pre">&quot;warn&quot;</span></code> to use deterministic algorithms whenever possible, throwing warnings on operations
that don’t support deterministic mode (requires PyTorch 1.11+). If not set, defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.benchmark"></span><strong>benchmark</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.benchmark">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – The value (<code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>) to set <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.benchmark</span></code> to.
The value for <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.benchmark</span></code> set in the current session will be used
(<code class="docutils literal notranslate"><span class="pre">False</span></code> if not manually set). If <a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.deterministic" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">deterministic</span></code></a>
is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this will default to <code class="docutils literal notranslate"><span class="pre">False</span></code>. Override to manually set a different value.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.inference_mode"></span><strong>inference_mode</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.inference_mode">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether to use <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.inference_mode()</span></code> or <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.no_grad()</span></code> during
evaluation (<code class="docutils literal notranslate"><span class="pre">validate</span></code>/<code class="docutils literal notranslate"><span class="pre">test</span></code>/<code class="docutils literal notranslate"><span class="pre">predict</span></code>).</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.use_distributed_sampler"></span><strong>use_distributed_sampler</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.use_distributed_sampler">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether to wrap the DataLoader’s sampler with
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DistributedSampler</span></code>. If not specified this is toggled automatically for
strategies that require it. By default, it will add <code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code> for the train sampler and
<code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code> for validation/test/predict samplers. If you want to disable this logic, you can pass
<code class="docutils literal notranslate"><span class="pre">False</span></code> and add your own distributed sampler in the dataloader hooks. If <code class="docutils literal notranslate"><span class="pre">True</span></code> and a distributed
sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,
we don’t do this automatically.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.profiler"></span><strong>profiler</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.profiler">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.profilers.Profiler.html#lightning.pytorch.profilers.Profiler" title="lightning.pytorch.profilers.profiler.Profiler"><code class="xref py py-class docutils literal notranslate"><span class="pre">Profiler</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – To profile individual steps during training and assist in identifying bottlenecks.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.detect_anomaly"></span><strong>detect_anomaly</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.detect_anomaly">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Enable anomaly detection for the autograd engine.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.barebones"></span><strong>barebones</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.barebones">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Whether to run in “barebones mode”, where all features that may impact raw speed are
disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training
runs. The following features are deactivated:
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.enable_checkpointing" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">enable_checkpointing</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.logger" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">logger</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.enable_progress_bar" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">enable_progress_bar</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.log_every_n_steps" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">log_every_n_steps</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.enable_model_summary" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">enable_model_summary</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.num_sanity_val_steps" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">num_sanity_val_steps</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.fast_dev_run" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">fast_dev_run</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.detect_anomaly" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">detect_anomaly</span></code></a>,
<a class="reference internal" href="../api/lightning.pytorch.trainer.trainer.Trainer.html#lightning.pytorch.trainer.trainer.Trainer.params.profiler" title="lightning.pytorch.trainer.trainer.Trainer"><code class="xref py py-paramref docutils literal notranslate"><span class="pre">profiler</span></code></a>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">log_dict()</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.plugins"></span><strong>plugins</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.plugins">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.plugins.precision.PrecisionPlugin.html#lightning.pytorch.plugins.precision.PrecisionPlugin" title="lightning.pytorch.plugins.precision.precision_plugin.PrecisionPlugin"><code class="xref py py-class docutils literal notranslate"><span class="pre">PrecisionPlugin</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.environments.ClusterEnvironment.html#lightning.pytorch.plugins.environments.ClusterEnvironment" title="lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClusterEnvironment</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.io.CheckpointIO.html#lightning.pytorch.plugins.io.CheckpointIO" title="lightning.fabric.plugins.io.checkpoint_io.CheckpointIO"><code class="xref py py-class docutils literal notranslate"><span class="pre">CheckpointIO</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.LayerSync.html#lightning.pytorch.plugins.LayerSync" title="lightning.pytorch.plugins.layer_sync.LayerSync"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerSync</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.plugins.precision.PrecisionPlugin.html#lightning.pytorch.plugins.precision.PrecisionPlugin" title="lightning.pytorch.plugins.precision.precision_plugin.PrecisionPlugin"><code class="xref py py-class docutils literal notranslate"><span class="pre">PrecisionPlugin</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.environments.ClusterEnvironment.html#lightning.pytorch.plugins.environments.ClusterEnvironment" title="lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClusterEnvironment</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.io.CheckpointIO.html#lightning.pytorch.plugins.io.CheckpointIO" title="lightning.fabric.plugins.io.checkpoint_io.CheckpointIO"><code class="xref py py-class docutils literal notranslate"><span class="pre">CheckpointIO</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.plugins.LayerSync.html#lightning.pytorch.plugins.LayerSync" title="lightning.pytorch.plugins.layer_sync.LayerSync"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerSync</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.sync_batchnorm"></span><strong>sync_batchnorm</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.sync_batchnorm">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – Synchronize batch norm layers between process groups/whole world.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.reload_dataloaders_every_n_epochs"></span><strong>reload_dataloaders_every_n_epochs</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.reload_dataloaders_every_n_epochs">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) – Set to a non-negative integer to reload dataloaders every n epochs.
Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.params.default_root_dir"></span><strong>default_root_dir</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.params.default_root_dir">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – Default path for logs and weights when no logger/ckpt_callback passed.
Default: <code class="docutils literal notranslate"><span class="pre">os.getcwd()</span></code>.
Can be remote file paths such as <cite>s3://mybucket/path</cite> or ‘hdfs://path/’</p></li>
</ul>
</dd>
<dt class="field-even">예외 발생</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(Python v3.11에서)"><strong>TypeError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">gradient_clip_val</span></code> is not an int or float.</p></li>
<li><p><strong>MisconfigurationException</strong> – If <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm</span></code> is invalid.
    If <code class="docutils literal notranslate"><span class="pre">track_grad_norm</span></code> is not a positive number or inf.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="fit">
<h4>fit<a class="headerlink" href="#fit" title="이 표제에 대한 퍼머링크">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Trainer.</span></span><span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataloaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_dataloaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/trainer/trainer.html#Trainer.fit"><span class="viewcode-link"><span class="pre">[소스]</span></span></a></dt>
<dd><p>Runs the full optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.fit.params.model"></span><strong>model</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.fit.params.model">¶</a> (<a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>) – Model to fit.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.fit.params.train_dataloaders"></span><strong>train_dataloaders</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.fit.params.train_dataloaders">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – An iterable or collection of iterables specifying training samples.
Alternatively, a <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.train_dataloader" title="lightning.pytorch.core.hooks.DataHooks.train_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">train_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.fit.params.val_dataloaders"></span><strong>val_dataloaders</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.fit.params.val_dataloaders">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]) – An iterable or collection of iterables specifying validation samples.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.fit.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.fit.params.datamodule">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>]) – A <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.train_dataloader" title="lightning.pytorch.core.hooks.DataHooks.train_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">train_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.fit.params.ckpt_path"></span><strong>ckpt_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.fit.params.ckpt_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – Path/URL of the checkpoint from which training is resumed. Could also be one of two special
keywords <code class="docutils literal notranslate"><span class="pre">&quot;last&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;hpc&quot;</span></code>. If there is no checkpoint file at the path, an exception is raised.</p></li>
</ul>
</dd>
<dt class="field-even">예외 발생</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(Python v3.11에서)"><strong>TypeError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">model</span></code> is not <a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> for torch version less than
    2.0.0 and if <code class="docutils literal notranslate"><span class="pre">model</span></code> is not <a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> or
    <a class="reference external" href="https://pytorch.org/docs/stable/_dynamo.html#torch._dynamo.OptimizedModule" title="(PyTorch v2.0에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch._dynamo.OptimizedModule</span></code></a> for torch versions greater than or equal to 2.0.0 .</p>
</dd>
</dl>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="validate">
<h4>validate<a class="headerlink" href="#validate" title="이 표제에 대한 퍼머링크">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Trainer.</span></span><span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/trainer/trainer.html#Trainer.validate"><span class="viewcode-link"><span class="pre">[소스]</span></span></a></dt>
<dd><p>Perform one evaluation epoch over the validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.validate.params.model"></span><strong>model</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.validate.params.model">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>]) – The model to validate.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.validate.params.dataloaders"></span><strong>dataloaders</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.validate.params.dataloaders">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – An iterable or collection of iterables specifying validation samples.
Alternatively, a <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.val_dataloader" title="lightning.pytorch.core.hooks.DataHooks.val_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">val_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.validate.params.ckpt_path"></span><strong>ckpt_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.validate.params.ckpt_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – Either <code class="docutils literal notranslate"><span class="pre">&quot;best&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;last&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;hpc&quot;</span></code> or path to the checkpoint you wish to validate.
If <code class="docutils literal notranslate"><span class="pre">None</span></code> and the model instance was passed, use the current weights.
Otherwise, the best model checkpoint from the previous <code class="docutils literal notranslate"><span class="pre">trainer.fit</span></code> call will be loaded
if a checkpoint callback is configured.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.validate.params.verbose"></span><strong>verbose</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.validate.params.verbose">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – If True, prints the validation results.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.validate.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.validate.params.datamodule">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>]) – A <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.val_dataloader" title="lightning.pytorch.core.hooks.DataHooks.val_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">val_dataloader</span></code></a> hook.</p></li>
</ul>
</dd>
</dl>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks
like <code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code> etc.
The length of the list corresponds to the number of validation dataloaders used.</p>
</dd>
<dt class="field-odd">예외 발생</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(Python v3.11에서)"><strong>TypeError</strong></a> – If no <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and there was no <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> passed in the previous run.
    If <code class="docutils literal notranslate"><span class="pre">model</span></code> passed is not <cite>LightningModule</cite> or <cite>torch._dynamo.OptimizedModule</cite>.</p></li>
<li><p><strong>MisconfigurationException</strong> – If both <code class="docutils literal notranslate"><span class="pre">dataloaders</span></code> and <code class="docutils literal notranslate"><span class="pre">datamodule</span></code> are passed. Pass only one of these.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(Python v3.11에서)"><strong>RuntimeError</strong></a> – If a compiled <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and the strategy is not supported.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="test">
<h4>test<a class="headerlink" href="#test" title="이 표제에 대한 퍼머링크">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Trainer.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/trainer/trainer.html#Trainer.test"><span class="viewcode-link"><span class="pre">[소스]</span></span></a></dt>
<dd><p>Perform one evaluation epoch over the test set. It’s separated from fit to make sure you never run on
your test set until you want to.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.test.params.model"></span><strong>model</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.test.params.model">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>]) – The model to test.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.test.params.dataloaders"></span><strong>dataloaders</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.test.params.dataloaders">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – An iterable or collection of iterables specifying test samples.
Alternatively, a <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.test_dataloader" title="lightning.pytorch.core.hooks.DataHooks.test_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">test_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.test.params.ckpt_path"></span><strong>ckpt_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.test.params.ckpt_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – Either <code class="docutils literal notranslate"><span class="pre">&quot;best&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;last&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;hpc&quot;</span></code> or path to the checkpoint you wish to test.
If <code class="docutils literal notranslate"><span class="pre">None</span></code> and the model instance was passed, use the current weights.
Otherwise, the best model checkpoint from the previous <code class="docutils literal notranslate"><span class="pre">trainer.fit</span></code> call will be loaded
if a checkpoint callback is configured.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.test.params.verbose"></span><strong>verbose</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.test.params.verbose">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>) – If True, prints the test results.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.test.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.test.params.datamodule">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>]) – A <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.test_dataloader" title="lightning.pytorch.core.hooks.DataHooks.test_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">test_dataloader</span></code></a> hook.</p></li>
</ul>
</dd>
</dl>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>]]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks
like <code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code> etc.
The length of the list corresponds to the number of test dataloaders used.</p>
</dd>
<dt class="field-odd">예외 발생</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(Python v3.11에서)"><strong>TypeError</strong></a> – If no <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and there was no <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> passed in the previous run.
    If <code class="docutils literal notranslate"><span class="pre">model</span></code> passed is not <cite>LightningModule</cite> or <cite>torch._dynamo.OptimizedModule</cite>.</p></li>
<li><p><strong>MisconfigurationException</strong> – If both <code class="docutils literal notranslate"><span class="pre">dataloaders</span></code> and <code class="docutils literal notranslate"><span class="pre">datamodule</span></code> are passed. Pass only one of these.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(Python v3.11에서)"><strong>RuntimeError</strong></a> – If a compiled <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and the strategy is not supported.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="predict">
<h4>predict<a class="headerlink" href="#predict" title="이 표제에 대한 퍼머링크">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Trainer.</span></span><span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloaders</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_predictions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/lightning/pytorch/trainer/trainer.html#Trainer.predict"><span class="viewcode-link"><span class="pre">[소스]</span></span></a></dt>
<dd><p>Run inference on your data. This will call the model forward function to compute predictions. Useful to
perform distributed and batched predictions. Logging is disabled in the predict hooks.</p>
<dl class="field-list simple">
<dt class="field-odd">매개변수</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.predict.params.model"></span><strong>model</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.predict.params.model">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="lightning.pytorch.core.module.LightningModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a>]) – The model to predict with.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.predict.params.dataloaders"></span><strong>dataloaders</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.predict.params.dataloaders">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>, <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]) – An iterable or collection of iterables specifying predict samples.
Alternatively, a <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.predict_dataloader" title="lightning.pytorch.core.hooks.DataHooks.predict_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.predict.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.predict.params.datamodule">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a>]) – A <a class="reference internal" href="../api/lightning.pytorch.core.LightningDataModule.html#lightning.pytorch.core.LightningDataModule" title="lightning.pytorch.core.datamodule.LightningDataModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningDataModule</span></code></a> that defines
the <a class="reference internal" href="../api/lightning.pytorch.core.hooks.DataHooks.html#lightning.pytorch.core.hooks.DataHooks.predict_dataloader" title="lightning.pytorch.core.hooks.DataHooks.predict_dataloader"><code class="xref py py-class docutils literal notranslate"><span class="pre">predict_dataloader</span></code></a> hook.</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.predict.params.return_predictions"></span><strong>return_predictions</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.predict.params.return_predictions">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>]) – Whether to return predictions.
<code class="docutils literal notranslate"><span class="pre">True</span></code> by default except when an accelerator that spawns processes is used (not supported).</p></li>
<li><p><span class="target" id="lightning.pytorch.trainer.Trainer.predict.params.ckpt_path"></span><strong>ckpt_path</strong><a class="paramlink headerlink reference internal" href="#lightning.pytorch.trainer.Trainer.predict.params.ckpt_path">¶</a> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>]) – Either <code class="docutils literal notranslate"><span class="pre">&quot;best&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;last&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;hpc&quot;</span></code> or path to the checkpoint you wish to predict.
If <code class="docutils literal notranslate"><span class="pre">None</span></code> and the model instance was passed, use the current weights.
Otherwise, the best model checkpoint from the previous <code class="docutils literal notranslate"><span class="pre">trainer.fit</span></code> call will be loaded
if a checkpoint callback is configured.</p></li>
</ul>
</dd>
</dl>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">반환 형식</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>], <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(Python v3.11에서)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(Python v3.11에서)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a>]], <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(Python v3.11에서)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>]</p>
</dd>
<dt class="field-even">반환</dt>
<dd class="field-even"><p>Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.</p>
</dd>
<dt class="field-odd">예외 발생</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(Python v3.11에서)"><strong>TypeError</strong></a> – If no <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and there was no <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> passed in the previous run.
    If <code class="docutils literal notranslate"><span class="pre">model</span></code> passed is not <cite>LightningModule</cite> or <cite>torch._dynamo.OptimizedModule</cite>.</p></li>
<li><p><strong>MisconfigurationException</strong> – If both <code class="docutils literal notranslate"><span class="pre">dataloaders</span></code> and <code class="docutils literal notranslate"><span class="pre">datamodule</span></code> are passed. Pass only one of these.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(Python v3.11에서)"><strong>RuntimeError</strong></a> – If a compiled <code class="docutils literal notranslate"><span class="pre">model</span></code> is passed and the strategy is not supported.</p></li>
</ul>
</dd>
</dl>
<p>See <a class="reference internal" href="../deploy/production_basic.html#predict-step-with-your-lightningmodule"><span class="std std-ref">Lightning inference section</span></a> for more.</p>
</dd></dl>

</section>
</section>
<section id="properties">
<h3>Properties<a class="headerlink" href="#properties" title="이 표제에 대한 퍼머링크">¶</a></h3>
<section id="callback-metrics">
<h4>callback_metrics<a class="headerlink" href="#callback-metrics" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The metrics available to callbacks.</p>
<p>This includes metrics logged via <code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;a_val&quot;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>


<span class="n">callback_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">callback_metrics</span>
<span class="k">assert</span> <span class="n">callback_metrics</span><span class="p">[</span><span class="s2">&quot;a_val&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">2.0</span>
</pre></div>
</div>
</section>
<section id="logged-metrics">
<h4>logged_metrics<a class="headerlink" href="#logged-metrics" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The metrics sent to the loggers.</p>
<p>This includes metrics logged via <code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code> with the
<code class="xref py py-paramref docutils literal notranslate"><span class="pre">logger</span></code> argument set.</p>
</section>
<section id="progress-bar-metrics">
<h4>progress_bar_metrics<a class="headerlink" href="#progress-bar-metrics" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The metrics sent to the progress bar.</p>
<p>This includes metrics logged via <code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code> with the
<code class="xref py py-paramref docutils literal notranslate"><span class="pre">prog_bar</span></code> argument set.</p>
</section>
<section id="current-epoch">
<h4>current_epoch<a class="headerlink" href="#current-epoch" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The current epoch, updated after the epoch end hooks are run.</p>
</section>
<section id="datamodule">
<h4>datamodule<a class="headerlink" href="#datamodule" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The current datamodule, which is used by the trainer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">used_datamodule</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">datamodule</span>
</pre></div>
</div>
</section>
<section id="is-last-batch">
<h4>is_last_batch<a class="headerlink" href="#is-last-batch" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>Whether trainer is executing the last batch.</p>
</section>
<section id="global-step">
<h4>global_step<a class="headerlink" href="#global-step" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of optimizer steps taken (does not reset each epoch).</p>
<p>This includes multiple optimizers (if enabled).</p>
</section>
<section id="id3">
<h4>logger<a class="headerlink" href="#id3" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The first <a class="reference internal" href="../api/lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a> being used.</p>
</section>
<section id="loggers">
<h4>loggers<a class="headerlink" href="#loggers" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The list of <a class="reference internal" href="../api/lightning.pytorch.loggers.logger.html#lightning.pytorch.loggers.logger.Logger" title="lightning.pytorch.loggers.logger.Logger"><code class="xref py py-class docutils literal notranslate"><span class="pre">Logger</span></code></a> used.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">logger</span> <span class="ow">in</span> <span class="n">trainer</span><span class="o">.</span><span class="n">loggers</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">({</span><span class="s2">&quot;foo&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="log-dir">
<h4>log_dir<a class="headerlink" href="#log-dir" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The directory for the current experiment. Use this to save images to, etc…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">save_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="is-global-zero">
<h4>is_global_zero<a class="headerlink" href="#is-global-zero" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>Whether this process is the global zero in multi-node training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">is_global_zero</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;in node 0, accelerator 0&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="estimated-stepping-batches">
<h4>estimated_stepping_batches<a class="headerlink" href="#estimated-stepping-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The estimated number of batches that will <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code> during training.</p>
<p>This accounts for gradient accumulation and the current trainer configuration. This might sets up your training
dataloader if hadn’t been set up already.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">stepping_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">estimated_stepping_batches</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">total_steps</span><span class="o">=</span><span class="n">stepping_batches</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="state">
<h4>state<a class="headerlink" href="#state" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The current state of the Trainer, including the current function that is running, the stage of
execution within that function, and the status of the Trainer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># fn in (&quot;fit&quot;, &quot;validate&quot;, &quot;test&quot;, &quot;predict&quot;)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span>
<span class="c1"># status in (&quot;initializing&quot;, &quot;running&quot;, &quot;finished&quot;, &quot;interrupted&quot;)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span>
<span class="c1"># stage in (&quot;train&quot;, &quot;sanity_check&quot;, &quot;validate&quot;, &quot;test&quot;, &quot;predict&quot;)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span>
</pre></div>
</div>
</section>
<section id="should-stop">
<h4>should_stop<a class="headerlink" href="#should-stop" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>If you want to terminate the training during <code class="docutils literal notranslate"><span class="pre">.fit</span></code>, you can set <code class="docutils literal notranslate"><span class="pre">trainer.should_stop=True</span></code> to terminate the training
as soon as possible. Note that, it will respect the arguments <code class="docutils literal notranslate"><span class="pre">min_steps</span></code> and <code class="docutils literal notranslate"><span class="pre">min_epochs</span></code> to check whether to stop. If these
arguments are set and the <code class="docutils literal notranslate"><span class="pre">current_epoch</span></code> or <code class="docutils literal notranslate"><span class="pre">global_step</span></code> don’t meet these minimum conditions, training will continue until
both conditions are met. If any of these arguments is not set, it won’t be considered for the final decision.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting `trainer.should_stop` at any point of training will terminate it</span>
<span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting `trainer.should_stop` will stop training only after at least 5 epochs have run</span>
<span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting `trainer.should_stop` will stop training only after at least 5 steps have run</span>
<span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting `trainer.should_stop` at any until both min_steps and min_epochs are satisfied</span>
<span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">min_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="sanity-checking">
<h4>sanity_checking<a class="headerlink" href="#sanity-checking" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>Indicates if the trainer is currently running sanity checking. This property can be useful to disable some hooks,
logging or callbacks during the sanity checking.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">sanity_checking</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="num-training-batches">
<h4>num_training_batches<a class="headerlink" href="#num-training-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of training batches that will be used during <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code>.</p>
</section>
<section id="num-sanity-val-batches">
<h4>num_sanity_val_batches<a class="headerlink" href="#num-sanity-val-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of validation batches that will be used during the sanity-checking part of <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code>.</p>
</section>
<section id="num-val-batches">
<h4>num_val_batches<a class="headerlink" href="#num-val-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of validation batches that will be used during <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">trainer.validate()</span></code>.</p>
</section>
<section id="num-test-batches">
<h4>num_test_batches<a class="headerlink" href="#num-test-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of test batches that will be used during <code class="docutils literal notranslate"><span class="pre">trainer.test()</span></code>.</p>
</section>
<section id="num-predict-batches">
<h4>num_predict_batches<a class="headerlink" href="#num-predict-batches" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The number of prediction batches that will be used during <code class="docutils literal notranslate"><span class="pre">trainer.predict()</span></code>.</p>
</section>
<section id="train-dataloader">
<h4>train_dataloader<a class="headerlink" href="#train-dataloader" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The training dataloader(s) used during <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code>.</p>
</section>
<section id="val-dataloaders">
<h4>val_dataloaders<a class="headerlink" href="#val-dataloaders" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The validation dataloader(s) used during <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">trainer.validate()</span></code>.</p>
</section>
<section id="test-dataloaders">
<h4>test_dataloaders<a class="headerlink" href="#test-dataloaders" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The test dataloader(s) used during <code class="docutils literal notranslate"><span class="pre">trainer.test()</span></code>.</p>
</section>
<section id="predict-dataloaders">
<h4>predict_dataloaders<a class="headerlink" href="#predict-dataloaders" title="이 표제에 대한 퍼머링크">¶</a></h4>
<p>The prediction dataloader(s) used during <code class="docutils literal notranslate"><span class="pre">trainer.predict()</span></code>.</p>
</section>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../api_references.html" class="btn btn-neutral float-right" title="accelerators" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="lightning_module.html" class="btn btn-neutral" title="LightningModule" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2018-2023, Lightning AI et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Trainer</a><ul>
<li><a class="reference internal" href="#basic-use">Basic use</a></li>
<li><a class="reference internal" href="#under-the-hood">Under the hood</a></li>
<li><a class="reference internal" href="#trainer-in-python-scripts">Trainer in Python scripts</a></li>
<li><a class="reference internal" href="#validation">Validation</a></li>
<li><a class="reference internal" href="#testing">Testing</a></li>
<li><a class="reference internal" href="#reproducibility">Reproducibility</a></li>
<li><a class="reference internal" href="#trainer-flags">Trainer flags</a><ul>
<li><a class="reference internal" href="#accelerator">accelerator</a></li>
<li><a class="reference internal" href="#accumulate-grad-batches">accumulate_grad_batches</a></li>
<li><a class="reference internal" href="#benchmark">benchmark</a></li>
<li><a class="reference internal" href="#deterministic">deterministic</a></li>
<li><a class="reference internal" href="#callbacks">callbacks</a></li>
<li><a class="reference internal" href="#check-val-every-n-epoch">check_val_every_n_epoch</a></li>
<li><a class="reference internal" href="#default-root-dir">default_root_dir</a></li>
<li><a class="reference internal" href="#devices">devices</a></li>
<li><a class="reference internal" href="#enable-checkpointing">enable_checkpointing</a></li>
<li><a class="reference internal" href="#fast-dev-run">fast_dev_run</a></li>
<li><a class="reference internal" href="#gradient-clip-val">gradient_clip_val</a></li>
<li><a class="reference internal" href="#limit-train-batches">limit_train_batches</a></li>
<li><a class="reference internal" href="#limit-test-batches">limit_test_batches</a></li>
<li><a class="reference internal" href="#limit-val-batches">limit_val_batches</a></li>
<li><a class="reference internal" href="#log-every-n-steps">log_every_n_steps</a></li>
<li><a class="reference internal" href="#logger">logger</a></li>
<li><a class="reference internal" href="#max-epochs">max_epochs</a></li>
<li><a class="reference internal" href="#min-epochs">min_epochs</a></li>
<li><a class="reference internal" href="#max-steps">max_steps</a></li>
<li><a class="reference internal" href="#min-steps">min_steps</a></li>
<li><a class="reference internal" href="#max-time">max_time</a></li>
<li><a class="reference internal" href="#num-nodes">num_nodes</a></li>
<li><a class="reference internal" href="#num-sanity-val-steps">num_sanity_val_steps</a></li>
<li><a class="reference internal" href="#overfit-batches">overfit_batches</a></li>
<li><a class="reference internal" href="#plugins">plugins</a></li>
<li><a class="reference internal" href="#precision">precision</a></li>
<li><a class="reference internal" href="#profiler">profiler</a></li>
<li><a class="reference internal" href="#enable-progress-bar">enable_progress_bar</a></li>
<li><a class="reference internal" href="#reload-dataloaders-every-n-epochs">reload_dataloaders_every_n_epochs</a></li>
<li><a class="reference internal" href="#use-distributed-sampler">use_distributed_sampler</a></li>
<li><a class="reference internal" href="#strategy">strategy</a></li>
<li><a class="reference internal" href="#sync-batchnorm">sync_batchnorm</a></li>
<li><a class="reference internal" href="#val-check-interval">val_check_interval</a></li>
<li><a class="reference internal" href="#enable-model-summary">enable_model_summary</a></li>
<li><a class="reference internal" href="#inference-mode">inference_mode</a></li>
</ul>
</li>
<li><a class="reference internal" href="#trainer-class-api">Trainer class API</a><ul>
<li><a class="reference internal" href="#methods">Methods</a><ul>
<li><a class="reference internal" href="#init">init</a></li>
<li><a class="reference internal" href="#fit">fit</a></li>
<li><a class="reference internal" href="#validate">validate</a></li>
<li><a class="reference internal" href="#test">test</a></li>
<li><a class="reference internal" href="#predict">predict</a></li>
</ul>
</li>
<li><a class="reference internal" href="#properties">Properties</a><ul>
<li><a class="reference internal" href="#callback-metrics">callback_metrics</a></li>
<li><a class="reference internal" href="#logged-metrics">logged_metrics</a></li>
<li><a class="reference internal" href="#progress-bar-metrics">progress_bar_metrics</a></li>
<li><a class="reference internal" href="#current-epoch">current_epoch</a></li>
<li><a class="reference internal" href="#datamodule">datamodule</a></li>
<li><a class="reference internal" href="#is-last-batch">is_last_batch</a></li>
<li><a class="reference internal" href="#global-step">global_step</a></li>
<li><a class="reference internal" href="#id3">logger</a></li>
<li><a class="reference internal" href="#loggers">loggers</a></li>
<li><a class="reference internal" href="#log-dir">log_dir</a></li>
<li><a class="reference internal" href="#is-global-zero">is_global_zero</a></li>
<li><a class="reference internal" href="#estimated-stepping-batches">estimated_stepping_batches</a></li>
<li><a class="reference internal" href="#state">state</a></li>
<li><a class="reference internal" href="#should-stop">should_stop</a></li>
<li><a class="reference internal" href="#sanity-checking">sanity_checking</a></li>
<li><a class="reference internal" href="#num-training-batches">num_training_batches</a></li>
<li><a class="reference internal" href="#num-sanity-val-batches">num_sanity_val_batches</a></li>
<li><a class="reference internal" href="#num-val-batches">num_val_batches</a></li>
<li><a class="reference internal" href="#num-test-batches">num_test_batches</a></li>
<li><a class="reference internal" href="#num-predict-batches">num_predict_batches</a></li>
<li><a class="reference internal" href="#train-dataloader">train_dataloader</a></li>
<li><a class="reference internal" href="#val-dataloaders">val_dataloaders</a></li>
<li><a class="reference internal" href="#test-dataloaders">test_dataloaders</a></li>
<li><a class="reference internal" href="#predict-dataloaders">predict_dataloaders</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Click to show';</script>
         <script>let toggleHintHide = 'Click to hide';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script src="../_static/translations.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Best practices', 'Optional Extensions', 'Tutorials', 'API References', 'Bolts', 'Examples', 'Partner Domain Frameworks', 'Community'];
</script>



  <!-- Begin Footer -->

  <!-- <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources"> -->
    <!-- <div class="container"> -->
      <!-- <div class="row"> -->
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://lightning.ai/docs/pytorch/latest/#community-examples">View Resources</a>
        </div>
        -->
      <!-- </div> -->
    <!-- </div> -->
  <!-- </div> -->

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://lightning.ai/docs/pytorch/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning.ai/docs/pytorch/latest/">PyTorch</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://lightning.ai/pages/blog/">Blog</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning/blob/master/.github/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning.ai/docs/pytorch/latest/#community-examples">Resources</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://lightning.ai/docs/pytorch/latest/">Docs</a></li>
            <li><a href="https://www.pytorchlightning.ai/community" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/LightningAI" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://lightning.ai/docs/pytorch/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://lightning.ai/docs/pytorch/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://lightning.ai/pages/blog/">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning.ai/docs/pytorch/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Lightning Fabric</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Fabric</a>
            </li>
          </ul> -->

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning.ai/docs/pytorch/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/pytorch/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="https://www.pytorchlightning.ai/community">Community</a>
            </li>

            <li>
              <a href="https://lightning.ai/forums/">Forums</a>
            </li>
          </ul>-->

          <li>
            <a href="https://www.lightning.ai/">Lightning.ai</a>
          </li>

          <li>
            <a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">파이토치 한국어 커뮤니티</a>
          </li>

        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5SCNQBF5"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
 </body>
</html>