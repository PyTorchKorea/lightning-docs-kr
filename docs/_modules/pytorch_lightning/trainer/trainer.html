


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>

  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorch_lightning.trainer.trainer &mdash; PyTorch Lightning 1.7.0dev documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch-lightning.readthedocs.io/en/stable//_modules/pytorch_lightning/trainer/trainer.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/main.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  
  <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-82W25RV60Q"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-82W25RV60Q');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="../../../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li> -->

          <!-- <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-transformers.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Transformers</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li> -->

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://www.pytorchlightning.ai/community">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://github.com/PyTorchLightning/pytorch-lightning/discussions" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">GitHub</a>
          </li>

          <li>
            <a href="https://www.grid.ai/">Train on the cloud</a>
          </li> -->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.7.0dev
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../starter/introduction.html">Lightning 15분 만에 배워보기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../starter/converting.html">Organize existing PyTorch into Lightning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Level Up</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../levels/core_skills.html">Basic skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../levels/intermediate.html">Intermediate skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../levels/advanced.html">Advanced skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../levels/expert.html">Expert skills</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/trainer.html">Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Workflows</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../common/evaluation.html">Avoid overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/build_model.html">Build a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/hyperparameters.html">Configure hyperparameters from the CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/progress_bar.html">Customize the progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy/production.html">Deploy models into production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/training_tricks.html">Effective Training Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli/lightning_cli.html">Eliminate config boilerplate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tuning/profiler.html">Find bottlenecks in your code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/transfer_learning.html">Finetune a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../visualize/logging_intermediate.html">Manage experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cluster.html">Run on an on-prem cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/model_parallel.html">Train 1 trillion+ parameter models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cloud_training.html">Train on the cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/checkpointing.html">Save and load model progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/precision.html">Save memory with half-precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/gpu.html">Train on single or multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/hpu.html">Train on single or multiple HPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/ipu.html">Train on single or multiple IPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/tpu.html">Train on single or multiple TPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/own_your_loop.html">Use a pure PyTorch training loop</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../extensions/accelerator.html">Accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extensions/callbacks.html">Callback</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/checkpointing.html">Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cluster.html">Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/checkpointing_advanced.html">Cloud checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/console_logs.html">Console Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../debug/debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/early_stopping.html">Early stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../visualize/experiment_managers.html">Experiment manager (Logger)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/fault_tolerant_training.html">Fault tolerant training</a></li>
<li class="toctree-l1"><a class="reference external" href="https://lightning-flash.readthedocs.io/en/stable/">Flash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cloud_training.html">Grid AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/gpu.html">GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/precision.html">Half precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/hpu.html">HPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy/production_intermediate.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/ipu.html">IPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli/lightning_cli.html">Lightning CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/build_model_expert.html">Raw PyTorch loop (expert)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/build_model_expert.html#lightninglite-stepping-stone-to-lightning">LightningLite (Stepping Stone to Lightning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data/datamodule.html">LightningDataModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/ecosystem/transformers.html">Lightning Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../visualize/loggers.html">Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extensions/loops.html">Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../accelerators/tpu.html">TPU</a></li>
<li class="toctree-l1"><a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model/build_model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/model_parallel.html">Model Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extensions/plugins.html">Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/progress_bar.html">Progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy/production_advanced.html">Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy/production_basic.html">Predict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tuning/profiler.html">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/pruning_quantization.html">Pruning and Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/remote_fs.html">Remote filesystem and FSSPEC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/strategy_registry.html">Strategy registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../starter/style_guide.html">Style guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/run_intermediate.html">Sweep</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/training_tricks.html">SWA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cluster_advanced.html">SLURM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../advanced/transfer_learning.html">Transfer learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../common/trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../clouds/cluster_intermediate_2.html">Torch distributed</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hands-on Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2">PyTorch Lightning 101 class</a></li>
<li class="toctree-l1"><a class="reference external" href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09">From PyTorch to PyTorch Lightning [Blog]</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/watch?v=QHww1JH7IDU">From PyTorch to PyTorch Lightning [Video]</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>pytorch_lightning.trainer.trainer</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pytorch_lightning.trainer.trainer</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright The PyTorch Lightning team.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;Trainer to automate the training.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">ArgumentParser</span><span class="p">,</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">cast</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">weakref</span> <span class="kn">import</span> <span class="n">proxy</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">Version</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.accelerators</span> <span class="kn">import</span> <span class="n">Accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">,</span> <span class="n">HPUAccelerator</span><span class="p">,</span> <span class="n">IPUAccelerator</span><span class="p">,</span> <span class="n">TPUAccelerator</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">Callback</span><span class="p">,</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">ProgressBarBase</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks.prediction_writer</span> <span class="kn">import</span> <span class="n">BasePredictionWriter</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.core.datamodule</span> <span class="kn">import</span> <span class="n">LightningDataModule</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.core.optimizer</span> <span class="kn">import</span> <span class="n">LightningOptimizer</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">LightningLoggerBase</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers.base</span> <span class="kn">import</span> <span class="n">DummyLogger</span><span class="p">,</span> <span class="n">LoggerCollection</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers.tensorboard</span> <span class="kn">import</span> <span class="n">TensorBoardLogger</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loops</span> <span class="kn">import</span> <span class="n">PredictionLoop</span><span class="p">,</span> <span class="n">TrainingEpochLoop</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loops.dataloader.evaluation_loop</span> <span class="kn">import</span> <span class="n">EvaluationLoop</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loops.fit_loop</span> <span class="kn">import</span> <span class="n">FitLoop</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loops.utilities</span> <span class="kn">import</span> <span class="n">_parse_loop_limits</span><span class="p">,</span> <span class="n">_reset_progress</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.plugins</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ApexMixedPrecisionPlugin</span><span class="p">,</span>
    <span class="n">NativeMixedPrecisionPlugin</span><span class="p">,</span>
    <span class="n">PLUGIN_INPUT</span><span class="p">,</span>
    <span class="n">PrecisionPlugin</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.plugins.environments.slurm_environment</span> <span class="kn">import</span> <span class="n">SLURMEnvironment</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.profiler</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AdvancedProfiler</span><span class="p">,</span>
    <span class="n">BaseProfiler</span><span class="p">,</span>
    <span class="n">PassThroughProfiler</span><span class="p">,</span>
    <span class="n">Profiler</span><span class="p">,</span>
    <span class="n">PyTorchProfiler</span><span class="p">,</span>
    <span class="n">SimpleProfiler</span><span class="p">,</span>
    <span class="n">XLAProfiler</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.strategies</span> <span class="kn">import</span> <span class="n">ParallelStrategy</span><span class="p">,</span> <span class="n">Strategy</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.ddp_spawn</span> <span class="kn">import</span> <span class="n">DDPSpawnStrategy</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.callback_hook</span> <span class="kn">import</span> <span class="n">TrainerCallbackHookMixin</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.configuration_validator</span> <span class="kn">import</span> <span class="n">verify_loop_configurations</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.accelerator_connector</span> <span class="kn">import</span> <span class="n">AcceleratorConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.callback_connector</span> <span class="kn">import</span> <span class="n">CallbackConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.checkpoint_connector</span> <span class="kn">import</span> <span class="n">CheckpointConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.data_connector</span> <span class="kn">import</span> <span class="n">DataConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.logger_connector</span> <span class="kn">import</span> <span class="n">LoggerConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.logger_connector.result</span> <span class="kn">import</span> <span class="n">_ResultCollection</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.connectors.signal_connector</span> <span class="kn">import</span> <span class="n">SignalConnector</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.data_loading</span> <span class="kn">import</span> <span class="n">TrainerDataLoadingMixin</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.optimizers</span> <span class="kn">import</span> <span class="n">TrainerOptimizersMixin</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.states</span> <span class="kn">import</span> <span class="n">RunningStage</span><span class="p">,</span> <span class="n">TrainerFn</span><span class="p">,</span> <span class="n">TrainerState</span><span class="p">,</span> <span class="n">TrainerStatus</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.supporters</span> <span class="kn">import</span> <span class="n">CombinedLoader</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.tuner.lr_finder</span> <span class="kn">import</span> <span class="n">_LRFinder</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.tuner.tuning</span> <span class="kn">import</span> <span class="n">Tuner</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_HPU_AVAILABLE</span><span class="p">,</span>
    <span class="n">_IPU_AVAILABLE</span><span class="p">,</span>
    <span class="n">_TPU_AVAILABLE</span><span class="p">,</span>
    <span class="n">AMPType</span><span class="p">,</span>
    <span class="n">GradClipAlgorithmType</span><span class="p">,</span>
    <span class="n">parsing</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.apply_func</span> <span class="kn">import</span> <span class="n">apply_to_collection</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.argparse</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_defaults_from_env_vars</span><span class="p">,</span>
    <span class="n">add_argparse_args</span><span class="p">,</span>
    <span class="n">from_argparse_args</span><span class="p">,</span>
    <span class="n">parse_argparser</span><span class="p">,</span>
    <span class="n">parse_env_variables</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.auto_restart</span> <span class="kn">import</span> <span class="n">_add_capture_metadata_collate</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.cloud_io</span> <span class="kn">import</span> <span class="n">get_filesystem</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.data</span> <span class="kn">import</span> <span class="n">_auto_add_worker_init_fn</span><span class="p">,</span> <span class="n">has_len_all_ranks</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.distributed</span> <span class="kn">import</span> <span class="n">distributed_available</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.exceptions</span> <span class="kn">import</span> <span class="n">ExitGracefullyException</span><span class="p">,</span> <span class="n">MisconfigurationException</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.imports</span> <span class="kn">import</span> <span class="n">_fault_tolerant_training</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.meta</span> <span class="kn">import</span> <span class="n">is_on_meta_device</span><span class="p">,</span> <span class="n">materialize_module</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.model_helpers</span> <span class="kn">import</span> <span class="n">is_overridden</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.rank_zero</span> <span class="kn">import</span> <span class="n">rank_zero_deprecation</span><span class="p">,</span> <span class="n">rank_zero_info</span><span class="p">,</span> <span class="n">rank_zero_warn</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.seed</span> <span class="kn">import</span> <span class="n">isolate_rng</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.signature_utils</span> <span class="kn">import</span> <span class="n">is_param_in_hook_signature</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.types</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_EVALUATE_OUTPUT</span><span class="p">,</span>
    <span class="n">_PATH</span><span class="p">,</span>
    <span class="n">_PREDICT_OUTPUT</span><span class="p">,</span>
    <span class="n">EVAL_DATALOADERS</span><span class="p">,</span>
    <span class="n">LRSchedulerConfig</span><span class="p">,</span>
    <span class="n">STEP_OUTPUT</span><span class="p">,</span>
    <span class="n">TRAIN_DATALOADERS</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.utilities.warnings</span> <span class="kn">import</span> <span class="n">PossibleUserWarning</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="c1"># warnings to ignore in trainer</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span>
    <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead&quot;</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">TrainerCallbackHookMixin</span><span class="p">,</span>  <span class="c1"># TODO: Remove in v1.8</span>
    <span class="n">TrainerOptimizersMixin</span><span class="p">,</span>  <span class="c1"># TODO: Remove in v1.8</span>
    <span class="n">TrainerDataLoadingMixin</span><span class="p">,</span>  <span class="c1"># TODO: Remove in v1.8</span>
<span class="p">):</span>
<div class="viewcode-block" id="Trainer.__init__"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.__init__">[docs]</a>    <span class="nd">@_defaults_from_env_vars</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">logger</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">checkpoint_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_checkpointing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callback</span><span class="p">],</span> <span class="n">Callback</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">default_root_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">process_position</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_processes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">devices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">auto_select_gpus</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">tpu_cores</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ipus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_gpu_memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># TODO: Remove in 1.7</span>
        <span class="n">progress_bar_refresh_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># TODO: remove in v1.7</span>
        <span class="n">enable_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">overfit_batches</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">track_grad_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">check_val_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">fast_dev_run</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">accumulate_grad_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">min_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_time</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">timedelta</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">limit_train_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">limit_val_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">limit_test_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">limit_predict_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_check_interval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">flush_logs_every_n_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_every_n_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">accelerator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Accelerator</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Strategy</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">precision</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">enable_model_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">weights_summary</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;top&quot;</span><span class="p">,</span>
        <span class="n">weights_save_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># TODO: Remove in 1.8</span>
        <span class="n">num_sanity_val_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">resume_from_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">profiler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">BaseProfiler</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">benchmark</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">reload_dataloaders_every_n_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">auto_lr_find</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">replace_sampler_ddp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">detect_anomaly</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">auto_scale_batch_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">prepare_data_per_node</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">plugins</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">PLUGIN_INPUT</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">PLUGIN_INPUT</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">amp_backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;native&quot;</span><span class="p">,</span>
        <span class="n">amp_level</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">move_metrics_to_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">multiple_trainloader_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;max_size_cycle&quot;</span><span class="p">,</span>
        <span class="n">stochastic_weight_avg</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">terminate_on_nan</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Customize every aspect of training via flags.</span>

<span class="sd">        Args:</span>

<span class="sd">            accelerator: Supports passing different accelerator types (&quot;cpu&quot;, &quot;gpu&quot;, &quot;tpu&quot;, &quot;ipu&quot;, &quot;hpu&quot;, &quot;auto&quot;)</span>
<span class="sd">                as well as custom accelerator instances.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    Passing training strategies (e.g., &#39;ddp&#39;) to ``accelerator`` has been deprecated in v1.5.0</span>
<span class="sd">                    and will be removed in v1.7.0. Please use the ``strategy`` argument instead.</span>

<span class="sd">            accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            amp_backend: The mixed precision backend to use (&quot;native&quot; or &quot;apex&quot;).</span>
<span class="sd">                Default: ``&#39;native&#39;&#39;``.</span>

<span class="sd">            amp_level: The optimization level to use (O1, O2, etc...). By default it will be set to &quot;O2&quot;</span>
<span class="sd">                if ``amp_backend`` is set to &quot;apex&quot;.</span>

<span class="sd">            auto_lr_find: If set to True, will make trainer.tune() run a learning rate finder,</span>
<span class="sd">                trying to optimize initial learning for faster convergence. trainer.tune() method will</span>
<span class="sd">                set the suggested learning rate in self.lr or self.learning_rate in the LightningModule.</span>
<span class="sd">                To use a different key set a string instead of True with the key name.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            auto_scale_batch_size: If set to True, will `initially` run a batch size</span>
<span class="sd">                finder trying to find the largest batch size that fits into memory.</span>
<span class="sd">                The result will be stored in self.batch_size in the LightningModule.</span>
<span class="sd">                Additionally, can be set to either `power` that estimates the batch size through</span>
<span class="sd">                a power search or `binsearch` that estimates the batch size through a binary search.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            auto_select_gpus: If enabled and ``gpus`` or ``devices`` is an integer, pick available</span>
<span class="sd">                gpus automatically. This is especially useful when</span>
<span class="sd">                GPUs are configured to be in &quot;exclusive mode&quot;, such</span>
<span class="sd">                that only one process at a time can access them.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            benchmark: Sets ``torch.backends.cudnn.benchmark``.</span>
<span class="sd">                Defaults to ``True`` if :paramref:`~pytorch_lightning.trainer.trainer.Trainer.deterministic`</span>
<span class="sd">                is ``False``. Overwrite to manually set a different value. Default: ``None``.</span>

<span class="sd">            callbacks: Add a callback or list of callbacks.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            checkpoint_callback: If ``True``, enable checkpointing.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``checkpoint_callback`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    Please consider using ``enable_checkpointing`` instead.</span>

<span class="sd">            enable_checkpointing: If ``True``, enable checkpointing.</span>
<span class="sd">                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in</span>
<span class="sd">                :paramref:`~pytorch_lightning.trainer.trainer.Trainer.callbacks`.</span>
<span class="sd">                Default: ``True``.</span>

<span class="sd">            check_val_every_n_epoch: Check val every n train epochs.</span>
<span class="sd">                Default: ``1``.</span>


<span class="sd">            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.</span>
<span class="sd">                Default: ``os.getcwd()``.</span>
<span class="sd">                Can be remote file paths such as `s3://mybucket/path` or &#39;hdfs://path/&#39;</span>

<span class="sd">            detect_anomaly: Enable anomaly detection for the autograd engine.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            devices: Will be mapped to either `gpus`, `tpu_cores`, `num_processes` or `ipus`,</span>
<span class="sd">                based on the accelerator type.</span>

<span class="sd">            fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)</span>
<span class="sd">                of train, val and test to find any bugs (ie: a sort of unit test).</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            flush_logs_every_n_steps: How often to flush logs to disk (defaults to every 100 steps).</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``flush_logs_every_n_steps`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    Please configure flushing directly in the logger instead.</span>

<span class="sd">            gpus: Number of GPUs to train on (int) or which GPUs to train on (list or str) applied per node</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables</span>
<span class="sd">                gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=&quot;value&quot;``</span>
<span class="sd">                to clip by value, and ``gradient_clip_algorithm=&quot;norm&quot;`` to clip by norm. By default it will</span>
<span class="sd">                be set to ``&quot;norm&quot;``.</span>

<span class="sd">            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).</span>
<span class="sd">                Default: ``1.0``.</span>

<span class="sd">            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).</span>
<span class="sd">                Default: ``1.0``.</span>

<span class="sd">            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).</span>
<span class="sd">                Default: ``1.0``.</span>

<span class="sd">            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).</span>
<span class="sd">                Default: ``1.0``.</span>

<span class="sd">            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses</span>
<span class="sd">                the default ``TensorBoardLogger``. ``False`` will disable logging. If multiple loggers are</span>
<span class="sd">                provided and the `save_dir` property of that logger is not set, local files (checkpoints,</span>
<span class="sd">                profiler traces, etc.) are saved in ``default_root_dir`` rather than in the ``log_dir`` of any</span>
<span class="sd">                of the individual loggers.</span>
<span class="sd">                Default: ``True``.</span>

<span class="sd">            log_gpu_memory: None, &#39;min_max&#39;, &#39;all&#39;. Might slow performance.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    Deprecated in v1.5.0 and will be removed in v1.7.0</span>
<span class="sd">                    Please use the ``DeviceStatsMonitor`` callback directly instead.</span>

<span class="sd">            log_every_n_steps: How often to log within steps.</span>
<span class="sd">                Default: ``50``.</span>

<span class="sd">            prepare_data_per_node: If True, each LOCAL_RANK=0 will call prepare data.</span>
<span class="sd">                Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    Deprecated in v1.5.0 and will be removed in v1.7.0</span>
<span class="sd">                    Please set ``prepare_data_per_node`` in ``LightningDataModule`` and/or</span>
<span class="sd">                    ``LightningModule`` directly instead.</span>

<span class="sd">            process_position: Orders the progress bar when running multiple models on same machine.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``process_position`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    Please pass :class:`~pytorch_lightning.callbacks.progress.TQDMProgressBar` with ``process_position``</span>
<span class="sd">                    directly to the Trainer&#39;s ``callbacks`` argument instead.</span>

<span class="sd">            progress_bar_refresh_rate: How often to refresh progress bar (in steps). Value ``0`` disables progress bar.</span>
<span class="sd">                Ignored when a custom progress bar is passed to :paramref:`~Trainer.callbacks`. Default: None, means</span>
<span class="sd">                a suitable value will be chosen based on the environment (terminal, Google COLAB, etc.).</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``progress_bar_refresh_rate`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    Please pass :class:`~pytorch_lightning.callbacks.progress.TQDMProgressBar` with ``refresh_rate``</span>
<span class="sd">                    directly to the Trainer&#39;s ``callbacks`` argument instead. To disable the progress bar,</span>
<span class="sd">                    pass ``enable_progress_bar = False`` to the Trainer.</span>

<span class="sd">            enable_progress_bar: Whether to enable to progress bar by default.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            profiler: To profile individual steps during training and assist in identifying bottlenecks.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            overfit_batches: Overfit a fraction of training data (float) or a set number of batches (int).</span>
<span class="sd">                Default: ``0.0``.</span>

<span class="sd">            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            precision: Double precision (64), full precision (32), half precision (16) or bfloat16 precision (bf16).</span>
<span class="sd">                Can be used on CPU, GPU, TPUs, HPUs or IPUs.</span>
<span class="sd">                Default: ``32``.</span>

<span class="sd">            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).</span>
<span class="sd">                If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.</span>
<span class="sd">                To enable infinite training, set ``max_epochs = -1``.</span>

<span class="sd">            min_epochs: Force training for at least these many epochs. Disabled by default (None).</span>

<span class="sd">            max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``</span>
<span class="sd">                and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set</span>
<span class="sd">                ``max_epochs`` to ``-1``.</span>

<span class="sd">            min_steps: Force training for at least these number of steps. Disabled by default (``None``).</span>

<span class="sd">            max_time: Stop training after this amount of time has passed. Disabled by default (``None``).</span>
<span class="sd">                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a</span>
<span class="sd">                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to</span>
<span class="sd">                :class:`datetime.timedelta`.</span>

<span class="sd">            num_nodes: Number of GPU nodes for distributed training.</span>
<span class="sd">                Default: ``1``.</span>

<span class="sd">            num_processes: Number of processes for distributed training with ``accelerator=&quot;cpu&quot;``.</span>
<span class="sd">                Default: ``1``.</span>

<span class="sd">            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.</span>
<span class="sd">                Set it to `-1` to run all batches in all validation dataloaders.</span>
<span class="sd">                Default: ``2``.</span>

<span class="sd">            reload_dataloaders_every_n_epochs: Set to a non-negative integer to reload dataloaders every n epochs.</span>
<span class="sd">                Default: ``0``.</span>

<span class="sd">            replace_sampler_ddp: Explicitly enables or disables sampler replacement. If not specified this</span>
<span class="sd">                will toggled automatically when DDP is used. By default it will add ``shuffle=True`` for</span>
<span class="sd">                train sampler and ``shuffle=False`` for val/test sampler. If you want to customize it,</span>
<span class="sd">                you can set ``replace_sampler_ddp=False`` and add your own distributed sampler.</span>

<span class="sd">            resume_from_checkpoint: Path/URL of the checkpoint from which training is resumed. If there is</span>
<span class="sd">                no checkpoint file at the path, an exception is raised. If resuming from mid-epoch checkpoint,</span>
<span class="sd">                training will start from the beginning of the next epoch.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``resume_from_checkpoint`` is deprecated in v1.5 and will be removed in v2.0.</span>
<span class="sd">                    Please pass the path to ``Trainer.fit(..., ckpt_path=...)`` instead.</span>

<span class="sd">            strategy: Supports different training strategies with aliases</span>
<span class="sd">                as well custom strategies.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            terminate_on_nan: If set to True, will terminate training (by raising a `ValueError`) at the</span>
<span class="sd">                end of each training batch, if any of the parameters or the loss are NaN or +/-inf.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    Trainer argument ``terminate_on_nan`` was deprecated in v1.5 and will be removed in 1.7.</span>
<span class="sd">                    Please use ``detect_anomaly`` instead.</span>

<span class="sd">            detect_anomaly: Enable anomaly detection for the autograd engine.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            tpu_cores: How many TPU cores to train on (1 or 8) / Single TPU to train on (1)</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            ipus: How many IPUs to train on.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">            track_grad_norm: -1 no tracking. Otherwise tracks that p-norm. May be set to &#39;inf&#39; infinity-norm. If using</span>
<span class="sd">                Automatic Mixed Precision (AMP), the gradients will be unscaled before logging them.</span>
<span class="sd">                Default: ``-1``.</span>

<span class="sd">            val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check</span>
<span class="sd">                after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training</span>
<span class="sd">                batches.</span>
<span class="sd">                Default: ``1.0``.</span>

<span class="sd">            enable_model_summary: Whether to enable model summarization by default.</span>
<span class="sd">                Default: ``True``.</span>

<span class="sd">            weights_summary: Prints a summary of the weights when training begins.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``weights_summary`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    To disable the summary, pass ``enable_model_summary = False`` to the Trainer.</span>
<span class="sd">                    To customize the summary, pass :class:`~pytorch_lightning.callbacks.model_summary.ModelSummary`</span>
<span class="sd">                    directly to the Trainer&#39;s ``callbacks`` argument.</span>

<span class="sd">            weights_save_path: Where to save weights if specified. Will override default_root_dir</span>
<span class="sd">                for checkpoints only. Use this if for whatever reason you need the checkpoints</span>
<span class="sd">                stored in a different place than the logs written in `default_root_dir`.</span>
<span class="sd">                Can be remote file paths such as `s3://mybucket/path` or &#39;hdfs://path/&#39;</span>
<span class="sd">                Defaults to `default_root_dir`.</span>

<span class="sd">                .. deprecated:: v1.6</span>
<span class="sd">                    ``weights_save_path`` has been deprecated in v1.6 and will be removed in v1.8. Please pass</span>
<span class="sd">                    ``dirpath`` directly to the :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint`</span>
<span class="sd">                    callback.</span>

<span class="sd">            move_metrics_to_cpu: Whether to force internal logged metrics to be moved to cpu.</span>
<span class="sd">                This can save some gpu memory, but can make training slower. Use with attention.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">            multiple_trainloader_mode: How to loop over the datasets when there are multiple train loaders.</span>
<span class="sd">                In &#39;max_size_cycle&#39; mode, the trainer ends one epoch when the largest dataset is traversed,</span>
<span class="sd">                and smaller datasets reload when running out of their data. In &#39;min_size&#39; mode, all the datasets</span>
<span class="sd">                reload when reaching the minimum length of datasets.</span>
<span class="sd">                Default: ``&quot;max_size_cycle&quot;``.</span>

<span class="sd">            stochastic_weight_avg: Whether to use `Stochastic Weight Averaging (SWA)</span>
<span class="sd">                &lt;https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/&gt;`_.</span>
<span class="sd">                Default: ``False``.</span>

<span class="sd">                .. deprecated:: v1.5</span>
<span class="sd">                    ``stochastic_weight_avg`` has been deprecated in v1.5 and will be removed in v1.7.</span>
<span class="sd">                    Please pass :class:`~pytorch_lightning.callbacks.stochastic_weight_avg.StochasticWeightAveraging`</span>
<span class="sd">                    directly to the Trainer&#39;s ``callbacks`` argument instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;init&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: Initializing trainer with parameters: </span><span class="si">{</span><span class="nb">locals</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainerState</span><span class="p">()</span>

        <span class="c1"># init connectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span> <span class="o">=</span> <span class="n">DataConnector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">multiple_trainloader_mode</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_accelerator_connector</span> <span class="o">=</span> <span class="n">AcceleratorConnector</span><span class="p">(</span>
            <span class="n">num_processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">,</span>
            <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">,</span>
            <span class="n">tpu_cores</span><span class="o">=</span><span class="n">tpu_cores</span><span class="p">,</span>
            <span class="n">ipus</span><span class="o">=</span><span class="n">ipus</span><span class="p">,</span>
            <span class="n">accelerator</span><span class="o">=</span><span class="n">accelerator</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">,</span>
            <span class="n">gpus</span><span class="o">=</span><span class="n">gpus</span><span class="p">,</span>
            <span class="n">num_nodes</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span>
            <span class="n">sync_batchnorm</span><span class="o">=</span><span class="n">sync_batchnorm</span><span class="p">,</span>
            <span class="n">benchmark</span><span class="o">=</span><span class="n">benchmark</span><span class="p">,</span>
            <span class="n">replace_sampler_ddp</span><span class="o">=</span><span class="n">replace_sampler_ddp</span><span class="p">,</span>
            <span class="n">deterministic</span><span class="o">=</span><span class="n">deterministic</span><span class="p">,</span>
            <span class="n">auto_select_gpus</span><span class="o">=</span><span class="n">auto_select_gpus</span><span class="p">,</span>
            <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
            <span class="n">amp_type</span><span class="o">=</span><span class="n">amp_backend</span><span class="p">,</span>
            <span class="n">amp_level</span><span class="o">=</span><span class="n">amp_level</span><span class="p">,</span>
            <span class="n">plugins</span><span class="o">=</span><span class="n">plugins</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span> <span class="o">=</span> <span class="n">LoggerConnector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_gpu_memory</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_connector</span> <span class="o">=</span> <span class="n">CallbackConnector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span> <span class="o">=</span> <span class="n">CheckpointConnector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">resume_from_checkpoint</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signal_connector</span> <span class="o">=</span> <span class="n">SignalConnector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tuner</span> <span class="o">=</span> <span class="n">Tuner</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">min_steps</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">,</span> <span class="n">min_epochs</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">max_time</span> <span class="o">=</span> <span class="n">_parse_loop_limits</span><span class="p">(</span>
            <span class="n">min_steps</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">,</span> <span class="n">min_epochs</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">max_time</span>
        <span class="p">)</span>
        <span class="n">fit_loop</span> <span class="o">=</span> <span class="n">FitLoop</span><span class="p">(</span><span class="n">min_epochs</span><span class="o">=</span><span class="n">min_epochs</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>
        <span class="n">training_epoch_loop</span> <span class="o">=</span> <span class="n">TrainingEpochLoop</span><span class="p">(</span><span class="n">min_steps</span><span class="o">=</span><span class="n">min_steps</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">)</span>
        <span class="n">fit_loop</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">epoch_loop</span><span class="o">=</span><span class="n">training_epoch_loop</span><span class="p">)</span>

        <span class="c1"># default .fit() loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span> <span class="o">=</span> <span class="n">fit_loop</span>

        <span class="c1"># default .validate() loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_loop</span> <span class="o">=</span> <span class="n">EvaluationLoop</span><span class="p">()</span>

        <span class="c1"># default .test() loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loop</span> <span class="o">=</span> <span class="n">EvaluationLoop</span><span class="p">()</span>

        <span class="c1"># default .predict() loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_loop</span> <span class="o">=</span> <span class="n">PredictionLoop</span><span class="p">()</span>

        <span class="c1"># set when a checkpoint is loaded via `Trainer.{fit,validate,test,predict}`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># .validate(), predict() and .test() set these when they load a checkpoint. They will be removed in favor of</span>
        <span class="c1">#  the unified read-only `Trainer.ckpt_path` attribute in v1.8</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validated_ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># TODO: remove in v1.8</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tested_ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># TODO: remove in v1.8</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_predicted_ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># TODO: remove in v1.8</span>

        <span class="c1"># todo: remove in v1.7</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_summary</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># init callbacks</span>
        <span class="c1"># Declare attributes to be set in _callback_connector on_trainer_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_connector</span><span class="o">.</span><span class="n">on_trainer_init</span><span class="p">(</span>
            <span class="n">callbacks</span><span class="p">,</span>
            <span class="n">checkpoint_callback</span><span class="p">,</span>
            <span class="n">enable_checkpointing</span><span class="p">,</span>
            <span class="n">enable_progress_bar</span><span class="p">,</span>
            <span class="n">progress_bar_refresh_rate</span><span class="p">,</span>
            <span class="n">process_position</span><span class="p">,</span>
            <span class="n">default_root_dir</span><span class="p">,</span>
            <span class="n">weights_save_path</span><span class="p">,</span>
            <span class="n">enable_model_summary</span><span class="p">,</span>
            <span class="n">weights_summary</span><span class="p">,</span>
            <span class="n">stochastic_weight_avg</span><span class="p">,</span>
            <span class="n">max_time</span><span class="p">,</span>
            <span class="n">accumulate_grad_batches</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># hook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_init_start&quot;</span><span class="p">)</span>

        <span class="c1"># init data flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_val_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">on_trainer_init</span><span class="p">(</span>
            <span class="n">check_val_every_n_epoch</span><span class="p">,</span>
            <span class="n">reload_dataloaders_every_n_epochs</span><span class="p">,</span>
            <span class="n">prepare_data_per_node</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">terminate_on_nan</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank_zero_deprecation</span><span class="p">(</span>
                <span class="s2">&quot;Trainer argument `terminate_on_nan` was deprecated in v1.5 and will be removed in 1.7.&quot;</span>
                <span class="s2">&quot; Please use `Trainer(detect_anomaly=True)` instead.&quot;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">terminate_on_nan</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`terminate_on_nan` should be a bool, got </span><span class="si">{</span><span class="n">terminate_on_nan</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="c1"># gradient clipping</span>
        <span class="k">if</span> <span class="n">gradient_clip_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gradient_clip_val</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`gradient_clip_val` should be an int or a float. Got </span><span class="si">{</span><span class="n">gradient_clip_val</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">gradient_clip_algorithm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">GradClipAlgorithmType</span><span class="o">.</span><span class="n">supported_type</span><span class="p">(</span>
            <span class="n">gradient_clip_algorithm</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`gradient_clip_algorithm` </span><span class="si">{</span><span class="n">gradient_clip_algorithm</span><span class="si">}</span><span class="s2"> is invalid. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Allowed algorithms: </span><span class="si">{</span><span class="n">GradClipAlgorithmType</span><span class="o">.</span><span class="n">supported_types</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># gradient norm tracking</span>
        <span class="k">if</span> <span class="n">track_grad_norm</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">track_grad_norm</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">track_grad_norm</span> <span class="o">==</span> <span class="s2">&quot;inf&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">float</span><span class="p">(</span><span class="n">track_grad_norm</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`track_grad_norm` must be a positive number or &#39;inf&#39; (infinity norm). Got </span><span class="si">{</span><span class="n">track_grad_norm</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_terminate_on_nan</span> <span class="o">=</span> <span class="n">terminate_on_nan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clip_val</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">gradient_clip_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clip_algorithm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GradClipAlgorithmType</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">GradClipAlgorithmType</span><span class="p">(</span><span class="n">gradient_clip_algorithm</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="k">if</span> <span class="n">gradient_clip_algorithm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">track_grad_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">track_grad_norm</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_detect_anomaly</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">detect_anomaly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_on_init</span><span class="p">(</span><span class="n">num_sanity_val_steps</span><span class="p">)</span>

        <span class="c1"># configure tuner</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tuner</span><span class="o">.</span><span class="n">on_trainer_init</span><span class="p">(</span><span class="n">auto_lr_find</span><span class="p">,</span> <span class="n">auto_scale_batch_size</span><span class="p">)</span>

        <span class="c1"># configure profiler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__init_profiler</span><span class="p">(</span><span class="n">profiler</span><span class="p">)</span>

        <span class="c1"># init logger flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">on_trainer_init</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">flush_logs_every_n_steps</span><span class="p">,</span> <span class="n">log_every_n_steps</span><span class="p">,</span> <span class="n">move_metrics_to_cpu</span><span class="p">)</span>

        <span class="c1"># init debugging flags</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_debugging_flags</span><span class="p">(</span>
            <span class="n">limit_train_batches</span><span class="p">,</span>
            <span class="n">limit_val_batches</span><span class="p">,</span>
            <span class="n">limit_test_batches</span><span class="p">,</span>
            <span class="n">limit_predict_batches</span><span class="p">,</span>
            <span class="n">val_check_interval</span><span class="p">,</span>
            <span class="n">overfit_batches</span><span class="p">,</span>
            <span class="n">fast_dev_run</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Callback system</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_init_end&quot;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_init_debugging_flags</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">limit_train_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">limit_val_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">limit_test_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">limit_predict_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">val_check_interval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span>
        <span class="n">overfit_batches</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">fast_dev_run</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">fast_dev_run</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;fast_dev_run=</span><span class="si">{</span><span class="n">fast_dev_run</span><span class="si">}</span><span class="s2"> is not a valid configuration. It should be &gt;= 0.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fast_dev_run</span> <span class="o">=</span> <span class="n">fast_dev_run</span>

        <span class="c1"># set fast_dev_run=True when it is 1, used while logging</span>
        <span class="k">if</span> <span class="n">fast_dev_run</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fast_dev_run</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">fast_dev_run</span><span class="p">:</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="p">)</span>
            <span class="n">limit_train_batches</span> <span class="o">=</span> <span class="n">num_batches</span>
            <span class="n">limit_val_batches</span> <span class="o">=</span> <span class="n">num_batches</span>
            <span class="n">limit_test_batches</span> <span class="o">=</span> <span class="n">num_batches</span>
            <span class="n">limit_predict_batches</span> <span class="o">=</span> <span class="n">num_batches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">num_batches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">val_check_interval</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">check_val_every_n_epoch</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DummyLogger</span><span class="p">()]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>

            <span class="n">rank_zero_info</span><span class="p">(</span>
                <span class="s2">&quot;Running in fast_dev_run mode: will run a full train,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; val, test and prediction loop using </span><span class="si">{</span><span class="n">num_batches</span><span class="si">}</span><span class="s2"> batch(es).&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="p">,</span> <span class="s2">&quot;limit_train_batches&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_val_batches</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">limit_val_batches</span><span class="p">,</span> <span class="s2">&quot;limit_val_batches&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_test_batches</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">limit_test_batches</span><span class="p">,</span> <span class="s2">&quot;limit_test_batches&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_predict_batches</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">limit_predict_batches</span><span class="p">,</span> <span class="s2">&quot;limit_predict_batches&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">val_check_interval</span><span class="p">,</span> <span class="s2">&quot;val_check_interval&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">overfit_batches</span> <span class="o">=</span> <span class="n">_determine_batch_limits</span><span class="p">(</span><span class="n">overfit_batches</span><span class="p">,</span> <span class="s2">&quot;overfit_batches&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_determine_data_use_amount</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">overfit_batches</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_determine_data_use_amount</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">overfit_batches</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Use less data for debugging purposes.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">overfit_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span> <span class="o">=</span> <span class="n">overfit_batches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">limit_val_batches</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_setup_on_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_sanity_val_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_device_info</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">should_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainerState</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">num_sanity_val_steps</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_steps</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_steps</span> <span class="o">=</span> <span class="n">num_sanity_val_steps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_batches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_test_batches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_val_batches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_train_dl_reload_epoch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_val_dl_reload_epoch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_predict_batches</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_call_and_handle_interrupt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Error handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)</span>
<span class="sd">        as all errors should funnel through them</span>

<span class="sd">        Args:</span>
<span class="sd">            trainer_fn: one of (fit, validate, test, predict)</span>
<span class="sd">            *args: positional arguments to be passed to the `trainer_fn`</span>
<span class="sd">            **kwargs: keyword arguments to be passed to `trainer_fn`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">launcher</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">launcher</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">trainer_fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">trainer_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7</span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span> <span class="k">as</span> <span class="n">exception</span><span class="p">:</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span><span class="s2">&quot;Detected KeyboardInterrupt, attempting graceful shutdown...&quot;</span><span class="p">)</span>
            <span class="c1"># user could press Ctrl+c many times... only shutdown once</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">interrupted</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">INTERRUPTED</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_keyboard_interrupt&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_exception&quot;</span><span class="p">,</span> <span class="n">exception</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">BaseException</span> <span class="k">as</span> <span class="n">exception</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">INTERRUPTED</span>
            <span class="k">if</span> <span class="n">distributed_available</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># try syncing remaining processes, kill otherwise</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reconciliate_processes</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_exception&quot;</span><span class="p">,</span> <span class="n">exception</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_teardown</span><span class="p">()</span>
            <span class="c1"># teardown might access the stage so we reset it after</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">raise</span>

<div class="viewcode-block" id="Trainer.fit"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">,</span>
        <span class="n">train_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">TRAIN_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the full optimization routine.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: Model to fit.</span>

<span class="sd">            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a</span>
<span class="sd">                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.</span>
<span class="sd">                In the case of multiple dataloaders, please see this :ref:`section &lt;multiple-dataloaders&gt;`.</span>

<span class="sd">            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.</span>

<span class="sd">            ckpt_path: Path/URL of the checkpoint from which training is resumed. If there is</span>
<span class="sd">                no checkpoint file at the path, an exception is raised. If resuming from mid-epoch checkpoint,</span>
<span class="sd">                training will start from the beginning of the next epoch.</span>

<span class="sd">            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_and_handle_interrupt</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_impl</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">,</span> <span class="n">ckpt_path</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_fit_impl</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">,</span>
        <span class="n">train_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">TRAIN_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: trainer fit stage&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">RUNNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_train_dl_reload_epoch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_val_dl_reload_epoch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>

        <span class="c1"># if a datamodule comes in as the second arg, then fix it for the user</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_dataloaders</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">):</span>
            <span class="n">datamodule</span> <span class="o">=</span> <span class="n">train_dataloaders</span>
            <span class="n">train_dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># If you supply a datamodule you can&#39;t supply train_dataloader or val_dataloaders</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">train_dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">val_dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">datamodule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.fit(datamodule=...)`&quot;</span>
            <span class="p">)</span>

        <span class="c1"># links data to the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">attach_data</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_dataloaders</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">val_dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span>
        <span class="p">)</span>

        <span class="c1"># TODO: ckpt_path only in v2.0</span>
        <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_path</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">resume_from_checkpoint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__set_ckpt_path</span><span class="p">(</span>
            <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">model_provided</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">model_connected</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stopped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="Trainer.validate"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.validate">[docs]</a>    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_EVALUATE_OUTPUT</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform one evaluation epoch over the validation set.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model to validate.</span>

<span class="sd">            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,</span>
<span class="sd">                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying validation samples.</span>

<span class="sd">            ckpt_path: Either ``best`` or path to the checkpoint you wish to validate.</span>
<span class="sd">                If ``None`` and the model instance was passed, use the current weights.</span>
<span class="sd">                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded</span>
<span class="sd">                if a checkpoint callback is configured.</span>

<span class="sd">            verbose: If True, prints the validation results.</span>

<span class="sd">            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks</span>
<span class="sd">            like :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step`,</span>
<span class="sd">            :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_epoch_end`, etc.</span>
<span class="sd">            The length of the list corresponds to the number of validation dataloaders used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_and_handle_interrupt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_impl</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_validate_impl</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_EVALUATE_OUTPUT</span><span class="p">:</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># SETUP HOOK</span>
        <span class="c1"># --------------------</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: trainer validate stage&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">VALIDATING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">RUNNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validating</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># if a datamodule comes in as the second arg, then fix it for the user</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">):</span>
            <span class="n">datamodule</span> <span class="o">=</span> <span class="n">dataloaders</span>
            <span class="n">dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># If you supply a datamodule you can&#39;t supply val_dataloaders</span>
        <span class="k">if</span> <span class="n">dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">datamodule</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span><span class="s2">&quot;You cannot pass both `trainer.validate(dataloaders=..., datamodule=...)`&quot;</span><span class="p">)</span>

        <span class="n">model_provided</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;`model` must be provided to `trainer.validate()` when it hasn&#39;t been passed in a previous run&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">validate_loop</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># links data to the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">attach_data</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__set_ckpt_path</span><span class="p">(</span>
            <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">model_provided</span><span class="o">=</span><span class="n">model_provided</span><span class="p">,</span> <span class="n">model_connected</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_validated_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span>  <span class="c1"># TODO: remove in v1.8</span>

        <span class="c1"># run validate</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stopped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validating</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="Trainer.test"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.test">[docs]</a>    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_EVALUATE_OUTPUT</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform one evaluation epoch over the test set.</span>
<span class="sd">        It&#39;s separated from fit to make sure you never run on your test set until you want to.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model to test.</span>

<span class="sd">            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,</span>
<span class="sd">                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying test samples.</span>

<span class="sd">            ckpt_path: Either ``best`` or path to the checkpoint you wish to test.</span>
<span class="sd">                If ``None`` and the model instance was passed, use the current weights.</span>
<span class="sd">                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded</span>
<span class="sd">                if a checkpoint callback is configured.</span>

<span class="sd">            verbose: If True, prints the test results.</span>

<span class="sd">            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks</span>
<span class="sd">            like :meth:`~pytorch_lightning.core.lightning.LightningModule.test_step`,</span>
<span class="sd">            :meth:`~pytorch_lightning.core.lightning.LightningModule.test_epoch_end`, etc.</span>
<span class="sd">            The length of the list corresponds to the number of test dataloaders used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_and_handle_interrupt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_impl</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_test_impl</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_EVALUATE_OUTPUT</span><span class="p">:</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># SETUP HOOK</span>
        <span class="c1"># --------------------</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: trainer test stage&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">TESTING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">RUNNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># if a datamodule comes in as the second arg, then fix it for the user</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">):</span>
            <span class="n">datamodule</span> <span class="o">=</span> <span class="n">dataloaders</span>
            <span class="n">dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># If you supply a datamodule you can&#39;t supply test_dataloaders</span>
        <span class="k">if</span> <span class="n">dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">datamodule</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span><span class="s2">&quot;You cannot pass both `trainer.test(dataloaders=..., datamodule=...)`&quot;</span><span class="p">)</span>

        <span class="n">model_provided</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;`model` must be provided to `trainer.test()` when it hasn&#39;t been passed in a previous run&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_loop</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># links data to the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">attach_data</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataloaders</span><span class="o">=</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__set_ckpt_path</span><span class="p">(</span>
            <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">model_provided</span><span class="o">=</span><span class="n">model_provided</span><span class="p">,</span> <span class="n">model_connected</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_tested_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span>  <span class="c1"># TODO: remove in v1.8</span>

        <span class="c1"># run test</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stopped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="Trainer.predict"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_predictions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_PREDICT_OUTPUT</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run inference on your data.</span>
<span class="sd">        This will call the model forward function to compute predictions. Useful to perform distributed</span>
<span class="sd">        and batched predictions. Logging is disabled in the predict hooks.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model to predict with.</span>

<span class="sd">            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them,</span>
<span class="sd">                or a :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying prediction samples.</span>

<span class="sd">            datamodule: The datamodule with a predict_dataloader method that returns one or more dataloaders.</span>

<span class="sd">            return_predictions: Whether to return predictions.</span>
<span class="sd">                ``True`` by default except when an accelerator that spawns processes is used (not supported).</span>

<span class="sd">            ckpt_path: Either ``best`` or path to the checkpoint you wish to predict.</span>
<span class="sd">                If ``None`` and the model instance was passed, use the current weights.</span>
<span class="sd">                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded</span>
<span class="sd">                if a checkpoint callback is configured.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_and_handle_interrupt</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_predict_impl</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">,</span> <span class="n">return_predictions</span><span class="p">,</span> <span class="n">ckpt_path</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_predict_impl</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_predictions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_PREDICT_OUTPUT</span><span class="p">]:</span>
        <span class="c1"># --------------------</span>
        <span class="c1"># SETUP HOOK</span>
        <span class="c1"># --------------------</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: trainer predict stage&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">PREDICTING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">RUNNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predicting</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">predict_loop</span><span class="o">.</span><span class="n">return_predictions</span> <span class="o">=</span> <span class="n">return_predictions</span>

        <span class="c1"># if a datamodule comes in as the second arg, then fix it for the user</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">):</span>
            <span class="n">datamodule</span> <span class="o">=</span> <span class="n">dataloaders</span>
            <span class="n">dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">datamodule</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span><span class="s2">&quot;You cannot pass both `trainer.predict(dataloaders=..., datamodule=...)`&quot;</span><span class="p">)</span>

        <span class="n">model_provided</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;`model` must be provided to `trainer.predict()` when it hasn&#39;t been passed in a previous run&quot;</span>
            <span class="p">)</span>

        <span class="c1"># links data to the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">attach_data</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">predict_dataloaders</span><span class="o">=</span><span class="n">dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__set_ckpt_path</span><span class="p">(</span>
            <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">model_provided</span><span class="o">=</span><span class="n">model_provided</span><span class="p">,</span> <span class="n">model_connected</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_predicted_ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span>  <span class="c1"># TODO: remove in v1.8</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stopped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predicting</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="Trainer.tune"><a class="viewcode-back" href="../../../common/trainer.html#pytorch_lightning.trainer.Trainer.tune">[docs]</a>    <span class="k">def</span> <span class="nf">tune</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">,</span>
        <span class="n">train_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">TRAIN_DATALOADERS</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_dataloaders</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EVAL_DATALOADERS</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">datamodule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningDataModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">scale_batch_size_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lr_find_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_LRFinder</span><span class="p">]]]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs routines to tune hyperparameters before training.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: Model to tune.</span>

<span class="sd">            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a</span>
<span class="sd">                :class:`~pytorch_lightning.core.datamodule.LightningDataModule` specifying training samples.</span>
<span class="sd">                In the case of multiple dataloaders, please see this :ref:`section &lt;multiple-dataloaders&gt;`.</span>

<span class="sd">            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.</span>

<span class="sd">            datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.</span>

<span class="sd">            scale_batch_size_kwargs: Arguments for :func:`~pytorch_lightning.tuner.batch_size_scaling.scale_batch_size`</span>

<span class="sd">            lr_find_kwargs: Arguments for :func:`~pytorch_lightning.tuner.lr_finder.lr_find`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Trainer</span><span class="o">.</span><span class="n">_log_api_event</span><span class="p">(</span><span class="s2">&quot;tune&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">TUNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">RUNNING</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tuning</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># if a datamodule comes in as the second arg, then fix it for the user</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_dataloaders</span><span class="p">,</span> <span class="n">LightningDataModule</span><span class="p">):</span>
            <span class="n">datamodule</span> <span class="o">=</span> <span class="n">train_dataloaders</span>
            <span class="n">train_dataloaders</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># If you supply a datamodule you can&#39;t supply train_dataloader or val_dataloaders</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">train_dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">val_dataloaders</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">datamodule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;You cannot pass `train_dataloader` or `val_dataloaders` to `trainer.tune(datamodule=...)`&quot;</span>
            <span class="p">)</span>

        <span class="c1"># links data to the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">attach_data</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_dataloaders</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">val_dataloaders</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="n">isolate_rng</span><span class="p">():</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tuner</span><span class="o">.</span><span class="n">_tune</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">scale_batch_size_kwargs</span><span class="o">=</span><span class="n">scale_batch_size_kwargs</span><span class="p">,</span> <span class="n">lr_find_kwargs</span><span class="o">=</span><span class="n">lr_find_kwargs</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stopped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tuning</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="n">result</span></div>

    <span class="k">def</span> <span class="nf">_restore_modules_and_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_PATH</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># restore modules after setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">resume_start</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">_restore_quantization_callbacks</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">restore_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">restore_datamodule</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span><span class="p">:</span>
            <span class="c1"># restore callback states</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">restore_callbacks</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">_EVALUATE_OUTPUT</span><span class="p">,</span> <span class="n">_PREDICT_OUTPUT</span><span class="p">]]:</span>
        <span class="c1"># clean hparams</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;hparams&quot;</span><span class="p">):</span>
            <span class="n">parsing</span><span class="o">.</span><span class="n">clean_namespace</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span><span class="p">)</span>

        <span class="c1"># attach model to the strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_connector</span><span class="o">.</span><span class="n">_attach_model_callbacks</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback_connector</span><span class="o">.</span><span class="n">_attach_model_logging_functions</span><span class="p">()</span>

        <span class="n">verify_loop_configurations</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># hook</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: preparing data&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>

        <span class="c1"># ----------------------------</span>
        <span class="c1"># SET UP TRAINING</span>
        <span class="c1"># ----------------------------</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_before_accelerator_backend_setup&quot;</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: setting up strategy environment&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">setup_environment</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__setup_profiler</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_setup_hook</span><span class="p">()</span>  <span class="c1"># allow user to setup lightning_module in accelerator environment</span>

        <span class="c1"># check if we should delay restoring checkpoint till later</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">restore_checkpoint_after_setup</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: restoring module and callbacks from checkpoint path: </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_restore_modules_and_callbacks</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: configuring sharded model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_configure_sharded_model</span><span class="p">()</span>  <span class="c1"># allow user to setup in model sharded environment</span>

        <span class="c1"># ----------------------------</span>
        <span class="c1"># INSPECT THE CORE LOOPS</span>
        <span class="c1"># ----------------------------</span>
        <span class="sa">rf</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">             Lightning internal flow looks like this:</span>
<span class="s2">        </span><span class="si">{</span><span class="n">Trainer</span><span class="o">.</span><span class="n">fit</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">Trainer</span><span class="o">.</span><span class="n">test</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">Trainer</span><span class="o">.</span><span class="n">predict</span><span class="si">}</span><span class="s2">  ||</span>
<span class="s2">                                |                             ||</span>
<span class="s2">                         spawn processes                      ||</span>
<span class="s2">                 </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">setup_environment</span><span class="si">}</span><span class="s2">            ||</span>
<span class="s2">                                |                             ||</span>
<span class="s2">                        setup accelerator                     ||</span>
<span class="s2">                           and strategy                       ||  LIGHTNING</span>
<span class="s2">                                |                             ||</span>
<span class="s2">                        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_stage</span><span class="si">}</span><span class="s2">                     ||  FLOW</span>
<span class="s2">                                |                             ||</span>
<span class="s2">                        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_train</span><span class="si">}</span><span class="s2">                     ||  DIRECTION</span>
<span class="s2">                     or </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_evaluate</span><span class="si">}</span><span class="s2">                  ||</span>
<span class="s2">                     or </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_predict</span><span class="si">}</span><span class="s2">                   ||</span>
<span class="s2">                                |                             ||</span>
<span class="s2">                             results                          \/</span>
<span class="s2">        This is used to guide readers to the core loops: train, test, predict.</span>
<span class="s2">        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_run_predict</span><span class="si">}</span><span class="s2"> is the simplest to understand, use `Go to Definition` to read it :)</span>
<span class="s2">        &quot;&quot;&quot;</span>

        <span class="c1"># ----------------------------</span>
        <span class="c1"># TRAIN</span>
        <span class="c1"># ----------------------------</span>

        <span class="c1"># reset logger connector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_results</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="c1"># strategy will configure model and move it to the device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># hook</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_fit_start&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;on_fit_start&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_log_hyperparams</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">restore_checkpoint_after_setup</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: restoring module and callbacks from checkpoint path: </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_restore_modules_and_callbacks</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">)</span>

        <span class="c1"># restore optimizers, etc.</span>
        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: restoring training state&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">restore_training_state</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">resume_end</span><span class="p">()</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_stage</span><span class="p">()</span>

        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: trainer tearing down&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_teardown</span><span class="p">()</span>

        <span class="c1"># ----------------------------</span>
        <span class="c1"># POST-Training CLEAN UP</span>
        <span class="c1"># ----------------------------</span>
        <span class="c1"># hook</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_fit_end&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;on_fit_end&quot;</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">detail</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: calling teardown hooks&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_teardown_hook</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">=</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">FINISHED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">_log_hyperparams</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># log hyper-parameters</span>
        <span class="n">hparams_initial</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># save exp to get started (this is where the first experiment logs are written)</span>
        <span class="n">datamodule_log_hyperparams</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">_log_hyperparams</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">_log_hyperparams</span> <span class="ow">and</span> <span class="n">datamodule_log_hyperparams</span><span class="p">:</span>
            <span class="n">datamodule_hparams</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">hparams_initial</span>
            <span class="n">lightning_hparams</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">hparams_initial</span>
            <span class="n">inconsistent_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">lightning_hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">datamodule_hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">lm_val</span><span class="p">,</span> <span class="n">dm_val</span> <span class="o">=</span> <span class="n">lightning_hparams</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">datamodule_hparams</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">lm_val</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">dm_val</span><span class="p">):</span>
                    <span class="n">inconsistent_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_val</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">id</span><span class="p">(</span><span class="n">lm_val</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">id</span><span class="p">(</span><span class="n">dm_val</span><span class="p">):</span>
                    <span class="n">inconsistent_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">lm_val</span> <span class="o">!=</span> <span class="n">dm_val</span><span class="p">:</span>
                    <span class="n">inconsistent_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">inconsistent_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Error while merging hparams: the keys </span><span class="si">{</span><span class="n">inconsistent_keys</span><span class="si">}</span><span class="s2"> are present &quot;</span>
                    <span class="s2">&quot;in both the LightningModule&#39;s and LightningDataModule&#39;s hparams &quot;</span>
                    <span class="s2">&quot;but have different values.&quot;</span>
                <span class="p">)</span>
            <span class="n">hparams_initial</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">lightning_hparams</span><span class="p">,</span> <span class="o">**</span><span class="n">datamodule_hparams</span><span class="p">}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">_log_hyperparams</span><span class="p">:</span>
            <span class="n">hparams_initial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">hparams_initial</span>
        <span class="k">elif</span> <span class="n">datamodule_log_hyperparams</span><span class="p">:</span>
            <span class="n">hparams_initial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">hparams_initial</span>

        <span class="k">for</span> <span class="n">logger</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hparams_initial</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">log_hyperparams</span><span class="p">(</span><span class="n">hparams_initial</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">log_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This is the Trainer&#39;s internal teardown, unrelated to the `teardown` hooks in LightningModule and</span>
<span class="sd">        Callback; those are handled by :meth:`_call_teardown_hook`.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">post_dispatch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_active_loop</span>
        <span class="c1"># loop should never be `None` here but it can because we don&#39;t know the trainer stage with `ddp_spawn`</span>
        <span class="k">if</span> <span class="n">loop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signal_connector</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">run_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.run_stage` is deprecated in v1.6 and will be removed in v1.8. Use&quot;</span>
            <span class="s2">&quot; `Trainer.{fit,validate,test,predict}` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_stage</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_run_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="s2">&quot;run-stage&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluating</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_evaluate</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicting</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_predict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_train</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_pre_training_routine</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># wait for all to join if on distributed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="s2">&quot;setup_training&quot;</span><span class="p">)</span>

        <span class="c1"># register signals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signal_connector</span><span class="o">.</span><span class="n">register_signal_handlers</span><span class="p">()</span>

        <span class="c1"># --------------------------</span>
        <span class="c1"># Pre-train</span>
        <span class="c1"># --------------------------</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_pretrain_routine_start&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;on_pretrain_routine_start&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_pretrain_routine_end&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;on_pretrain_routine_end&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_run_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pre_training_routine</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">isolate_rng</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_sanity_check</span><span class="p">()</span>

        <span class="c1"># enable train mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_detect_anomaly</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_run_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_EVALUATE_OUTPUT</span><span class="p">:</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluating</span>

        <span class="c1"># reload dataloaders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_loop</span><span class="o">.</span><span class="n">_reload_evaluation_dataloaders</span><span class="p">()</span>

        <span class="c1"># reset trainer on this loop and all child loops in case user connected a custom loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span><span class="si">}</span><span class="s2">_evaluation&quot;</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">eval_loop_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_loop</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

        <span class="c1"># remove the tensors from the eval results</span>
        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">eval_loop_results</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                        <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">eval_loop_results</span>

    <span class="k">def</span> <span class="nf">_run_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_PREDICT_OUTPUT</span><span class="p">]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">)</span>
        <span class="c1"># reset trainer on this loop and all child loops in case user connected a custom loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_loop</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_run_sanity_check</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">val_loop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">val_loop</span>

        <span class="n">should_sanity_check</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enable_validation</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_steps</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="c1"># do not sanity check if restarting because it would mess up the loaded state</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">val_loop</span><span class="o">.</span><span class="n">restarting</span>
        <span class="p">)</span>

        <span class="c1"># run tiny validation (if validation defined)</span>
        <span class="c1"># to make sure program won&#39;t crash during val</span>
        <span class="k">if</span> <span class="n">should_sanity_check</span><span class="p">:</span>
            <span class="n">stage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sanity_checking</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># reset logger connector</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_results</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_sanity_check_start&quot;</span><span class="p">)</span>

            <span class="c1"># reload dataloaders</span>
            <span class="n">val_loop</span><span class="o">.</span><span class="n">_reload_evaluation_dataloaders</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_sanity_val_steps</span><span class="p">,</span> <span class="n">val_batches</span><span class="p">)</span> <span class="k">for</span> <span class="n">val_batches</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_val_batches</span>
            <span class="p">]</span>

            <span class="c1"># run eval step</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">val_loop</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_sanity_check_end&quot;</span><span class="p">)</span>

            <span class="c1"># reset logger connector</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_results</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

            <span class="c1"># reset the progress tracking state after sanity checking. we don&#39;t need to set the state before</span>
            <span class="c1"># because sanity check only runs when we are not restarting</span>
            <span class="n">_reset_progress</span><span class="p">(</span><span class="n">val_loop</span><span class="p">)</span>

            <span class="c1"># restore the previous stage when the sanity check if finished</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">stage</span>

    <span class="k">def</span> <span class="nf">__set_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">model_provided</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">model_connected</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="c1"># fault-tolerance takes precedence</span>
        <span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks.fault_tolerance</span> <span class="kn">import</span> <span class="n">_FaultToleranceCheckpoint</span>

        <span class="n">ft_checkpoints</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">_FaultToleranceCheckpoint</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">ft_checkpoints</span><span class="p">:</span>
            <span class="n">ft_ckpt_path</span> <span class="o">=</span> <span class="n">ft_checkpoints</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ckpt_path</span>
            <span class="n">fs</span> <span class="o">=</span> <span class="n">get_filesystem</span><span class="p">(</span><span class="n">ft_ckpt_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fs</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ft_ckpt_path</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">ft_ckpt_path</span>

        <span class="k">if</span> <span class="n">model_provided</span> <span class="ow">and</span> <span class="n">ckpt_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># use passed model to function without loading weights</span>
            <span class="k">return</span>

        <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">value</span>

        <span class="k">if</span> <span class="n">model_connected</span> <span class="ow">and</span> <span class="n">ckpt_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">(ckpt_path=None)` was called without a model.&quot;</span>
                <span class="s2">&quot; The best model of the previous `fit` call will be used.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; You can pass `</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">(ckpt_path=&#39;best&#39;)` to use and best model&quot;</span>
                <span class="s2">&quot; checkpoint and avoid this warning or&quot;</span>
                <span class="s2">&quot; `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.&quot;</span>
            <span class="p">)</span>
            <span class="n">ckpt_path</span> <span class="o">=</span> <span class="s2">&quot;best&quot;</span>

        <span class="k">if</span> <span class="n">ckpt_path</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_callbacks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">rank_zero_warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;`.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s1">(ckpt_path=&quot;best&quot;)` is called with Trainer configured with multiple `ModelCheckpoint`&#39;</span>
                    <span class="s2">&quot; callbacks. It will use the best checkpoint path from first checkpoint callback.&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;`.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s1">(ckpt_path=&quot;best&quot;)` is set but `ModelCheckpoint` is not configured.&#39;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fast_dev_run</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;You cannot execute `.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s1">(ckpt_path=&quot;best&quot;)` with `fast_dev_run=True`.&#39;</span>
                        <span class="sa">f</span><span class="s2">&quot; Please pass an exact checkpoint path to `.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">(ckpt_path=...)`&quot;</span>
                    <span class="p">)</span>
                <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;`.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s1">(ckpt_path=&quot;best&quot;)` is set but `ModelCheckpoint` is not configured to save the best model.&#39;</span>
                <span class="p">)</span>
            <span class="c1"># load best weights</span>
            <span class="n">ckpt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ckpt_path</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">()` found no path for the best weights: </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">!r}</span><span class="s2">. Please&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; specify a path for a checkpoint `.</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">(ckpt_path=PATH)`&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">ckpt_path</span>

    <span class="k">def</span> <span class="nf">_call_setup_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">_setup_fn</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="s2">&quot;pre_setup&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;setup&quot;</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;setup&quot;</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="s2">&quot;post_setup&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_configure_sharded_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model_sharded_context</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_meta_model</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;configure_sharded_model&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;on_configure_sharded_model&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_handle_meta_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_on_meta_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">DDPSpawnStrategy</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span><span class="s2">&quot;LightningModule on meta device isn&#39;t supported with spawn.&quot;</span><span class="p">)</span>

        <span class="n">materialize_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">)</span>
        <span class="c1"># the trainer reference is lost during materialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_teardown_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">_setup_fn</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span><span class="o">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_call_callback_hooks</span><span class="p">(</span><span class="s2">&quot;teardown&quot;</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_lightning_module_hook</span><span class="p">(</span><span class="s2">&quot;teardown&quot;</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="n">fn</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># these could have become stale if metrics are defined in `setup`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">_metric_attributes</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># todo: TPU 8 cores hangs in flush with TensorBoard. Might do for all loggers.</span>
        <span class="c1"># It might be related to xla tensors blocked when moving the cpu kill loggers.</span>
        <span class="k">for</span> <span class="n">logger</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="s2">&quot;success&quot;</span><span class="p">)</span>

        <span class="c1"># summarize profile results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        .. deprecated:: v1.6</span>
<span class="sd">            The Trainer&#39;s `call_hook` method was deprecated in v1.6 and will be removed in v1.8.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;The Trainer&#39;s `call_hook` method was deprecated in v1.6 and will be removed in v1.8.&quot;</span><span class="p">)</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="n">pl_module</span>
        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">hook_name</span>

        <span class="c1"># always profile hooks</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">hook_name</span><span class="p">):</span>

            <span class="c1"># first call trainer hook</span>
            <span class="n">callback_fx</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">callback_fx</span><span class="p">):</span>
                <span class="n">callback_fx</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="c1"># next call hook in lightningModule</span>
            <span class="n">output</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">model_fx</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pl_module</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">model_fx</span><span class="p">):</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model_fx</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="c1"># call the strategy hook</span>
            <span class="k">if</span> <span class="n">hook_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;setup&quot;</span><span class="p">,</span> <span class="s2">&quot;teardown&quot;</span><span class="p">,</span> <span class="s2">&quot;on_train_start&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">):</span>
                <span class="n">strategy_hook</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
                <span class="n">strategy_output</span> <span class="o">=</span> <span class="n">strategy_hook</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">strategy_output</span> <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="c1"># restore current_fx when nested context</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">_call_lightning_module_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hook_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">pl_module</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="n">pl_module</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>

        <span class="k">if</span> <span class="n">pl_module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;No Lightning Module is available to call hooks on&quot;</span><span class="p">)</span>

        <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pl_module</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
        <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">hook_name</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[LightningModule]</span><span class="si">{</span><span class="n">pl_module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">hook_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># restore current_fx when nested context</span>
        <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">_call_callback_hooks</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hook_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: calling callback hook: </span><span class="si">{</span><span class="n">hook_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TODO: remove if block in v1.8</span>
        <span class="k">if</span> <span class="n">hook_name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;on_init_start&quot;</span><span class="p">,</span> <span class="s2">&quot;on_init_end&quot;</span><span class="p">):</span>
            <span class="c1"># these `Callback` hooks are the only ones that do not take a lightning module.</span>
            <span class="c1"># we also don&#39;t profile bc profiler hasn&#39;t been set yet</span>
            <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
                <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
                    <span class="n">fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">hook_name</span>

        <span class="c1"># TODO: remove if block in v1.7</span>
        <span class="k">if</span> <span class="n">hook_name</span> <span class="o">==</span> <span class="s2">&quot;on_train_batch_start&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">hook_name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_batch_start</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">hook_name</span> <span class="o">==</span> <span class="s2">&quot;on_train_batch_end&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">hook_name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_on_train_batch_end</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
                <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Callback]</span><span class="si">{</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">hook_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                        <span class="n">fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="c1"># restore current_fx when nested context</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

    <span class="c1"># TODO: Delete this in v1.7 (deprecations: #9816 and #11148)</span>
    <span class="k">def</span> <span class="nf">_on_train_batch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Called when the training batch begins. This function is needed because of two different deprecations affecting</span>
<span class="sd">        the original function in TrainerCallbackHookMixin: #9816 and #11148.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_param_in_hook_signature</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_start</span><span class="p">,</span> <span class="s2">&quot;dataloader_idx&quot;</span><span class="p">,</span> <span class="n">explicit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

    <span class="c1"># TODO: Delete this in v1.7 (deprecations: #9816 and #11148)</span>
    <span class="k">def</span> <span class="nf">_on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">STEP_OUTPUT</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Called when the training batch ends. This function is needed because of two different deprecations affecting</span>
<span class="sd">        the original function in TrainerCallbackHookMixin: #9816 and #11148.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_param_in_hook_signature</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">,</span> <span class="s2">&quot;dataloader_idx&quot;</span><span class="p">,</span> <span class="n">explicit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_callbacks_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Called when saving a model checkpoint, calls and returns every callback&#39;s `state_dict`, keyed by</span>
<span class="sd">        `Callback.state_key`.&quot;&quot;&quot;</span>
        <span class="n">callback_state_dicts</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">callback</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">state_dict</span><span class="p">:</span>
                <span class="n">callback_state_dicts</span><span class="p">[</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span>
        <span class="k">return</span> <span class="n">callback_state_dicts</span>

    <span class="k">def</span> <span class="nf">_call_callbacks_on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Called when saving a model checkpoint, calls every callback&#39;s `on_save_checkpoint` hook.</span>

<span class="sd">        Will be removed in v1.8: If state is returned, we insert the callback state into</span>
<span class="sd">        ``checkpoint[&quot;callbacks&quot;][Callback.state_key]``. It overrides ``state_dict`` if already present.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="s2">&quot;on_save_checkpoint&quot;</span>

        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Callback]</span><span class="si">{</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="si">}</span><span class="s2">.on_save_checkpoint&quot;</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">callback</span><span class="o">.</span><span class="n">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">state</span><span class="p">:</span>
                <span class="n">rank_zero_deprecation</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Returning a value from `</span><span class="si">{</span><span class="n">callback</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.on_save_checkpoint` is deprecated in v1.6&quot;</span>
                    <span class="s2">&quot; and will be removed in v1.8. Please override `Callback.state_dict`&quot;</span>
                    <span class="s2">&quot; to return state to be saved.&quot;</span>
                <span class="p">)</span>
                <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;callbacks&quot;</span><span class="p">][</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span>

        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="c1"># restore current_fx when nested context</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

    <span class="k">def</span> <span class="nf">_call_callbacks_on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Called when loading a model checkpoint.</span>

<span class="sd">        Calls every callback&#39;s `on_load_checkpoint` hook. We have a dedicated function for this rather than using</span>
<span class="sd">        `_call_callback_hooks` because we have special logic for getting callback_states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="s2">&quot;on_load_checkpoint&quot;</span>

        <span class="n">callback_states</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">is_legacy_ckpt</span> <span class="o">=</span> <span class="n">Version</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;pytorch-lightning_version&quot;</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.5.0dev&quot;</span><span class="p">)</span>
        <span class="n">current_callbacks_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">cb</span><span class="o">.</span><span class="n">_legacy_state_key</span> <span class="k">if</span> <span class="n">is_legacy_ckpt</span> <span class="k">else</span> <span class="n">cb</span><span class="o">.</span><span class="n">state_key</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">}</span>
        <span class="n">difference</span> <span class="o">=</span> <span class="n">callback_states</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">-</span> <span class="n">current_callbacks_keys</span>
        <span class="k">if</span> <span class="n">difference</span><span class="p">:</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;Be aware that when using `ckpt_path`,&quot;</span>
                <span class="s2">&quot; callbacks used to create the checkpoint need to be provided during `Trainer` instantiation.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; Please add the following callbacks: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">callback_states</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="p">,</span> <span class="n">callback_states</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">_legacy_state_key</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">state</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Callback]</span><span class="si">{</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="si">}</span><span class="s2">.on_load_checkpoint&quot;</span><span class="p">):</span>
                    <span class="n">callback</span><span class="o">.</span><span class="n">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pl_module</span><span class="p">:</span>
            <span class="c1"># restore current_fx when nested context</span>
            <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

    <span class="k">def</span> <span class="nf">_call_callbacks_load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Called when loading a model checkpoint, calls every callback&#39;s `load_state_dict`.&quot;&quot;&quot;</span>
        <span class="n">callback_states</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">callback_states</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">state_key</span><span class="p">,</span> <span class="n">callback_states</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">_legacy_state_key</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">state</span><span class="p">:</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">callback</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_call_strategy_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hook_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="n">prev_fx_name</span> <span class="o">=</span> <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span>
        <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">hook_name</span>

        <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Strategy]</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">hook_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># restore current_fx when nested context</span>
        <span class="n">pl_module</span><span class="o">.</span><span class="n">_current_fx_name</span> <span class="o">=</span> <span class="n">prev_fx_name</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_log_api_event</span><span class="p">(</span><span class="n">event</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;lightning.trainer.&quot;</span> <span class="o">+</span> <span class="n">event</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__init_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">profiler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Profiler</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profiler</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">PROFILERS</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;simple&quot;</span><span class="p">:</span> <span class="n">SimpleProfiler</span><span class="p">,</span>
                <span class="s2">&quot;advanced&quot;</span><span class="p">:</span> <span class="n">AdvancedProfiler</span><span class="p">,</span>
                <span class="s2">&quot;pytorch&quot;</span><span class="p">:</span> <span class="n">PyTorchProfiler</span><span class="p">,</span>
                <span class="s2">&quot;xla&quot;</span><span class="p">:</span> <span class="n">XLAProfiler</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">profiler</span> <span class="o">=</span> <span class="n">profiler</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">profiler</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PROFILERS</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                    <span class="s2">&quot;When passing string value for the `profiler` parameter of `Trainer`,&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; it can only be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">PROFILERS</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="n">profiler_class</span> <span class="o">=</span> <span class="n">PROFILERS</span><span class="p">[</span><span class="n">profiler</span><span class="p">]</span>
            <span class="n">profiler</span> <span class="o">=</span> <span class="n">profiler_class</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="p">:</span> <span class="n">Profiler</span> <span class="o">=</span> <span class="n">profiler</span> <span class="ow">or</span> <span class="n">PassThroughProfiler</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__setup_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">local_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">_lightning_module</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">_setup_fn</span><span class="p">,</span> <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_device_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;GPU available: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">, used: </span><span class="si">{</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="n">num_tpu_cores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">TPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">rank_zero_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TPU available: </span><span class="si">{</span><span class="n">_TPU_AVAILABLE</span><span class="si">}</span><span class="s2">, using: </span><span class="si">{</span><span class="n">num_tpu_cores</span><span class="si">}</span><span class="s2"> TPU cores&quot;</span><span class="p">)</span>

        <span class="n">num_ipus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">IPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">rank_zero_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;IPU available: </span><span class="si">{</span><span class="n">_IPU_AVAILABLE</span><span class="si">}</span><span class="s2">, using: </span><span class="si">{</span><span class="n">num_ipus</span><span class="si">}</span><span class="s2"> IPUs&quot;</span><span class="p">)</span>

        <span class="n">num_hpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">HPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">rank_zero_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;HPU available: </span><span class="si">{</span><span class="n">_HPU_AVAILABLE</span><span class="si">}</span><span class="s2">, using: </span><span class="si">{</span><span class="n">num_hpus</span><span class="si">}</span><span class="s2"> HPUs&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">):</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;GPU available but not used. Set `accelerator` and `devices` using&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; `Trainer(accelerator=&#39;gpu&#39;, devices=</span><span class="si">{</span><span class="n">GPUAccelerator</span><span class="o">.</span><span class="n">auto_device_count</span><span class="p">()</span><span class="si">}</span><span class="s2">)`.&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="n">PossibleUserWarning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">_TPU_AVAILABLE</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">TPUAccelerator</span><span class="p">):</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;TPU available but not used. Set `accelerator` and `devices` using&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; `Trainer(accelerator=&#39;tpu&#39;, devices=</span><span class="si">{</span><span class="n">TPUAccelerator</span><span class="o">.</span><span class="n">auto_device_count</span><span class="p">()</span><span class="si">}</span><span class="s2">)`.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">_IPU_AVAILABLE</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">IPUAccelerator</span><span class="p">):</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;IPU available but not used. Set `accelerator` and `devices` using&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; `Trainer(accelerator=&#39;ipu&#39;, devices=</span><span class="si">{</span><span class="n">IPUAccelerator</span><span class="o">.</span><span class="n">auto_device_count</span><span class="p">()</span><span class="si">}</span><span class="s2">)`.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">_HPU_AVAILABLE</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">HPUAccelerator</span><span class="p">):</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;HPU available but not used. Set `accelerator` and `devices` using&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; `Trainer(accelerator=&#39;hpu&#39;, devices=</span><span class="si">{</span><span class="n">HPUAccelerator</span><span class="o">.</span><span class="n">auto_device_count</span><span class="p">()</span><span class="si">}</span><span class="s2">)`.&quot;</span>
            <span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data loading methods</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">reset_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Resets the train dataloader and initialises required variables (number of batches, when to validate,</span>
<span class="sd">        etc.).</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The ``LightningModule`` if calling this outside of the trainer scope.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_train_dataloader_source</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="n">model</span>
        <span class="n">has_step</span> <span class="o">=</span> <span class="n">is_overridden</span><span class="p">(</span><span class="s2">&quot;training_step&quot;</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">)</span>
        <span class="n">enable_training</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">source</span><span class="o">.</span><span class="n">is_defined</span><span class="p">()</span> <span class="ow">and</span> <span class="n">has_step</span> <span class="ow">and</span> <span class="n">enable_training</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_request_dataloader</span><span class="p">(</span><span class="n">RunningStage</span><span class="o">.</span><span class="n">TRAINING</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">overfit_batches</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_resolve_overfit_batches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span>

        <span class="c1"># automatically add samplers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">apply_to_collection</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">,</span>
            <span class="p">(</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">CombinedLoader</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_prepare_dataloader</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">RunningStage</span><span class="o">.</span><span class="n">TRAINING</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">loaders</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="o">.</span><span class="n">loaders</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">CombinedLoader</span><span class="p">)</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span>
        <span class="p">)</span>

        <span class="c1"># check the workers recursively</span>
        <span class="n">apply_to_collection</span><span class="p">(</span><span class="n">loaders</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_worker_check</span><span class="p">,</span> <span class="s2">&quot;train_dataloader&quot;</span><span class="p">)</span>

        <span class="c1"># add worker_init_fn for correct seeding in worker processes</span>
        <span class="n">apply_to_collection</span><span class="p">(</span><span class="n">loaders</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">_auto_add_worker_init_fn</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_rank</span><span class="p">)</span>

        <span class="c1"># add collate_fn to collect metadata for fault tolerant training</span>
        <span class="k">if</span> <span class="n">_fault_tolerant_training</span><span class="p">():</span>
            <span class="n">apply_to_collection</span><span class="p">(</span><span class="n">loaders</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">_add_capture_metadata_collate</span><span class="p">)</span>

        <span class="c1"># wrap the sequence of train loaders to a CombinedLoader object for computing the num_training_batches</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">CombinedLoader</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">CombinedLoader</span><span class="p">(</span><span class="n">loaders</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">multiple_trainloader_mode</span><span class="p">)</span>

        <span class="n">module</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">datamodule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">has_len_all_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
            <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">!=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_train_batches</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;When using an IterableDataset for `limit_train_batches`,&quot;</span>
                <span class="s2">&quot; `Trainer(limit_train_batches)` must be `1.0` or an int. An int k specifies&quot;</span>
                <span class="s2">&quot; `num_training_batches` to use.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`val_check_interval` (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span><span class="si">}</span><span class="s2">) must be less than or equal &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;to the number of the training batches (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="s2">&quot;If you want to disable validation set `limit_val_batches` to 0.0 instead.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_len_all_ranks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                        <span class="s2">&quot;When using an IterableDataset for `train_dataloader`,&quot;</span>
                        <span class="s2">&quot; `Trainer(val_check_interval)` must be `1.0` or an int. An int k specifies&quot;</span>
                        <span class="s2">&quot; checking validation every k training batches.&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_check_interval</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_check_batch</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_every_n_steps</span><span class="p">:</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The number of training batches (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span><span class="si">}</span><span class="s2">) is smaller than the logging interval&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; Trainer(log_every_n_steps=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_every_n_steps</span><span class="si">}</span><span class="s2">). Set a lower value for log_every_n_steps if&quot;</span>
                <span class="s2">&quot; you want to see logs for the training epoch.&quot;</span><span class="p">,</span>
                <span class="n">category</span><span class="o">=</span><span class="n">PossibleUserWarning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># store epoch of dataloader reset for reload_dataloaders_every_n_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_last_train_dl_reload_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span>

    <span class="k">def</span> <span class="nf">reset_val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Resets the validation dataloader and determines the number of batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The ``LightningModule`` if called outside of the trainer scope.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_val_dataloader_source</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="n">model</span>
        <span class="n">has_step</span> <span class="o">=</span> <span class="n">is_overridden</span><span class="p">(</span><span class="s2">&quot;validation_step&quot;</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">)</span>
        <span class="n">enable_validation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_val_batches</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">source</span><span class="o">.</span><span class="n">is_defined</span><span class="p">()</span> <span class="ow">and</span> <span class="n">has_step</span> <span class="ow">and</span> <span class="n">enable_validation</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_val_batches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloaders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_reset_eval_dataloader</span><span class="p">(</span>
                <span class="n">RunningStage</span><span class="o">.</span><span class="n">VALIDATING</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">pl_module</span>
            <span class="p">)</span>

            <span class="c1"># store epoch of dataloader reset for reload_dataloaders_every_n_epochs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_last_val_dl_reload_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span>

    <span class="k">def</span> <span class="nf">reset_test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Resets the test dataloader and determines the number of batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The ``LightningModule`` if called outside of the trainer scope.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_test_dataloader_source</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="n">model</span>
        <span class="n">has_step</span> <span class="o">=</span> <span class="n">is_overridden</span><span class="p">(</span><span class="s2">&quot;test_step&quot;</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">)</span>
        <span class="n">enable_testing</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_test_batches</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">source</span><span class="o">.</span><span class="n">is_defined</span><span class="p">()</span> <span class="ow">and</span> <span class="n">has_step</span> <span class="ow">and</span> <span class="n">enable_testing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_test_batches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataloaders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_reset_eval_dataloader</span><span class="p">(</span>
                <span class="n">RunningStage</span><span class="o">.</span><span class="n">TESTING</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">pl_module</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Resets the predict dataloader and determines the number of batches.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The ``LightningModule`` if called outside of the trainer scope.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">source</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_predict_dataloader_source</span>
        <span class="n">pl_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span> <span class="ow">or</span> <span class="n">model</span>
        <span class="n">enable_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_predict_batches</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">source</span><span class="o">.</span><span class="n">is_defined</span><span class="p">()</span> <span class="ow">and</span> <span class="n">enable_prediction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_predict_batches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_dataloaders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_reset_eval_dataloader</span><span class="p">(</span>
                <span class="n">RunningStage</span><span class="o">.</span><span class="n">PREDICTING</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">pl_module</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_train_val_dataloaders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Resets train and val dataloaders if none are attached to the trainer.</span>

<span class="sd">        The val dataloader must be initialized before training loop starts, as the training loop</span>
<span class="sd">        inspects the val dataloader to determine whether to run the evaluation loop.</span>
<span class="sd">        Args:</span>
<span class="sd">            model: The ``LightningModule`` if called outside of the trainer scope.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_train_dataloader</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloaders</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_val_dataloader</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Accelerator properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">accelerator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Accelerator</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">accelerator</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Strategy</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_accelerator_connector</span><span class="o">.</span><span class="n">strategy</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">training_type_plugin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Strategy</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.training_type_plugin` is deprecated in v1.6 and will be removed in v1.8. Use&quot;</span>
            <span class="s2">&quot; `Trainer.strategy` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precision_plugin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PrecisionPlugin</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">precision_plugin</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">global_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">global_rank</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">local_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="c1"># some strategies define a local rank</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="s2">&quot;local_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="c1"># some strategies define a node rank</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="s2">&quot;node_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="c1"># some strategies define a world size</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="s2">&quot;world_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">should_rank_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.should_rank_save_checkpoint` is deprecated in v1.6 and will be removed in v1.8.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span>
        <span class="p">)</span>
        <span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">strategy</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">strategies</span><span class="o">.</span><span class="n">TPUSpawnStrategy</span><span class="p">)</span> <span class="ow">and</span> <span class="n">strategy</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">strategy</span><span class="o">.</span><span class="n">is_global_zero</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="s2">&quot;num_nodes&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;List of device indexes per node.&quot;&quot;&quot;</span>
        <span class="n">devices</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">parallel_devices</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">ParallelStrategy</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">root_device</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">device_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">devices</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                <span class="n">device_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">index</span> <span class="ow">or</span> <span class="n">idx</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">device_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">device_ids</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_devices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Number of devices the trainer uses per node.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_processes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.num_processes` is deprecated in v1.6 and will be removed in v1.8. &quot;</span>
            <span class="s2">&quot;Please use `Trainer.num_devices` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">root_gpu</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.root_gpu` is deprecated in v1.6 and will be removed in v1.8. &quot;</span>
            <span class="s2">&quot;Please use `Trainer.strategy.root_device.index` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">root_device</span><span class="o">.</span><span class="n">index</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tpu_cores</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.tpu_cores` is deprecated in v1.6 and will be removed in v1.8. &quot;</span>
            <span class="s2">&quot;Please use `Trainer.num_devices` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">TPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ipus</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.ipus` was deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.num_devices` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">IPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_gpus</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.num_gpus` was deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.num_devices` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">devices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.devices` was deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.num_devices` or `Trainer.device_ids` to get device information instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">data_parallel_device_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.data_parallel_device_ids` was deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.device_ids` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span> <span class="n">GPUAccelerator</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">lightning_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pl.LightningModule&quot;</span><span class="p">:</span>
        <span class="c1"># TODO: this is actually an optional return</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">lightning_module</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">optimizers</span>

    <span class="nd">@optimizers</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_optims</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="n">new_optims</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">lightning_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">LightningOptimizer</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.lightning_optimizers` is deprecated in v1.6 and will be removed in v1.8&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">_lightning_optimizers</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">lr_scheduler_configs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LRSchedulerConfig</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">lr_scheduler_configs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">lr_schedulers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.lr_schedulers` is deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; You can use `trainer.lr_scheduler_configs` instead which contains dataclasses instead of dictionaries.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">asdict</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">lr_scheduler_configs</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optimizer_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">optimizer_frequencies</span>

    <span class="nd">@optimizer_frequencies</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">optimizer_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_freqs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">optimizer_frequencies</span> <span class="o">=</span> <span class="n">new_freqs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">amp_backend</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AMPType</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_plugin</span><span class="p">,</span> <span class="n">ApexMixedPrecisionPlugin</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">AMPType</span><span class="o">.</span><span class="n">APEX</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_plugin</span><span class="p">,</span> <span class="n">NativeMixedPrecisionPlugin</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">AMPType</span><span class="o">.</span><span class="n">NATIVE</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precision</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">precision_plugin</span><span class="o">.</span><span class="n">precision</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">scaler</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precision_plugin</span><span class="p">,</span> <span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">gpus</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.gpus` was deprecated in v1.6 and will be removed in v1.8.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.num_devices` or `Trainer.device_ids` to get device information instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_accelerator_connector</span><span class="o">.</span><span class="n">gpus</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The LightningModule, but possibly wrapped into DataParallel or DistributedDataParallel.</span>

<span class="sd">        To access the pure LightningModule, use</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.lightning_module` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span>

    <span class="nd">@model</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Setter for the model, pass-through to accelerator and plugin where the model reference is stored. Used</span>
<span class="sd">        by the Tuner to reset the state of Trainer and Accelerator.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The LightningModule, possibly wrapped into DataParallel or DistributedDataParallel, depending</span>
<span class="sd">                on the backend.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    General properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">log_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span> <span class="n">TensorBoardLogger</span><span class="p">):</span>
                <span class="n">dirpath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dirpath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">save_dir</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dirpath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_root_dir</span>

        <span class="n">dirpath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">dirpath</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dirpath</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">use_amp</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`Trainer.use_amp` is deprecated in v1.6.0 and will be removed in v1.8.0.&quot;</span>
            <span class="s2">&quot; Please use `Trainer.amp_backend` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision</span> <span class="o">==</span> <span class="mi">16</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_global_zero</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">is_global_zero</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">slurm_job_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;Method `slurm_job_id` is deprecated in v1.6.0 and will be removed in v1.7.0.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">SLURMEnvironment</span><span class="o">.</span><span class="n">job_id</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">distributed_sampler_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">ParallelStrategy</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">distributed_sampler_kwargs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">data_parallel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span> <span class="n">ParallelStrategy</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">progress_bar_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Read-only for progress bar metrics.&quot;&quot;&quot;</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;`trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7.&quot;</span>
            <span class="s2">&quot; Use `ProgressBarBase.get_metrics` instead.&quot;</span>
        <span class="p">)</span>
        <span class="n">ref_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span>
        <span class="n">ref_model</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">,</span> <span class="n">ref_model</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar_callback</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar_callback</span><span class="o">.</span><span class="n">get_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ref_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar_metrics</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">enable_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Check if we should run validation during training.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_connector</span><span class="o">.</span><span class="n">_val_dataloader_source</span><span class="o">.</span><span class="n">is_defined</span><span class="p">()</span>
            <span class="ow">and</span> <span class="n">is_overridden</span><span class="p">(</span><span class="s2">&quot;validation_step&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_val_batches</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">default_root_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The default location to save artifacts of loggers, checkpoints etc.</span>

<span class="sd">        It is used as a fallback if logger or checkpoint callback do not define specific save paths.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">get_filesystem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_root_dir</span><span class="p">)</span><span class="o">.</span><span class="n">protocol</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_root_dir</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_root_dir</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights_save_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The default root location to save weights (checkpoints), e.g., when the</span>
<span class="sd">        :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint` does not define a file path.</span>

<span class="sd">        .. deprecated:: v1.6</span>
<span class="sd">            `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_save_path_internal</span>

    <span class="c1"># TODO: Remove _weights_save_path_internal in v1.8</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_weights_save_path_internal</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;This is an internal implementation of weights_save_path which allows weights_save_path to be used</span>
<span class="sd">        internally by the framework without emitting a deprecation warning.</span>

<span class="sd">        To be removed in v1.8.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">get_filesystem</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights_save_path</span><span class="p">)</span><span class="o">.</span><span class="n">protocol</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">normpath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights_save_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_save_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">early_stopping_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EarlyStopping</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The first :class:`~pytorch_lightning.callbacks.early_stopping.EarlyStopping` callback in the</span>
<span class="sd">        Trainer.callbacks list, or ``None`` if it doesn&#39;t exist.&quot;&quot;&quot;</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_callbacks</span>
        <span class="k">return</span> <span class="n">callbacks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">early_stopping_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">EarlyStopping</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;A list of all instances of :class:`~pytorch_lightning.callbacks.early_stopping.EarlyStopping` found in</span>
<span class="sd">        the Trainer.callbacks list.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">EarlyStopping</span><span class="p">)]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">prediction_writer_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">BasePredictionWriter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;A list of all instances of :class:`~pytorch_lightning.callbacks.prediction_writer.BasePredictionWriter`</span>
<span class="sd">        found in the Trainer.callbacks list.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">cb</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">BasePredictionWriter</span><span class="p">)]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">checkpoint_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The first :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint` callback in the</span>
<span class="sd">        Trainer.callbacks list, or ``None`` if it doesn&#39;t exist.&quot;&quot;&quot;</span>
        <span class="n">callbacks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_callbacks</span>
        <span class="k">return</span> <span class="n">callbacks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">checkpoint_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;A list of all instances of :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint` found</span>
<span class="sd">        in the Trainer.callbacks list.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">ModelCheckpoint</span><span class="p">)]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">progress_bar_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProgressBarBase</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;An instance of :class:`~pytorch_lightning.callbacks.progress.base.ProgressBarBase` found in the</span>
<span class="sd">        Trainer.callbacks list, or ``None`` if one doesn&#39;t exist.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">ProgressBarBase</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">c</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">resume_from_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]:</span>
        <span class="n">resume_from_checkpoint</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">resume_from_checkpoint_fit_path</span>
        <span class="k">if</span> <span class="n">resume_from_checkpoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank_zero_deprecation</span><span class="p">(</span>
                <span class="s2">&quot;`trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0.&quot;</span>
                <span class="s2">&quot; Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.&quot;</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">resume_from_checkpoint</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Set to the path/URL of a checkpoint loaded via :meth:`~pytorch_lightning.trainer.trainer.Trainer.fit`,</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.validate`,</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.test`, or</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.predict`. ``None`` otherwise.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ckpt_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">validated_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.validated_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via&quot;</span>
            <span class="s2">&quot; `Trainer.ckpt_path` instead.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validated_ckpt_path</span>

    <span class="nd">@validated_ckpt_path</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">validated_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.validated_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via the&quot;</span>
            <span class="s2">&quot; read-only `Trainer.ckpt_path`.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validated_ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tested_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.tested_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via&quot;</span>
            <span class="s2">&quot; `Trainer.ckpt_path` instead.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tested_ckpt_path</span>

    <span class="nd">@tested_ckpt_path</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">tested_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.tested_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via the&quot;</span>
            <span class="s2">&quot; read-only `Trainer.ckpt_path` instead.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tested_ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">predicted_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.predicted_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via&quot;</span>
            <span class="s2">&quot; `Trainer.ckpt_path` instead.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predicted_ckpt_path</span>

    <span class="nd">@predicted_ckpt_path</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">predicted_ckpt_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.predicted_ckpt_path` attribute was deprecated in v1.6 and will be removed in v1.8. The&quot;</span>
            <span class="s2">&quot; path of a checkpoint loaded via `Trainer.{fit,validate,test,predict}` should be accessed via the&quot;</span>
            <span class="s2">&quot; read-only `Trainer.ckpt_path` instead.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_predicted_ckpt_path</span> <span class="o">=</span> <span class="n">ckpt_path</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">:</span> <span class="n">_PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">storage_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs routine to create a checkpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            filepath: Path where checkpoint is saved.</span>
<span class="sd">            weights_only: If ``True``, will only save the model weights.</span>
<span class="sd">            storage_options: parameter for how to save to storage, passed to ``CheckpointIO`` plugin</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_connector</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="n">weights_only</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="n">storage_options</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parsing properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">default_attributes</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">init_signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">default</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">init_signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_deprecated_arg_names</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns a list with deprecated Trainer arguments.&quot;&quot;&quot;</span>
        <span class="n">depr_arg_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;DEPRECATED&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="n">depr_arg_names</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">depr_arg_names</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">ArgumentParser</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">from_argparse_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">parse_argparser</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">arg_parser</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ArgumentParser</span><span class="p">,</span> <span class="n">Namespace</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Namespace</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parse_argparser</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">arg_parser</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">match_env_arguments</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Namespace</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parse_env_variables</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parent_parser</span><span class="p">:</span> <span class="n">ArgumentParser</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ArgumentParser</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">add_argparse_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parent_parser</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    State properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">interrupted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="n">TrainerStatus</span><span class="o">.</span><span class="n">INTERRUPTED</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TRAINING</span>

    <span class="nd">@training</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">training</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TRAINING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">testing</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TESTING</span>

    <span class="nd">@testing</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">testing</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TESTING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">testing</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">predicting</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">PREDICTING</span>

    <span class="nd">@predicting</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">predicting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">PREDICTING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicting</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TUNING</span>

    <span class="nd">@tuning</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">tuning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">TUNING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">tuning</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">validating</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">VALIDATING</span>

    <span class="nd">@validating</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">validating</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">VALIDATING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">validating</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">evaluating</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span><span class="o">.</span><span class="n">evaluating</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sanity_checking</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">==</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">SANITY_CHECKING</span>

    <span class="nd">@sanity_checking</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">sanity_checking</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">val</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="n">RunningStage</span><span class="o">.</span><span class="n">SANITY_CHECKING</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">sanity_checking</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stage</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loop properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">global_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The number of optimizer steps taken (does not reset each epoch).</span>

<span class="sd">        This includes multiple optimizers and TBPTT steps (if enabled).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">global_step</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">current_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The current epoch, updated after the epoch end hooks are run.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_progress</span><span class="o">.</span><span class="n">current</span><span class="o">.</span><span class="n">completed</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">max_epochs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">max_epochs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">min_epochs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">min_epochs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">max_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">max_steps</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">min_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">min_steps</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_last_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">batch_progress</span><span class="o">.</span><span class="n">is_last_batch</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">fit_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FitLoop</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_loop</span>

    <span class="nd">@fit_loop</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">fit_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loop</span><span class="p">:</span> <span class="n">FitLoop</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach a custom fit loop to this Trainer.</span>

<span class="sd">        It will run with</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.fit`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit_loop</span> <span class="o">=</span> <span class="n">loop</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">validate_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvaluationLoop</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_loop</span>

    <span class="nd">@validate_loop</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">validate_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loop</span><span class="p">:</span> <span class="n">EvaluationLoop</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach a custom validation loop to this Trainer.</span>

<span class="sd">        It will run with</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.validate`. Note that this loop is different from the one</span>
<span class="sd">        running during training inside the :meth:`pytorch_lightning.trainer.trainer.Trainer.fit` call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_loop</span> <span class="o">=</span> <span class="n">loop</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvaluationLoop</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_loop</span>

    <span class="nd">@test_loop</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loop</span><span class="p">:</span> <span class="n">EvaluationLoop</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach a custom test loop to this Trainer.</span>

<span class="sd">        It will run with</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.test`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_loop</span> <span class="o">=</span> <span class="n">loop</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">predict_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PredictionLoop</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_loop</span>

    <span class="nd">@predict_loop</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">predict_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loop</span><span class="p">:</span> <span class="n">PredictionLoop</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach a custom prediction loop to this Trainer.</span>

<span class="sd">        It will run with</span>
<span class="sd">        :meth:`~pytorch_lightning.trainer.trainer.Trainer.predict`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loop</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_predict_loop</span> <span class="o">=</span> <span class="n">loop</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">verbose_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.verbose_evaluate` property has been deprecated and will be removed in v1.8. The current value&quot;</span>
            <span class="s2">&quot; returned is the union of the validate and test loop values. You can choose which one to access with&quot;</span>
            <span class="s2">&quot; `trainer.{validate,test}_loop.verbose`.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate_loop</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loop</span><span class="o">.</span><span class="n">verbose</span>

    <span class="nd">@verbose_evaluate</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">verbose_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="s2">&quot;The `Trainer.verbose_evaluate` property has been deprecated and will be removed in v1.8. This will set&quot;</span>
            <span class="s2">&quot; the value for both trainer.{validate,test}_loop.verbose`.&quot;</span><span class="p">,</span>
            <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_loop</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loop</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_evaluation_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvaluationLoop</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="ow">in</span> <span class="p">(</span><span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span><span class="p">,</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">TUNING</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">val_loop</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">VALIDATING</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate_loop</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">TESTING</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loop</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The `Trainer._evaluation_loop` property isn&#39;t defined. Accessed outside of scope&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_active_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">FitLoop</span><span class="p">,</span> <span class="n">EvaluationLoop</span><span class="p">,</span> <span class="n">PredictionLoop</span><span class="p">]]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_loop</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sanity_checking</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluating</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_loop</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicting</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_loop</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Logging properties</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">logger</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rank_zero_warn</span><span class="p">(</span>
                <span class="s2">&quot;Using trainer.logger when Trainer is configured to use multiple loggers.&quot;</span>
                <span class="s2">&quot; This behavior will change in v1.8 when LoggerCollection is removed, and&quot;</span>
                <span class="s2">&quot; trainer.logger will return the first logger in trainer.loggers&quot;</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">LoggerCollection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loggers</span><span class="p">)</span>

    <span class="nd">@logger</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">logger</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">logger</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">LoggerCollection</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">logger</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loggers</span> <span class="o">=</span> <span class="p">[</span><span class="n">logger</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">loggers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span>

    <span class="nd">@loggers</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">loggers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loggers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">LightningLoggerBase</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span> <span class="o">=</span> <span class="n">loggers</span> <span class="k">if</span> <span class="n">loggers</span> <span class="k">else</span> <span class="p">[]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">callback_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">callback_metrics</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">logged_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">logged_metrics</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">progress_bar_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logger_connector</span><span class="o">.</span><span class="n">progress_bar_metrics</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_results</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ResultCollection</span><span class="p">]:</span>
        <span class="n">active_loop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_active_loop</span>
        <span class="k">if</span> <span class="n">active_loop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">active_loop</span><span class="o">.</span><span class="n">_results</span>

    <span class="k">def</span> <span class="nf">_exit_gracefully_on_signal</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_fault_tolerant_training</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_terminate_gracefully</span><span class="p">():</span>
            <span class="k">return</span>
        <span class="k">raise</span> <span class="n">ExitGracefullyException</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_should_terminate_gracefully</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_terminate_gracefully</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">root_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">reduce_op</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;`Trainer.weights_summary` is deprecated in v1.5 and will be removed in v1.7.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_summary</span>

    <span class="nd">@weights_summary</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">weights_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;Setting `Trainer.weights_summary` is deprecated in v1.5 and will be removed in v1.7.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_summary</span> <span class="o">=</span> <span class="n">val</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Other</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">estimated_stepping_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimated stepping batches for the complete training inferred from DataLoaders, gradient</span>
<span class="sd">        accumulation factor and distributed setup.</span>

<span class="sd">        Examples::</span>

<span class="sd">            def configure_optimizers(self):</span>
<span class="sd">                optimizer = ...</span>
<span class="sd">                scheduler = torch.optim.lr_scheduler.OneCycleLR(</span>
<span class="sd">                    optimizer, max_lr=1e-3, total_steps=self.trainer.estimated_stepping_batches</span>
<span class="sd">                )</span>
<span class="sd">                return [optimizer], [scheduler]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">accumulation_scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulation_scheduler</span>

        <span class="k">if</span> <span class="n">accumulation_scheduler</span><span class="o">.</span><span class="n">epochs</span> <span class="o">!=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
                <span class="s2">&quot;Estimated stepping batches cannot be computed with different&quot;</span>
                <span class="s2">&quot; `accumulate_grad_batches` at different epochs.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># infinite training</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank_zero_info</span><span class="p">(</span><span class="s2">&quot;Loading `train_dataloader` to estimate number of stepping batches.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_train_dataloader</span><span class="p">()</span>

        <span class="n">total_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_training_batches</span>

        <span class="c1"># iterable dataset</span>
        <span class="k">if</span> <span class="n">total_batches</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad_batches</span> <span class="o">=</span> <span class="n">accumulation_scheduler</span><span class="o">.</span><span class="n">get_accumulate_grad_batches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
        <span class="n">effective_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad_batches</span>
        <span class="n">max_estimated_steps</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">total_batches</span> <span class="o">/</span> <span class="n">effective_batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">max_estimated_steps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">max_estimated_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">max_estimated_steps</span>
        <span class="k">return</span> <span class="n">max_estimated_steps</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">terminate_on_nan</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span><span class="s2">&quot;`Trainer.terminate_on_nan` is deprecated in v1.5 and will be removed in 1.7.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_terminate_on_nan</span>

    <span class="nd">@terminate_on_nan</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">terminate_on_nan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank_zero_deprecation</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Setting `Trainer.terminate_on_nan = </span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">` is deprecated in v1.5 and will be removed in 1.7.&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; Please set `Trainer(detect_anomaly=</span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">)` instead.&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_terminate_on_nan</span> <span class="o">=</span> <span class="n">val</span>  <span class="c1"># : 212</span>


<span class="k">def</span> <span class="nf">_determine_batch_limits</span><span class="p">(</span><span class="n">batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">batches</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># batches is optional to know if the user passed a value so that we can show the above info messages only to the</span>
        <span class="c1"># users that set a value explicitly</span>
        <span class="k">return</span> <span class="mf">1.0</span>

    <span class="c1"># differentiating based on the type can be error-prone for users. show a message describing the chosen behaviour</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">batches</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;limit_train_batches&quot;</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;1 batch per epoch will be used.&quot;</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;val_check_interval&quot;</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;validation will run after every batch.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;1 batch will be used.&quot;</span>
        <span class="n">rank_zero_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`Trainer(</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">=1)` was configured so </span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batches</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">batches</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;limit_train_batches&quot;</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;100</span><span class="si">% o</span><span class="s2">f the batches per epoch will be used.&quot;</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;val_check_interval&quot;</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;validation will run at the end of the training epoch.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;100</span><span class="si">% o</span><span class="s2">f the batches will be used.&quot;</span>
        <span class="n">rank_zero_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`Trainer(</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">=1.0)` was configured so </span><span class="si">{</span><span class="n">message</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">batches</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batches</span>
    <span class="k">if</span> <span class="n">batches</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">batches</span> <span class="o">%</span> <span class="mf">1.0</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="k">raise</span> <span class="n">MisconfigurationException</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;You have passed invalid value </span><span class="si">{</span><span class="n">batches</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, it has to be in [0.0, 1.0] or an int.&quot;</span>
    <span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2018-2022, William Falcon et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
         <script src="../../../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Click to show';</script>
         <script>let toggleHintHide = 'Click to hide';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../../../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Best practices', 'Optional Extensions', 'Tutorials', 'API References', 'Bolts', 'Examples', 'Partner Domain Frameworks', 'Community'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.rtfd.io/en/latest">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">View Resources</a>
        </div>
        -->
      </div>
    </div>
  </div>

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-lightning.rtfd.io/en/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.rtfd.io/en/latest/">PyTorch</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://www.pytorchlightning.ai/blog">Blog</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Resources</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest">Docs</a></li>
            <li><a href="https://www.pytorchlightning.ai/community" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/PyTorchLightnin" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.pytorchlightning.ai/blog">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning-flash.readthedocs.io/en/stable/">Lightning Flash</a>
            </li>

            <li>
              <a href="https://lightning-transformers.readthedocs.io/en/stable/">Lightning Transformers</a>
            </li>

            <li>
              <a href="https://lightning-bolts.readthedocs.io/en/stable/">Lightning Bolts</a>
            </li>
          </ul> -->

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch-lightning.rtfd.io/en/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="https://www.pytorchlightning.ai/community">Community</a>
            </li>

            <li>
              <a href="https://github.com/PyTorchLightning/pytorch-lightning/discussions">Forums</a>
            </li>
          </ul>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">Github</a>
          </li> -->

          <!-- <li>
            <a href="https://www.grid.ai/">Grid.ai</a>
          </li> -->
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

 </body>
</html>