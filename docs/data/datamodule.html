


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LightningDataModule &mdash; PyTorch Lightning 1.7.0dev documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch-lightning.readthedocs.io/en/stable//data/datamodule.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/main.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Track and Visualize Experiments" href="../visualize/loggers.html" />
    <link rel="prev" title="Raw PyTorch loop (expert)" href="../model/build_model_expert.html" />
  
  <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-82W25RV60Q"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-82W25RV60Q');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li> -->

          <!-- <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-transformers.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Transformers</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li> -->

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://www.pytorchlightning.ai/community">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://github.com/PyTorchLightning/pytorch-lightning/discussions" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">GitHub</a>
          </li>

          <li>
            <a href="https://www.grid.ai/">Train on the cloud</a>
          </li> -->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.7.0dev
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../starter/introduction.html">Lightning 15분 만에 배워보기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/converting.html">Organize existing PyTorch into Lightning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Level Up</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../levels/core_skills.html">Basic skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/intermediate.html">Intermediate skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/advanced.html">Advanced skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/expert.html">Expert skills</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/trainer.html">Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Workflows</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/evaluation.html">Avoid overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model.html">Build a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/hyperparameters.html">Configure hyperparameters from the CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/progress_bar.html">Customize the progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production.html">Deploy models into production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/training_tricks.html">Effective Training Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli/lightning_cli.html">Eliminate config boilerplate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/profiler.html">Find bottlenecks in your code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/transfer_learning.html">Finetune a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/logging_intermediate.html">Manage experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster.html">Run on an on-prem cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/model_parallel.html">Train 1 trillion+ parameter models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cloud_training.html">Train on the cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing.html">Save and load model progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/precision.html">Save memory with half-precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/gpu.html">Train on single or multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/hpu.html">Train on single or multiple HPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/ipu.html">Train on single or multiple IPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/tpu.html">Train on single or multiple TPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/own_your_loop.html">Use a pure PyTorch training loop</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../extensions/accelerator.html">Accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extensions/callbacks.html">Callback</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing.html">Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster.html">Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing_advanced.html">Cloud checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/console_logs.html">Console Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/early_stopping.html">Early stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/experiment_managers.html">Experiment manager (Logger)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/fault_tolerant_training.html">Fault tolerant training</a></li>
<li class="toctree-l1"><a class="reference external" href="https://lightning-flash.readthedocs.io/en/stable/">Flash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cloud_training.html">Grid AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/gpu.html">GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/precision.html">Half precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/hpu.html">HPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_intermediate.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/ipu.html">IPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli/lightning_cli.html">Lightning CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model_expert.html">Raw PyTorch loop (expert)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model_expert.html#lightninglite-stepping-stone-to-lightning">LightningLite (Stepping Stone to Lightning)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">LightningDataModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/ecosystem/transformers.html">Lightning Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/loggers.html">Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extensions/loops.html">Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/tpu.html">TPU</a></li>
<li class="toctree-l1"><a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/model_parallel.html">Model Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extensions/plugins.html">Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/progress_bar.html">Progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_advanced.html">Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_basic.html">Predict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/profiler.html">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/pruning_quantization.html">Pruning and Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/remote_fs.html">Remote filesystem and FSSPEC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/strategy_registry.html">Strategy registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/style_guide.html">Style guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/run_intermediate.html">Sweep</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/training_tricks.html">SWA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster_advanced.html">SLURM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/transfer_learning.html">Transfer learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster_intermediate_2.html">Torch distributed</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hands-on Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2">PyTorch Lightning 101 class</a></li>
<li class="toctree-l1"><a class="reference external" href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09">From PyTorch to PyTorch Lightning [Blog]</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/watch?v=QHww1JH7IDU">From PyTorch to PyTorch Lightning [Video]</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>LightningDataModule</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/data/datamodule.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="lightningdatamodule">
<span id="datamodules"></span><h1>LightningDataModule<a class="headerlink" href="#lightningdatamodule" title="Permalink to this headline">¶</a></h1>
<p>A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data:</p>
<video width="100%" max-width="400px" controls autoplay muted playsinline src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pt_dm_vid.m4v"></video><div class="line-block">
<div class="line"><br /></div>
</div>
<p>A datamodule encapsulates the five steps involved in data processing in PyTorch:</p>
<ol class="arabic simple">
<li><p>Download / tokenize / process.</p></li>
<li><p>Clean and (maybe) save to disk.</p></li>
<li><p>Load inside <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code>.</p></li>
<li><p>Apply transforms (rotate, tokenize, etc…).</p></li>
<li><p>Wrap inside a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>This class can then be shared and used anywhere:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pl_bolts.datamodules</span> <span class="kn">import</span> <span class="n">CIFAR10DataModule</span><span class="p">,</span> <span class="n">ImagenetDataModule</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LitClassifier</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>

<span class="n">imagenet</span> <span class="o">=</span> <span class="n">ImagenetDataModule</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">imagenet</span><span class="p">)</span>

<span class="n">cifar10</span> <span class="o">=</span> <span class="n">CIFAR10DataModule</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">cifar10</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<section id="why-do-i-need-a-datamodule">
<h2>Why do I need a DataModule?<a class="headerlink" href="#why-do-i-need-a-datamodule" title="Permalink to this headline">¶</a></h2>
<p>In normal PyTorch code, the data cleaning/preparation is usually scattered across many files. This makes
sharing and reusing the exact splits and transforms across projects impossible.</p>
<p>Datamodules are for you if you ever asked the questions:</p>
<ul class="simple">
<li><p>what splits did you use?</p></li>
<li><p>what transforms did you use?</p></li>
<li><p>what normalization did you use?</p></li>
<li><p>how did you prepare/tokenize the data?</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="what-is-a-datamodule">
<h2>What is a DataModule?<a class="headerlink" href="#what-is-a-datamodule" title="Permalink to this headline">¶</a></h2>
<p>A DataModule is simply a collection of a train_dataloader(s), val_dataloader(s), test_dataloader(s) and
predict_dataloader(s) along with the matching transforms and data processing/downloads steps required.</p>
<p>Here’s a simple PyTorch example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># regular PyTorch</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">predict_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">predict_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">predict_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p>The equivalent DataModule just organizes the same exact code, but makes it reusable across projects.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;path/to/dir&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span> <span class="o">=</span> <span class="n">data_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mnist_predict</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_predict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Used to clean-up when the run is finished</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>But now, as the complexity of your processing grows (transforms, multiple-GPU training), you can
let Lightning handle those details for you while making this dataset reusable so you can share with
colleagues or use in different projects.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mnist</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">(</span><span class="n">my_path</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitClassifier</span><span class="p">()</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mnist</span><span class="p">)</span>
</pre></div>
</div>
<p>Here’s a more realistic, complex DataModule that shows how much more reusable the datamodule is.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="c1"># Note - you must have torchvision installed for this example</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;./&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span> <span class="o">=</span> <span class="n">data_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))])</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># download</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="c1"># Assign train/val datasets for use in dataloaders</span>
        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;fit&quot;</span> <span class="ow">or</span> <span class="n">stage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

        <span class="c1"># Assign test dataset for use in dataloader(s)</span>
        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span> <span class="ow">or</span> <span class="n">stage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s2">&quot;predict&quot;</span> <span class="ow">or</span> <span class="n">stage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mnist_predict</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_predict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="lightningdatamodule-api">
<h2>LightningDataModule API<a class="headerlink" href="#lightningdatamodule-api" title="Permalink to this headline">¶</a></h2>
<p>To define a DataModule the following methods are used to create train/val/test/predict dataloaders:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#prepare-data"><span class="std std-ref">prepare_data</span></a> (how to download, tokenize, etc…)</p></li>
<li><p><a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a> (how to split, define dataset, etc…)</p></li>
<li><p><a class="reference internal" href="#train-dataloader"><span class="std std-ref">train_dataloader</span></a></p></li>
<li><p><a class="reference internal" href="#val-dataloader"><span class="std std-ref">val_dataloader</span></a></p></li>
<li><p><a class="reference internal" href="#test-dataloader"><span class="std std-ref">test_dataloader</span></a></p></li>
<li><p><a class="reference internal" href="#predict-dataloader"><span class="std std-ref">predict_dataloader</span></a></p></li>
</ul>
<section id="prepare-data">
<h3>prepare_data<a class="headerlink" href="#prepare-data" title="Permalink to this headline">¶</a></h3>
<p>Downloading and saving data with multiple processes (distributed settings) will result in corrupted data. Lightning
ensures the <code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code> is called only within a single process on CPU,
so you can safely add your downloading logic within. In case of multi-node training, the execution of this hook
depends upon <a class="reference internal" href="#prepare-data-per-node"><span class="std std-ref">prepare_data_per_node</span></a>. <code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code> is called after
<code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> and there is a barrier in between which ensures that all the processes proceed to <code class="docutils literal notranslate"><span class="pre">setup</span></code> once the data is prepared and available for use.</p>
<ul class="simple">
<li><p>download, i.e. download data only once on the disk from a single process</p></li>
<li><p>tokenize. Since it’s a one time process, it is not recommended to do it on all processes</p></li>
<li><p>etc…</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># download</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> is called from the main process. It is not recommended to assign state here (e.g. <code class="docutils literal notranslate"><span class="pre">self.x</span> <span class="pre">=</span> <span class="pre">y</span></code>) since it is called on a single process and if you assign
states here then they won’t be available for other processes.</p>
</div>
</section>
<section id="setup">
<h3>setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h3>
<p>There are also data operations you might want to perform on every GPU. Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code> to do things like:</p>
<ul class="simple">
<li><p>count number of classes</p></li>
<li><p>build vocabulary</p></li>
<li><p>perform train/val/test splits</p></li>
<li><p>create datasets</p></li>
<li><p>apply transforms (defined explicitly in your datamodule)</p></li>
<li><p>etc…</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="c1"># Assign Train/val split(s) for use in Dataloaders</span>
        <span class="k">if</span> <span class="n">stage</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">):</span>
            <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

        <span class="c1"># Assign Test split(s) for use in Dataloaders</span>
        <span class="k">if</span> <span class="n">stage</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
<p>For eg., if you are working with NLP task where you need to tokenize the text and use it, then you can do something like as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_Dataset</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="o">...</span>
        <span class="c1"># tokenize</span>
        <span class="c1"># save it to disk</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="c1"># load it back here</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset_from_disk</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>This method expects a <code class="docutils literal notranslate"><span class="pre">stage</span></code> argument.
It is used to separate setup logic for <code class="docutils literal notranslate"><span class="pre">trainer.{fit,validate,test,predict}</span></code>. If <code class="docutils literal notranslate"><span class="pre">setup</span></code> is called with <code class="docutils literal notranslate"><span class="pre">stage=None</span></code>,
we assume all stages have been set-up.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a> is called from every process across all the nodes. Setting state here is recommended.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#teardown"><span class="std std-ref">teardown</span></a> can be used to clean up the state. It is also called from every process across all the nodes.</p>
</div>
</section>
<section id="train-dataloader">
<h3>train_dataloader<a class="headerlink" href="#train-dataloader" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">train_dataloader()</span></code> method to generate the training dataloader(s).
Usually you just wrap the dataset you defined in <a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a>. This is the dataloader that the Trainer
<code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method uses.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="val-dataloader">
<span id="datamodule-val-dataloader-label"></span><h3>val_dataloader<a class="headerlink" href="#val-dataloader" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">val_dataloader()</span></code> method to generate the validation dataloader(s).
Usually you just wrap the dataset you defined in <a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a>. This is the dataloader that the Trainer
<code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code> methods uses.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="test-dataloader">
<span id="datamodule-test-dataloader-label"></span><h3>test_dataloader<a class="headerlink" href="#test-dataloader" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">test_dataloader()</span></code> method to generate the test dataloader(s).
Usually you just wrap the dataset you defined in <a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a>. This is the dataloader that the Trainer
<code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code> method uses.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="predict-dataloader">
<h3>predict_dataloader<a class="headerlink" href="#predict-dataloader" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_dataloader()</span></code> method to generate the prediction dataloader(s).
Usually you just wrap the dataset you defined in <a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a>. This is the dataloader that the Trainer
<code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> method uses.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mnist_predict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="transfer-batch-to-device">
<h3>transfer_batch_to_device<a class="headerlink" href="#transfer-batch-to-device" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom
data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torchtext.data.batch.Batch</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook only runs on single GPU training and DDP (no data-parallel).
Data-Parallel support will come in near future.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.batch">¶</a> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.device"></span><strong>device</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.device">¶</a> (<code class="xref py py-class docutils literal notranslate"><span class="pre">device</span></code>) – The target device as defined in PyTorch.</p></li>
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.dataloader_idx"></span><strong>dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.transfer_batch_to_device.params.dataloader_idx">¶</a> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using data-parallel, <code class="docutils literal notranslate"><span class="pre">Trainer(strategy='dp')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="on-before-batch-transfer">
<h3>on_before_batch_transfer<a class="headerlink" href="#on-before-batch-transfer" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook only runs on single GPU training and DDP (no data-parallel).
Data-Parallel support will come in near future.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.on_before_batch_transfer.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.on_before_batch_transfer.params.batch">¶</a> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.on_before_batch_transfer.params.dataloader_idx"></span><strong>dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.on_before_batch_transfer.params.dataloader_idx">¶</a> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using data-parallel, <code class="docutils literal notranslate"><span class="pre">Trainer(strategy='dp')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="on-after-batch-transfer">
<h3>on_after_batch_transfer<a class="headerlink" href="#on-after-batch-transfer" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook only runs on single GPU training and DDP (no data-parallel).
Data-Parallel support will come in near future.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.on_after_batch_transfer.params.batch"></span><strong>batch</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.on_after_batch_transfer.params.batch">¶</a> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.on_after_batch_transfer.params.dataloader_idx"></span><strong>dataloader_idx</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.on_after_batch_transfer.params.dataloader_idx">¶</a> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A batch of data</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using data-parallel, <code class="docutils literal notranslate"><span class="pre">Trainer(strategy='dp')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></p></li>
</ul>
</div>
</dd></dl>

</section>
<section id="load-state-dict">
<h3>load_state_dict<a class="headerlink" href="#load-state-dict" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_lightning/core/datamodule.html#LightningDataModule.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Called when loading a checkpoint, implement to reload datamodule state given datamodule state_dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.load_state_dict.params.state_dict"></span><strong>state_dict</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.load_state_dict.params.state_dict">¶</a> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]) – the datamodule state returned by <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="state-dict">
<h3>state_dict<a class="headerlink" href="#state-dict" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_lightning/core/datamodule.html#LightningDataModule.state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Called when saving a checkpoint, implement to generate and save datamodule state.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary containing datamodule state.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="on-train-dataloader">
<h3>on_train_dataloader<a class="headerlink" href="#on-train-dataloader" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Called before requesting the train dataloader.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version v1.5: </span><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_train_dataloader()</span></code> is deprecated and will be removed in v1.7.0.
Please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">train_dataloader()</span></code> directly.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="on-val-dataloader">
<h3>on_val_dataloader<a class="headerlink" href="#on-val-dataloader" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Called before requesting the val dataloader.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version v1.5: </span><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_val_dataloader()</span></code> is deprecated and will be removed in v1.7.0.
Please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">val_dataloader()</span></code> directly.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="on-test-dataloader">
<h3>on_test_dataloader<a class="headerlink" href="#on-test-dataloader" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Called before requesting the test dataloader.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version v1.5: </span><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_test_dataloader()</span></code> is deprecated and will be removed in v1.7.0.
Please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">test_dataloader()</span></code> directly.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="on-predict-dataloader">
<h3>on_predict_dataloader<a class="headerlink" href="#on-predict-dataloader" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">on_predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Called before requesting the predict dataloader.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version v1.5: </span><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_predict_dataloader()</span></code> is deprecated and will be removed in v1.7.0.
Please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_dataloader()</span></code> directly.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="teardown">
<h3>teardown<a class="headerlink" href="#teardown" title="Permalink to this headline">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">LightningDataModule.</span></span><span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><span class="target" id="pytorch_lightning.core.datamodule.LightningDataModule.teardown.params.stage"></span><strong>stage</strong><a class="paramlink headerlink reference internal" href="#pytorch_lightning.core.datamodule.LightningDataModule.teardown.params.stage">¶</a> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="prepare-data-per-node">
<h3>prepare_data_per_node<a class="headerlink" href="#prepare-data-per-node" title="Permalink to this headline">¶</a></h3>
<p>If set to <code class="docutils literal notranslate"><span class="pre">True</span></code> will call <code class="docutils literal notranslate"><span class="pre">prepare_data()</span></code> on LOCAL_RANK=0 for every node.
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> will only call from NODE_RANK=0, LOCAL_RANK=0.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="using-a-datamodule">
<h2>Using a DataModule<a class="headerlink" href="#using-a-datamodule" title="Permalink to this headline">¶</a></h2>
<p>The recommended way to use a DataModule is simply:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</pre></div>
</div>
<p>If you need information from the dataset to build your model, then run
<a class="reference internal" href="#prepare-data"><span class="std std-ref">prepare_data</span></a> and
<a class="reference internal" href="#setup"><span class="std std-ref">setup</span></a> manually (Lightning ensures
the method runs on the correct devices).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">dm</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dm</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">dm</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>

<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="datamodules-without-lightning">
<h2>DataModules without Lightning<a class="headerlink" href="#datamodules-without-lightning" title="Permalink to this headline">¶</a></h2>
<p>You can of course use DataModules in plain PyTorch code as well.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># download, etc...</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>

<span class="c1"># splits/transforms</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="c1"># use data</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">():</span>
    <span class="o">...</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">():</span>
    <span class="o">...</span>

<span class="n">dm</span><span class="o">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>

<span class="c1"># lazy load test data</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">():</span>
    <span class="o">...</span>

<span class="n">dm</span><span class="o">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>But overall, DataModules encourage reproducibility by allowing all details of a dataset to be specified in a unified
structure.</p>
</section>
<hr class="docutils" />
<section id="hyperparameters-in-datamodules">
<h2>Hyperparameters in DataModules<a class="headerlink" href="#hyperparameters-in-datamodules" title="Permalink to this headline">¶</a></h2>
<p>Like LightningModules, DataModules support hyperparameters with the same API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>


<span class="k">class</span> <span class="nc">CustomDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># access the saved hyperparameters</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>Refer to <code class="docutils literal notranslate"><span class="pre">save_hyperparameters</span></code> in <a class="reference internal" href="../common/lightning_module.html"><span class="doc">lightning module</span></a> for more details.</p>
<hr class="docutils" />
<section id="save-datamodule-state">
<h3>Save DataModule state<a class="headerlink" href="#save-datamodule-state" title="Permalink to this headline">¶</a></h3>
<p>When a checkpoint is created, it asks every DataModule for their state. If your DataModule defines the <em>state_dict</em> and <em>load_state_dict</em> methods, the checkpoint will automatically track and restore your DataModules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">DataModuler</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># track whatever you want here</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;current_train_batch_index&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_train_batch_index</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="c1"># restore the state based on what you tracked in (def state_dict)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_train_batch_index</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;current_train_batch_index&quot;</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../visualize/loggers.html" class="btn btn-neutral float-right" title="Track and Visualize Experiments" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../model/build_model_expert.html" class="btn btn-neutral" title="Raw PyTorch loop (expert)" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2018-2022, William Falcon et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">LightningDataModule</a><ul>
<li><a class="reference internal" href="#why-do-i-need-a-datamodule">Why do I need a DataModule?</a></li>
<li><a class="reference internal" href="#what-is-a-datamodule">What is a DataModule?</a></li>
<li><a class="reference internal" href="#lightningdatamodule-api">LightningDataModule API</a><ul>
<li><a class="reference internal" href="#prepare-data">prepare_data</a></li>
<li><a class="reference internal" href="#setup">setup</a></li>
<li><a class="reference internal" href="#train-dataloader">train_dataloader</a></li>
<li><a class="reference internal" href="#val-dataloader">val_dataloader</a></li>
<li><a class="reference internal" href="#test-dataloader">test_dataloader</a></li>
<li><a class="reference internal" href="#predict-dataloader">predict_dataloader</a></li>
<li><a class="reference internal" href="#transfer-batch-to-device">transfer_batch_to_device</a></li>
<li><a class="reference internal" href="#on-before-batch-transfer">on_before_batch_transfer</a></li>
<li><a class="reference internal" href="#on-after-batch-transfer">on_after_batch_transfer</a></li>
<li><a class="reference internal" href="#load-state-dict">load_state_dict</a></li>
<li><a class="reference internal" href="#state-dict">state_dict</a></li>
<li><a class="reference internal" href="#on-train-dataloader">on_train_dataloader</a></li>
<li><a class="reference internal" href="#on-val-dataloader">on_val_dataloader</a></li>
<li><a class="reference internal" href="#on-test-dataloader">on_test_dataloader</a></li>
<li><a class="reference internal" href="#on-predict-dataloader">on_predict_dataloader</a></li>
<li><a class="reference internal" href="#teardown">teardown</a></li>
<li><a class="reference internal" href="#prepare-data-per-node">prepare_data_per_node</a></li>
</ul>
</li>
<li><a class="reference internal" href="#using-a-datamodule">Using a DataModule</a></li>
<li><a class="reference internal" href="#datamodules-without-lightning">DataModules without Lightning</a></li>
<li><a class="reference internal" href="#hyperparameters-in-datamodules">Hyperparameters in DataModules</a><ul>
<li><a class="reference internal" href="#save-datamodule-state">Save DataModule state</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Click to show';</script>
         <script>let toggleHintHide = 'Click to hide';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Best practices', 'Optional Extensions', 'Tutorials', 'API References', 'Bolts', 'Examples', 'Partner Domain Frameworks', 'Community'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.rtfd.io/en/latest">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">View Resources</a>
        </div>
        -->
      </div>
    </div>
  </div>

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-lightning.rtfd.io/en/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.rtfd.io/en/latest/">PyTorch</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://www.pytorchlightning.ai/blog">Blog</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Resources</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest">Docs</a></li>
            <li><a href="https://www.pytorchlightning.ai/community" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/PyTorchLightnin" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.pytorchlightning.ai/blog">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning-flash.readthedocs.io/en/stable/">Lightning Flash</a>
            </li>

            <li>
              <a href="https://lightning-transformers.readthedocs.io/en/stable/">Lightning Transformers</a>
            </li>

            <li>
              <a href="https://lightning-bolts.readthedocs.io/en/stable/">Lightning Bolts</a>
            </li>
          </ul> -->

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch-lightning.rtfd.io/en/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="https://www.pytorchlightning.ai/community">Community</a>
            </li>

            <li>
              <a href="https://github.com/PyTorchLightning/pytorch-lightning/discussions">Forums</a>
            </li>
          </ul>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">Github</a>
          </li> -->

          <!-- <li>
            <a href="https://www.grid.ai/">Grid.ai</a>
          </li> -->
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

 </body>
</html>