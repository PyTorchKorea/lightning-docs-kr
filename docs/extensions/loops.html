


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="google-site-verification" content="okUst94cAlWSsUsGZTB4xSS4UKTtRV8Nu5XZ9pdd3Aw" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Loops &mdash; PyTorch Lightning 1.7.0dev documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://pytorch-lightning.readthedocs.io/en/stable//extensions/loops.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/main.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Plugins" href="plugins.html" />
    <link rel="prev" title="Track and Visualize Experiments" href="../visualize/loggers.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-82W25RV60Q"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-82W25RV60Q');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li> -->

          <!-- <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-transformers.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Transformers</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li> -->

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://www.pytorchlightning.ai/community">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://github.com/PyTorchLightning/pytorch-lightning/discussions" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">GitHub</a>
          </li>

          <li>
            <a href="https://www.grid.ai/">Train on the cloud</a>
          </li> -->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.7.0dev
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../starter/introduction.html">Lightning in 15 minutes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/converting.html">Organize existing PyTorch into Lightning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Level Up</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../levels/core_skills.html">Basic skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/intermediate.html">Intermediate skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/advanced.html">Advanced skills</a></li>
<li class="toctree-l1"><a class="reference internal" href="../levels/expert.html">Expert skills</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/trainer.html">Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Workflows</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/evaluation.html">Avoid overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model.html">Build a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/hyperparameters.html">Configure hyperparameters from the CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/progress_bar.html">Customize the progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production.html">Deploy models into production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/training_tricks.html">Effective Training Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli/lightning_cli.html">Eliminate config boilerplate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/profiler.html">Find bottlenecks in your code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/transfer_learning.html">Finetune a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/logging_intermediate.html">Manage experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster.html">Run on an on-prem cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/model_parallel.html">Train 1 trillion+ parameter models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cloud_training.html">Train on the cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing.html">Save and load model progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/precision.html">Save memory with half-precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/gpu.html">Train on single or multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/hpu.html">Train on single or multiple HPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/ipu.html">Train on single or multiple IPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/tpu.html">Train on single or multiple TPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/own_your_loop.html">Use a pure PyTorch training loop</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Glossary</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="accelerator.html">Accelerators</a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks.html">Callback</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing.html">Checkpointing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster.html">Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/checkpointing_advanced.html">Cloud checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/console_logs.html">Console Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug/debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/early_stopping.html">Early stopping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/experiment_managers.html">Experiment manager (Logger)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/fault_tolerant_training.html">Fault tolerant training</a></li>
<li class="toctree-l1"><a class="reference external" href="https://lightning-flash.readthedocs.io/en/stable/">Flash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cloud_training.html">Grid AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/gpu.html">GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/precision.html">Half precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/hpu.html">HPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_intermediate.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/ipu.html">IPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli/lightning_cli.html">Lightning CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model_expert.html">Raw PyTorch loop (expert)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model_expert.html#lightninglite-stepping-stone-to-lightning">LightningLite (Stepping Stone to Lightning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/datamodule.html">LightningDataModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/lightning_module.html">LightningModule</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/stable/ecosystem/transformers.html">Lightning Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualize/loggers.html">Log</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerators/tpu.html">TPU</a></li>
<li class="toctree-l1"><a class="reference external" href="https://torchmetrics.readthedocs.io/en/stable/">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/build_model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/model_parallel.html">Model Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="plugins.html">Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/progress_bar.html">Progress bar</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_advanced.html">Production</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/production_basic.html">Predict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/profiler.html">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/pruning_quantization.html">Pruning and Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/remote_fs.html">Remote filesystem and FSSPEC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/strategy_registry.html">Strategy registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starter/style_guide.html">Style guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/run_intermediate.html">Sweep</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/training_tricks.html">SWA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster_advanced.html">SLURM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/transfer_learning.html">Transfer learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clouds/cluster_intermediate_2.html">Torch distributed</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hands-on Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2">PyTorch Lightning 101 class</a></li>
<li class="toctree-l1"><a class="reference external" href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09">From PyTorch to PyTorch Lightning [Blog]</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/watch?v=QHww1JH7IDU">From PyTorch to PyTorch Lightning [Video]</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Loops</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/extensions/loops.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="loops">
<span id="loop-customization-extensions"></span><h1>Loops<a class="headerlink" href="#loops" title="Permalink to this headline">¶</a></h1>
<p>Loops let advanced users swap out the default gradient descent optimization loop at the core of Lightning with a different optimization paradigm.</p>
<p>The Lightning Trainer is built on top of the standard gradient descent optimization loop which works for 90%+ of machine learning use cases:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>However, some new research use cases such as meta-learning, active learning, recommendation systems, etc., require a different loop structure.
For example here is a simple loop that guides the weight updates with a loss from a special validation split:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val_batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">val_batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">scale_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">val_loss</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>With Lightning Loops, you can customize to non-standard gradient descent optimizations to get the same loop above:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span> <span class="o">=</span> <span class="n">MyGradientDescentLoop</span><span class="p">()</span>
</pre></div>
</div>
<p>Think of this as swapping out the engine in a car!</p>
<hr class="docutils" />
<section id="understanding-the-default-trainer-loop">
<h2>Understanding the Default Trainer Loop<a class="headerlink" href="#understanding-the-default-trainer-loop" title="Permalink to this headline">¶</a></h2>
<p>The Lightning <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> automates the standard optimization loop which every PyTorch user is familiar with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>The core research logic is simply shifted to the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="c1"># x, y = batch                      moved to training_step</span>
    <span class="c1"># y_hat = model(x)                  moved to training_step</span>
    <span class="c1"># loss = loss_function(y_hat, y)    moved to training_step</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">lightning_module</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

    <span class="c1"># Lightning handles automatically:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<p>Under the hood, the above loop is implemented using the <code class="xref py py-class docutils literal notranslate"><span class="pre">Loop</span></code> API like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DefaultLoop</span><span class="p">(</span><span class="n">Loop</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">lightning_module</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>Defining a loop within a class interface instead of hard-coding a raw Python for/while loop has several benefits:</p>
<ol class="arabic simple">
<li><p>You can have full control over the data flow through loops.</p></li>
<li><p>You can add new loops and nest as many of them as you want.</p></li>
<li><p>If needed, the state of a loop can be <a class="reference internal" href="loops_advanced.html#persisting-loop-state"><span class="std std-ref">saved and resumed</span></a>.</p></li>
<li><p>New hooks can be injected at any point.</p></li>
</ol>
<img alt="Animation showing how to convert a standard training loop to a Lightning loop" src="https://pl-public-data.s3.amazonaws.com/docs/static/images/loops/epoch-loop-steps.gif" />
<hr class="docutils" />
</section>
<section id="overriding-the-default-loops">
<span id="override-default-loops-extensions"></span><h2>Overriding the default Loops<a class="headerlink" href="#overriding-the-default-loops" title="Permalink to this headline">¶</a></h2>
<p>The fastest way to get started with loops, is to override functionality of an existing loop.
Lightning has 4 main loops which relies on : <code class="xref py py-class docutils literal notranslate"><span class="pre">FitLoop</span></code> for fitting (training and validating),
<code class="xref py py-class docutils literal notranslate"><span class="pre">EvaluationLoop</span></code> for validating or testing,
<code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionLoop</span></code> for predicting.</p>
<p>For simple changes that don’t require a custom loop, you can modify each of these loops.</p>
<p>Each loop has a series of methods that can be modified.
For example with the <code class="xref py py-class docutils literal notranslate"><span class="pre">FitLoop</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.loops</span> <span class="kn">import</span> <span class="n">FitLoop</span>


<span class="k">class</span> <span class="nc">MyLoop</span><span class="p">(</span><span class="n">FitLoop</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Advance from one iteration to the next.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_advance_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Do something at the end of an iteration.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">on_run_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Do something when the loop ends.&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>A full list with all built-in loops and subloops can be found <a class="reference internal" href="#loop-structure-extensions"><span class="std std-ref">here</span></a>.</p>
<p>To add your own modifications to a loop, simply subclass an existing loop class and override what you need.
Here is a simple example how to add a new hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.loops</span> <span class="kn">import</span> <span class="n">FitLoop</span>


<span class="k">class</span> <span class="nc">CustomFitLoop</span><span class="p">(</span><span class="n">FitLoop</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># ... whatever code before</span>

        <span class="c1"># pass anything you want to the hook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">call_hook</span><span class="p">(</span><span class="s2">&quot;my_new_hook&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># ... whatever code after</span>
</pre></div>
</div>
<p>Now simply attach the correct loop in the trainer directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span> <span class="o">=</span> <span class="n">CustomFitLoop</span><span class="p">()</span>

<span class="c1"># fit() now uses the new FitLoop!</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="c1"># the equivalent for validate()</span>
<span class="n">val_loop</span> <span class="o">=</span> <span class="n">CustomValLoop</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">validate_loop</span> <span class="o">=</span> <span class="n">val_loop</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Now your code is FULLY flexible and you can still leverage ALL the best parts of Lightning!</p>
<img alt="Animation showing how to replace a loop on the Trainer" src="https://pl-public-data.s3.amazonaws.com/docs/static/images/loops/replace-fit-loop.gif" />
</section>
<hr class="docutils" />
<section id="creating-a-new-loop-from-scratch">
<h2>Creating a New Loop From Scratch<a class="headerlink" href="#creating-a-new-loop-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>You can also go wild and implement a full loop from scratch by sub-classing the <code class="xref py py-class docutils literal notranslate"><span class="pre">Loop</span></code> base class.
You will need to override a minimum of two things:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.loop</span> <span class="kn">import</span> <span class="n">Loop</span>


<span class="k">class</span> <span class="nc">MyFancyLoop</span><span class="p">(</span><span class="n">Loop</span><span class="p">):</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">done</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Provide a condition to stop the loop.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Access your dataloader/s in whatever way you want.</span>
<span class="sd">        Do your fancy optimization things.</span>
<span class="sd">        Call the LightningModule methods at your leisure.</span>
<span class="sd">        &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>Finally, attach it into the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span> <span class="o">=</span> <span class="n">MyFancyLoop</span><span class="p">()</span>

<span class="c1"># fit() now uses your fancy loop!</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>But beware: Loop customization gives you more power and full control over the Trainer and with great power comes great responsibility.
We recommend that you familiarize yourself with <a class="reference internal" href="#override-default-loops-extensions"><span class="std std-ref">overriding the default loops</span></a> first before you start building a new loop from the ground up.</p>
</section>
<hr class="docutils" />
<section id="loop-api">
<h2>Loop API<a class="headerlink" href="#loop-api" title="Permalink to this headline">¶</a></h2>
<p>Here is the full API of methods available in the Loop base class.</p>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">Loop</span></code> class is the base of all loops in the same way as the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> is the base of all models.
It defines a public interface that each loop implementation must follow, the key ones are:</p>
<section id="properties">
<h3>Properties<a class="headerlink" href="#properties" title="Permalink to this headline">¶</a></h3>
<section id="done">
<h4>done<a class="headerlink" href="#done" title="Permalink to this headline">¶</a></h4>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Loop.</span></span><span class="sig-name descname"><span class="pre">done</span></span></dt>
<dd><p>Property indicating when the loop is finished.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">done</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">max_steps</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="skip-optional">
<h4>skip (optional)<a class="headerlink" href="#skip-optional" title="Permalink to this headline">¶</a></h4>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Loop.</span></span><span class="sig-name descname"><span class="pre">skip</span></span></dt>
<dd><p>Determine whether to return immediately from the call to <code class="xref py py-meth docutils literal notranslate"><span class="pre">run()</span></code>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">skip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h3>
<section id="reset-optional">
<h4>reset (optional)<a class="headerlink" href="#reset-optional" title="Permalink to this headline">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Loop.</span></span><span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_lightning/loops/base.html#Loop.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Resets the internal state of the loop at the beginning of each call to <code class="xref py py-attr docutils literal notranslate"><span class="pre">run</span></code>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># reset your internal state or add custom logic</span>
    <span class="c1"># if you expect run() to be called multiple times</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_iteration</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="advance">
<h4>advance<a class="headerlink" href="#advance" title="Permalink to this headline">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">Loop.</span></span><span class="sig-name descname"><span class="pre">advance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_lightning/loops/base.html#Loop.advance"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Performs a single step.</p>
<p>Accepts all arguments passed to <code class="xref py py-attr docutils literal notranslate"><span class="pre">run</span></code>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="run-optional">
<h4>run (optional)<a class="headerlink" href="#run-optional" title="Permalink to this headline">¶</a></h4>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">Loop.</span></span><span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pytorch_lightning/loops/base.html#Loop.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>The main entry point to the loop.</p>
<p>Will frequently check the <code class="xref py py-attr docutils literal notranslate"><span class="pre">done</span></code> condition and calls <code class="xref py py-attr docutils literal notranslate"><span class="pre">advance</span></code>
until <code class="xref py py-attr docutils literal notranslate"><span class="pre">done</span></code> evaluates to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Override this if you wish to change the default behavior. The default implementation is:</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_skip</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_run_start</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_run_end</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>~T</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The output of <code class="xref py py-attr docutils literal notranslate"><span class="pre">on_run_end</span></code> (often outputs collected from each step of the loop)</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>
<hr class="docutils" />
<section id="subloops">
<h2>Subloops<a class="headerlink" href="#subloops" title="Permalink to this headline">¶</a></h2>
<p>When you want to customize nested loops within loops, use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">replace()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># This takes care of properly instantiating the new Loop and setting all references</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">epoch_loop</span><span class="o">=</span><span class="n">MyEpochLoop</span><span class="p">)</span>
<span class="c1"># Trainer runs the fit loop with your new epoch loop!</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, for more fine-grained control, use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">connect()</span></code> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Optional: stitch back the trainer arguments</span>
<span class="n">epoch_loop</span> <span class="o">=</span> <span class="n">MyEpochLoop</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">min_steps</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">max_steps</span><span class="p">)</span>
<span class="c1"># Optional: connect children loops as they might have existing state</span>
<span class="n">epoch_loop</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">batch_loop</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">epoch_loop</span><span class="o">.</span><span class="n">val_loop</span><span class="p">)</span>
<span class="c1"># Instantiate and connect the loop.</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">epoch_loop</span><span class="o">=</span><span class="n">epoch_loop</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>More about the built-in loops and how they are composed is explained in the next section.</p>
<img alt="Animation showing how to connect a custom subloop" src="https://pl-public-data.s3.amazonaws.com/docs/static/images/loops/connect-epoch-loop.gif" />
</section>
<hr class="docutils" />
<section id="built-in-loops">
<h2>Built-in Loops<a class="headerlink" href="#built-in-loops" title="Permalink to this headline">¶</a></h2>
<p id="loop-structure-extensions">The training loop in Lightning is called <em>fit loop</em> and is actually a combination of several loops.
Here is what the structure would look like in plain Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># FitLoop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>

    <span class="c1"># TrainingEpochLoop</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>

        <span class="c1"># TrainingBatchLoop</span>
        <span class="k">for</span> <span class="n">split_batch</span> <span class="ow">in</span> <span class="n">tbptt_split</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>

            <span class="c1"># OptimizerLoop</span>
            <span class="k">for</span> <span class="n">optimizer_idx</span><span class="p">,</span> <span class="n">opt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">optimizers</span><span class="p">):</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">lightning_module</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer_idx</span><span class="p">)</span>
                <span class="o">...</span>

        <span class="c1"># ValidationEpochLoop</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_dataloader</span><span class="p">):</span>
            <span class="n">lightning_module</span><span class="o">.</span><span class="n">validation_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer_idx</span><span class="p">)</span>
            <span class="o">...</span>
</pre></div>
</div>
<p>Each of these <code class="code docutils literal notranslate"><span class="pre">for</span></code>-loops represents a class implementing the <code class="xref py py-class docutils literal notranslate"><span class="pre">Loop</span></code> interface.</p>
<table class="colwidths-given docutils align-default" id="id1">
<caption><span class="caption-text">Trainer entry points and associated loops</span><a class="headerlink" href="#id1" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Built-in loop</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">FitLoop</span></code></p></td>
<td><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">FitLoop</span></code> is the top-level loop where training starts.
It simply counts the epochs and iterates from one to the next by calling <code class="code docutils literal notranslate"><span class="pre">TrainingEpochLoop.run()</span></code> in its <code class="code docutils literal notranslate"><span class="pre">advance()</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingEpochLoop</span></code></p></td>
<td><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingEpochLoop</span></code> is the one that iterates over the dataloader that the user returns in their <code class="xref py py-meth docutils literal notranslate"><span class="pre">train_dataloader()</span></code> method.
Its main responsibilities are calling the <code class="code docutils literal notranslate"><span class="pre">*_epoch_start</span></code> and <code class="code docutils literal notranslate"><span class="pre">*_epoch_end</span></code> hooks, accumulating outputs if the user request them in one of these hooks, and running validation at the requested interval.
The validation is carried out by yet another loop, <code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationEpochLoop</span></code>.</p>
<p>In the <code class="code docutils literal notranslate"><span class="pre">run()</span></code> method, the training epoch loop could in theory simply call the <code class="code docutils literal notranslate"><span class="pre">LightningModule.training_step</span></code> already and perform the optimization.
However, Lightning has built-in support for automatic optimization with multiple optimizers and on top of that also supports <a class="reference internal" href="../guides/data.html#sequential-data"><span class="std std-ref">TBPTT</span></a>.
For this reason there are actually two more loops nested under <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingEpochLoop</span></code>.</p>
</td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingBatchLoop</span></code></p></td>
<td><p>The responsibility of the <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingBatchLoop</span></code> is to split a batch given by the <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingEpochLoop</span></code> along the time-dimension and iterate over the list of splits.
It also keeps track of the hidden state <em>hiddens</em> returned by the training step.
By default, when truncated back-propagation through time (TBPTT) is turned off, this loop does not do anything except redirect the call to the <code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerLoop</span></code>.
Read more about <a class="reference internal" href="../guides/data.html#sequential-data"><span class="std std-ref">TBPTT</span></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerLoop</span></code></p></td>
<td><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerLoop</span></code> iterates over one or multiple optimizers and for each one it calls the <code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code> method with the batch, the current batch index and the optimizer index if multiple optimizers are requested.
It is the leaf node in the tree of loops and performs the actual optimization (forward, zero grad, backward, optimizer step).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ManualOptimization</span></code></p></td>
<td><p>Substitutes the <code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizerLoop</span></code> in case of <a class="reference internal" href="../model/manual_optimization.html"><span class="doc">manual optimization</span></a> and implements the manual optimization step.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">EvaluationLoop</span></code></p></td>
<td><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">EvaluationLoop</span></code> is the top-level loop where validation/testing starts.
It simply iterates over each evaluation dataloader from one to the next by calling <code class="code docutils literal notranslate"><span class="pre">EvaluationEpochLoop.run()</span></code> in its <code class="code docutils literal notranslate"><span class="pre">advance()</span></code> method.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionLoop</span></code></p></td>
<td><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionLoop</span></code> is the top-level loop where prediction starts.
It simply iterates over each prediction dataloader from one to the next by calling <code class="code docutils literal notranslate"><span class="pre">PredictionEpochLoop.run()</span></code> in its <code class="code docutils literal notranslate"><span class="pre">advance()</span></code> method.</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="available-loops-in-lightning-flash">
<h2>Available Loops in Lightning Flash<a class="headerlink" href="#available-loops-in-lightning-flash" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)">Active Learning</a> is a machine learning practice in which the user interacts with the learner in order to provide new labels when required.</p>
<p>You can find a real use case in <a class="reference external" href="https://github.com/PyTorchLightning/lightning-flash">Lightning Flash</a>.</p>
<p>Flash implements the <code class="code docutils literal notranslate"><span class="pre">ActiveLearningLoop</span></code> that you can use together with the <code class="code docutils literal notranslate"><span class="pre">ActiveLearningDataModule</span></code> to label new data on the fly.
To run the following demo, install Flash and <a class="reference external" href="https://github.com/ElementAI/baal">BaaL</a>  first:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install lightning-flash baal
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">flash</span>
<span class="kn">from</span> <span class="nn">flash.core.classification</span> <span class="kn">import</span> <span class="n">Probabilities</span>
<span class="kn">from</span> <span class="nn">flash.core.data.utils</span> <span class="kn">import</span> <span class="n">download_data</span>
<span class="kn">from</span> <span class="nn">flash.image</span> <span class="kn">import</span> <span class="n">ImageClassificationData</span><span class="p">,</span> <span class="n">ImageClassifier</span>
<span class="kn">from</span> <span class="nn">flash.image.classification.integrations.baal</span> <span class="kn">import</span> <span class="n">ActiveLearningDataModule</span><span class="p">,</span> <span class="n">ActiveLearningLoop</span>

<span class="c1"># 1. Create the DataModule</span>
<span class="n">download_data</span><span class="p">(</span><span class="s2">&quot;https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip&quot;</span><span class="p">,</span> <span class="s2">&quot;./data&quot;</span><span class="p">)</span>

<span class="c1"># Implement the research use-case where we mask labels from labelled dataset.</span>
<span class="n">datamodule</span> <span class="o">=</span> <span class="n">ActiveLearningDataModule</span><span class="p">(</span>
    <span class="n">ImageClassificationData</span><span class="o">.</span><span class="n">from_folders</span><span class="p">(</span><span class="n">train_folder</span><span class="o">=</span><span class="s2">&quot;data/hymenoptera_data/train/&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">initial_num_labels</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">val_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 2. Build the task</span>
<span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">num_classes</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">(</span><span class="n">backbone</span><span class="o">=</span><span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="n">head</span><span class="o">=</span><span class="n">head</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">Probabilities</span><span class="p">())</span>


<span class="c1"># 3.1 Create the trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">flash</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># 3.2 Create the active learning loop and connect it to the trainer</span>
<span class="n">active_learning_loop</span> <span class="o">=</span> <span class="n">ActiveLearningLoop</span><span class="p">(</span><span class="n">label_epoch_frequency</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">active_learning_loop</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit_loop</span> <span class="o">=</span> <span class="n">active_learning_loop</span>

<span class="c1"># 3.3 Finetune</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">finetune</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;freeze&quot;</span><span class="p">)</span>

<span class="c1"># 4. Predict what&#39;s on a few images! ants or bees?</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s2">&quot;data/hymenoptera_data/val/bees/65038344_52a45d090d.jpg&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="c1"># 5. Save the model!</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="s2">&quot;image_classification_model.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here is the <a class="reference external" href="https://github.com/PyTorchLightning/lightning-flash/blob/master/flash_examples/integrations/baal/image_classification_active_learning.py">Active Learning Loop example</a> and the <a class="reference external" href="https://github.com/PyTorchLightning/lightning-flash/blob/master/flash/image/classification/integrations/baal/loop.py">code for the active learning loop</a>.</p>
</section>
<hr class="docutils" />
<section id="advanced-examples">
<h2>Advanced Examples<a class="headerlink" href="#advanced-examples" title="Permalink to this headline">¶</a></h2>
<table class="colwidths-given docutils align-default" id="id2">
<caption><span class="caption-text">Ready-to-run loop examples and tutorials</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Link to Example</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/loop_examples/kfold.py">K-fold Cross Validation</a></p></td>
<td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">KFold / Cross Validation</a> is a machine learning practice in which the training dataset is being partitioned into <code class="docutils literal notranslate"><span class="pre">num_folds</span></code> complementary subsets.
One cross validation round will perform fitting where one fold is left out for validation and the other folds are used for training.
To reduce variability, once all rounds are performed using the different folds, the trained models are ensembled and their predictions are
averaged when estimating the model’s predictive performance on the test dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/loop_examples/yielding_training_step.py">Yielding Training Step</a></p></td>
<td><p>This loop enables you to write the <code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code> hook
as a Python Generator for automatic optimization with multiple optimizers, i.e., you can <code class="code docutils literal notranslate"><span class="pre">yield</span></code> loss
values from it instead of returning them. This can enable more elegant and expressive implementations, as shown
shown with a GAN in this example.</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="advanced-features">
<h2>Advanced Features<a class="headerlink" href="#advanced-features" title="Permalink to this headline">¶</a></h2>
<p>Next: <a class="reference internal" href="loops_advanced.html"><span class="doc">Advanced loop features</span></a></p>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plugins.html" class="btn btn-neutral float-right" title="Plugins" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../visualize/loggers.html" class="btn btn-neutral" title="Track and Visualize Experiments" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2018-2022, William Falcon et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Loops</a><ul>
<li><a class="reference internal" href="#understanding-the-default-trainer-loop">Understanding the Default Trainer Loop</a></li>
<li><a class="reference internal" href="#overriding-the-default-loops">Overriding the default Loops</a></li>
<li><a class="reference internal" href="#creating-a-new-loop-from-scratch">Creating a New Loop From Scratch</a></li>
<li><a class="reference internal" href="#loop-api">Loop API</a><ul>
<li><a class="reference internal" href="#properties">Properties</a><ul>
<li><a class="reference internal" href="#done">done</a></li>
<li><a class="reference internal" href="#skip-optional">skip (optional)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#methods">Methods</a><ul>
<li><a class="reference internal" href="#reset-optional">reset (optional)</a></li>
<li><a class="reference internal" href="#advance">advance</a></li>
<li><a class="reference internal" href="#run-optional">run (optional)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#subloops">Subloops</a></li>
<li><a class="reference internal" href="#built-in-loops">Built-in Loops</a></li>
<li><a class="reference internal" href="#available-loops-in-lightning-flash">Available Loops in Lightning Flash</a></li>
<li><a class="reference internal" href="#advanced-examples">Advanced Examples</a></li>
<li><a class="reference internal" href="#advanced-features">Advanced Features</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script>let toggleHintShow = 'Click to show';</script>
         <script>let toggleHintHide = 'Click to hide';</script>
         <script>let toggleOpenOnPrint = 'true';</script>
         <script src="../_static/togglebutton.js"></script>
         <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Best practices', 'Optional Extensions', 'Tutorials', 'API References', 'Bolts', 'Examples', 'Partner Domain Frameworks', 'Community'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.rtfd.io/en/latest">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">View Resources</a>
        </div>
        -->
      </div>
    </div>
  </div>

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch-lightning.rtfd.io/en/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.rtfd.io/en/latest/">PyTorch</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://www.pytorchlightning.ai/blog">Blog</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Resources</a></li>
            <li><a href="https://pytorch-lightning.readthedocs.io/en/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://pytorch-lightning.rtfd.io/en/latest">Docs</a></li>
            <li><a href="https://www.pytorchlightning.ai/community" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/PyTorchLightning/pytorch-lightning/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/PyTorchLightnin" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch-lightning.rtfd.io/en/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <!-- <li>
            <a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.pytorchlightning.ai/blog">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning-flash.readthedocs.io/en/stable/">Lightning Flash</a>
            </li>

            <li>
              <a href="https://lightning-transformers.readthedocs.io/en/stable/">Lightning Transformers</a>
            </li>

            <li>
              <a href="https://lightning-bolts.readthedocs.io/en/stable/">Lightning Bolts</a>
            </li>
          </ul> -->

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch-lightning.rtfd.io/en/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="https://www.pytorchlightning.ai/community">Community</a>
            </li>

            <li>
              <a href="https://github.com/PyTorchLightning/pytorch-lightning/discussions">Forums</a>
            </li>
          </ul>-->

          <!-- <li>
            <a href="https://github.com/PyTorchLightning/pytorch-lightning">Github</a>
          </li> -->

          <!-- <li>
            <a href="https://www.grid.ai/">Grid.ai</a>
          </li> -->
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

 </body>
</html>